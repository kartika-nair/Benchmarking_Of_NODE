{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AmericaLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saahil-jain/Covid_19_predictor/blob/master/AmericaLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yRFjN9fUYFr",
        "colab_type": "code",
        "outputId": "9aa0e60e-991c-472a-e786-c2ce0990a725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten, LSTM\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Input\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers import Bidirectional\n",
        "import re\n",
        "import os\n",
        "import numpy\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "print(os.getcwd())\n",
        "if os.getcwd().split(\"/\")[-1] == \"Covid_19_predictor\":\n",
        "  print(\"Current working directory is already Covid_19_predictor\")\n",
        "elif os.path.isdir(\"Covid_19_predictor\"):\n",
        "  print(\"Covid_19_predictor already Exists\")\n",
        "else:\n",
        "  ! git clone https://github.com/saahil-jain/Covid_19_predictor.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'Covid_19_predictor'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 29 (delta 13), reused 4 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (29/29), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNjgbb2rUe5C",
        "colab_type": "code",
        "outputId": "16eb5920-8a36-4936-cd40-c17ce5eb4411",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "if os.path.isdir(\"Covid_19_predictor\"):\n",
        "  % cd Covid_19_predictor\n",
        "! git pull"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Covid_19_predictor\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP6kal--UkJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv(\"data.csv\")\n",
        "grouped=df.groupby('countriesAndTerritories')\n",
        "countries=sorted(list(set(df.countriesAndTerritories.unique())))\n",
        "country_wise_cases=dict()\n",
        "country_wise_deaths=dict()\n",
        "for country in countries:\n",
        "  country_wise_cases[country]=list(grouped.get_group(country)['cases'])[::-1]\n",
        "  country_wise_deaths[country]=list(grouped.get_group(country)['deaths'])[::-1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUj62R_rVJq4",
        "colab_type": "code",
        "outputId": "1c24ed78-d8c3-42f5-fe2c-9fafc6f8fb9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "cumulative_country_wise_cases=dict()\n",
        "cumulative_country_wise_deaths=dict()\n",
        "\n",
        "for country in countries:\n",
        "  cumulative_country_wise_cases[country] = []\n",
        "  cumulative_country_wise_deaths[country] = []\n",
        "  cumulative_cases = 0\n",
        "  cumulative_death = 0\n",
        "  total_days = len(country_wise_deaths[country])\n",
        "  for index in range(total_days):\n",
        "    cumulative_cases += country_wise_cases[country][index]\n",
        "    cumulative_death += country_wise_deaths[country][index]\n",
        "    cumulative_country_wise_cases[country].append(cumulative_cases)\n",
        "    cumulative_country_wise_deaths[country].append(cumulative_death)\n",
        "\n",
        "for country in countries:\n",
        "  if country == 'United_States_of_America':\n",
        "    print(cumulative_country_wise_cases[country])\n",
        "    graph=plt.plot(cumulative_country_wise_cases[country])\n",
        "plt.show()\n",
        "\n",
        "for country in countries:\n",
        "  if country == 'United_States_of_America':\n",
        "    print(cumulative_country_wise_deaths[country])\n",
        "    graph=plt.plot(cumulative_country_wise_deaths[country])\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 5, 5, 5, 5, 6, 7, 8, 11, 11, 11, 12, 12, 12, 12, 12, 13, 13, 14, 15, 15, 15, 15, 15, 15, 15, 16, 35, 35, 35, 53, 53, 59, 60, 66, 69, 89, 103, 125, 159, 233, 338, 433, 554, 754, 1025, 1312, 1663, 2174, 2951, 3774, 4661, 6427, 9415, 14250, 19624, 26747, 35206, 46442, 55231, 69194, 85991, 104686, 124665, 143025, 164620, 189618, 216721, 245540, 277965, 312237, 337635, 368196, 398809, 432132, 466033, 501560, 529951, 557571, 582594, 609516, 639664, 671331, 702164, 735086, 759687, 787752, 825041, 842629, 869172, 890524, 939053, 965910, 988451, 1012583, 1039909, 1069826, 1103781, 1133069, 1158041, 1180634, 1204475, 1228603, 1256972, 1283929, 1309541, 1329799, 1347916, 1369964, 1390746, 1417889, 1443397, 1467884, 1486757, 1508598, 1528568, 1551853, 1577287]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 6, 9, 11, 12, 14, 17, 21, 26, 28, 30, 40, 47, 57, 69, 85, 108, 150, 150, 260, 340, 471, 590, 801, 1050, 1296, 1707, 2191, 2509, 3170, 4079, 5138, 6053, 7157, 8501, 9647, 10989, 12895, 14817, 16690, 18777, 20608, 22108, 23649, 26057, 30985, 33284, 37054, 38910, 40682, 42539, 45063, 46784, 49963, 51017, 53189, 54876, 56245, 58355, 60966, 63006, 65068, 66385, 67682, 68934, 71078, 73431, 75670, 77180, 78794, 79528, 80684, 82387, 84133, 85906, 87568, 88754, 89562, 90353, 91921, 93439, 94702]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l4rQk-PVU2f",
        "colab_type": "code",
        "outputId": "31fc9656-160d-46fe-c3e6-c7d854cf8d89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "for country in countries:\n",
        "  if country == 'United_States_of_America':\n",
        "    america_cases = []\n",
        "    america_death = []\n",
        "    total_days = len(country_wise_deaths[country])\n",
        "    for index in range(total_days):\n",
        "      america_cases.append(country_wise_cases[country][index])\n",
        "      america_death.append(country_wise_deaths[country][index])\n",
        "america_cases.sort()\n",
        "america_death.sort()\n",
        "\n",
        "print(america_cases)\n",
        "print(america_death)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 6, 6, 14, 18, 19, 20, 22, 34, 74, 95, 105, 121, 200, 271, 287, 351, 511, 777, 823, 887, 1766, 2988, 4835, 5374, 7123, 8459, 8789, 11236, 13963, 16797, 17588, 18117, 18360, 18695, 18873, 19970, 19979, 20258, 20782, 21352, 21595, 21841, 22048, 22541, 22593, 23285, 23841, 24128, 24132, 24487, 24601, 24972, 24998, 25023, 25398, 25434, 25508, 25612, 26543, 26857, 26922, 26957, 27103, 27143, 27326, 27620, 28065, 28369, 28391, 28819, 29288, 29917, 30148, 30561, 30613, 30833, 31667, 32425, 32922, 33323, 33901, 33955, 34272, 35527, 37289, 48529]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 3, 3, 4, 4, 5, 7, 10, 10, 12, 16, 23, 42, 80, 110, 119, 131, 211, 246, 249, 318, 411, 484, 661, 734, 791, 808, 909, 915, 1054, 1059, 1104, 1146, 1156, 1186, 1252, 1263, 1297, 1317, 1342, 1344, 1369, 1500, 1510, 1518, 1541, 1568, 1614, 1662, 1687, 1703, 1721, 1746, 1772, 1773, 1831, 1856, 1857, 1873, 1906, 1922, 2040, 2062, 2087, 2110, 2144, 2172, 2239, 2299, 2353, 2408, 2524, 2611, 3179, 3770, 4928]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J92JTLk-ActC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(america_cases)):\n",
        "  if(america_cases[i] != 0):\n",
        "    break\n",
        "america_cases = america_cases[i:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WUJ0BRD7ujG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = [x for x in range(len(america_cases))]\n",
        "X = array(X).reshape(len(america_cases), 1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPSqPG2kScsU",
        "colab_type": "code",
        "outputId": "7d0d8908-bf91-4f58-92ff-5c85bbeba2f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(LSTM(128, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "print(model.summary())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (None, 1, 128)            66560     \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 198,273\n",
            "Trainable params: 198,273\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYEL7PZUSihd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e677cb2-0578-4562-e379-6c28d67596c1"
      },
      "source": [
        "model.fit(X, america_cases, epochs=2048, validation_split=0.1, verbose=1, batch_size=2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 90 samples, validate on 10 samples\n",
            "Epoch 1/2048\n",
            "90/90 [==============================] - 1s 9ms/step - loss: 328618489.5316 - val_loss: 1266465382.4000\n",
            "Epoch 2/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 321615257.9441 - val_loss: 1210233395.2000\n",
            "Epoch 3/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 294449756.5966 - val_loss: 1060406348.8000\n",
            "Epoch 4/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 242502579.4474 - val_loss: 827823065.6000\n",
            "Epoch 5/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 172440372.4309 - val_loss: 542231500.8000\n",
            "Epoch 6/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 101305613.1299 - val_loss: 278074316.8000\n",
            "Epoch 7/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 49623088.9667 - val_loss: 117896403.2000\n",
            "Epoch 8/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 31548177.1653 - val_loss: 76726730.8000\n",
            "Epoch 9/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 18241888.8056 - val_loss: 31776343.3500\n",
            "Epoch 10/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 11199531.6944 - val_loss: 21083617.6187\n",
            "Epoch 11/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 9809683.1033 - val_loss: 24386752.7250\n",
            "Epoch 12/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 11694020.2161 - val_loss: 19186611.0680\n",
            "Epoch 13/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 8444052.3983 - val_loss: 18454228.2820\n",
            "Epoch 14/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 8935856.0236 - val_loss: 16827014.5789\n",
            "Epoch 15/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 7783233.9186 - val_loss: 15312536.2875\n",
            "Epoch 16/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 5591530.9201 - val_loss: 15153325.9500\n",
            "Epoch 17/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 5014419.0039 - val_loss: 14948764.2500\n",
            "Epoch 18/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 5506067.3576 - val_loss: 15164700.9250\n",
            "Epoch 19/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4690507.1978 - val_loss: 14946063.1750\n",
            "Epoch 20/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3510024.9910 - val_loss: 14923958.4750\n",
            "Epoch 21/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3185824.3877 - val_loss: 14959485.8500\n",
            "Epoch 22/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3605806.0087 - val_loss: 14961845.3000\n",
            "Epoch 23/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3261181.5398 - val_loss: 14976098.4750\n",
            "Epoch 24/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 5157285.9286 - val_loss: 14949095.1000\n",
            "Epoch 25/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3204178.5977 - val_loss: 14962164.7000\n",
            "Epoch 26/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3069500.4400 - val_loss: 14956123.4750\n",
            "Epoch 27/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 5768910.7371 - val_loss: 15845794.7625\n",
            "Epoch 28/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2809805.4144 - val_loss: 14961536.4250\n",
            "Epoch 29/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3652584.9693 - val_loss: 14979805.7000\n",
            "Epoch 30/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2586011.0266 - val_loss: 15006460.1500\n",
            "Epoch 31/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2796804.9600 - val_loss: 14992111.8000\n",
            "Epoch 32/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 5008647.8561 - val_loss: 15256041.5875\n",
            "Epoch 33/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4654378.0080 - val_loss: 15067767.0000\n",
            "Epoch 34/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 5314030.8480 - val_loss: 15000278.5000\n",
            "Epoch 35/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4048448.1086 - val_loss: 14969150.8000\n",
            "Epoch 36/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4335713.2091 - val_loss: 14961889.8250\n",
            "Epoch 37/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3442047.5611 - val_loss: 14951251.4000\n",
            "Epoch 38/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4246479.9397 - val_loss: 14987895.3500\n",
            "Epoch 39/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2929744.9013 - val_loss: 14952636.2500\n",
            "Epoch 40/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2549721.0025 - val_loss: 14973107.5000\n",
            "Epoch 41/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2428770.2213 - val_loss: 14983129.7000\n",
            "Epoch 42/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2733373.8429 - val_loss: 15046507.8250\n",
            "Epoch 43/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2267051.1133 - val_loss: 15005552.3500\n",
            "Epoch 44/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2162751.5279 - val_loss: 15006392.3000\n",
            "Epoch 45/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2682262.0438 - val_loss: 15056756.5750\n",
            "Epoch 46/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2388847.6546 - val_loss: 15085963.9000\n",
            "Epoch 47/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2010636.5048 - val_loss: 15036041.1750\n",
            "Epoch 48/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2076187.5518 - val_loss: 15119103.9250\n",
            "Epoch 49/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2106409.4807 - val_loss: 15096650.2250\n",
            "Epoch 50/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2389629.9470 - val_loss: 15163536.7750\n",
            "Epoch 51/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3966251.5193 - val_loss: 17608295.6898\n",
            "Epoch 52/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3900656.3716 - val_loss: 15086588.6750\n",
            "Epoch 53/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2961295.4222 - val_loss: 15241771.8500\n",
            "Epoch 54/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2198176.1053 - val_loss: 15069523.8250\n",
            "Epoch 55/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3295175.7845 - val_loss: 15354214.1000\n",
            "Epoch 56/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2315305.7024 - val_loss: 15047992.3250\n",
            "Epoch 57/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1996777.5695 - val_loss: 15038979.4500\n",
            "Epoch 58/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4055182.4671 - val_loss: 15852442.0813\n",
            "Epoch 59/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4252875.2972 - val_loss: 15052869.7000\n",
            "Epoch 60/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3831439.4968 - val_loss: 15002085.6500\n",
            "Epoch 61/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2306780.2314 - val_loss: 15179299.3750\n",
            "Epoch 62/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2280586.4239 - val_loss: 15032211.2500\n",
            "Epoch 63/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2005746.8881 - val_loss: 15070459.5500\n",
            "Epoch 64/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2848343.2757 - val_loss: 15189355.1750\n",
            "Epoch 65/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2140944.4097 - val_loss: 15038020.2500\n",
            "Epoch 66/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1908748.2926 - val_loss: 15065577.9500\n",
            "Epoch 67/2048\n",
            "90/90 [==============================] - 0s 3ms/step - loss: 1951015.5081 - val_loss: 15201700.6625\n",
            "Epoch 68/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 6441181.2222 - val_loss: 15471634.5375\n",
            "Epoch 69/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 9588689.6656 - val_loss: 28977639.4500\n",
            "Epoch 70/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 5033191.6132 - val_loss: 15151279.0500\n",
            "Epoch 71/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3896866.0735 - val_loss: 15752768.6062\n",
            "Epoch 72/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2856801.5355 - val_loss: 15011922.7000\n",
            "Epoch 73/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2906610.2195 - val_loss: 15057733.3750\n",
            "Epoch 74/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3631249.8185 - val_loss: 15078606.8750\n",
            "Epoch 75/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3097267.6478 - val_loss: 15067609.9500\n",
            "Epoch 76/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3301440.8642 - val_loss: 15054879.8500\n",
            "Epoch 77/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4547288.1246 - val_loss: 15048752.6250\n",
            "Epoch 78/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4315648.0559 - val_loss: 15022186.7500\n",
            "Epoch 79/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2385618.7867 - val_loss: 15010282.4500\n",
            "Epoch 80/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2261357.7174 - val_loss: 14997160.4250\n",
            "Epoch 81/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2405229.5089 - val_loss: 15028432.5500\n",
            "Epoch 82/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1945229.8759 - val_loss: 15025547.3250\n",
            "Epoch 83/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2067213.9048 - val_loss: 15268173.1125\n",
            "Epoch 84/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1926050.8672 - val_loss: 15108837.4750\n",
            "Epoch 85/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2284840.4390 - val_loss: 15068107.0250\n",
            "Epoch 86/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2529653.6916 - val_loss: 15219407.2125\n",
            "Epoch 87/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1816495.3863 - val_loss: 15095826.6500\n",
            "Epoch 88/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2966454.1043 - val_loss: 15316858.7250\n",
            "Epoch 89/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2863944.9918 - val_loss: 15183674.0000\n",
            "Epoch 90/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2904786.4535 - val_loss: 15135269.4250\n",
            "Epoch 91/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2866229.5445 - val_loss: 15075862.5750\n",
            "Epoch 92/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1946286.4946 - val_loss: 15198521.6750\n",
            "Epoch 93/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1851771.4425 - val_loss: 15094531.0750\n",
            "Epoch 94/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2004821.0841 - val_loss: 15302408.5250\n",
            "Epoch 95/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1909505.0225 - val_loss: 15115418.5750\n",
            "Epoch 96/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2042800.9852 - val_loss: 15167224.3250\n",
            "Epoch 97/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2065906.5988 - val_loss: 15312509.0375\n",
            "Epoch 98/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2486031.9144 - val_loss: 15169809.4500\n",
            "Epoch 99/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2246048.2571 - val_loss: 15230730.0625\n",
            "Epoch 100/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1956653.6710 - val_loss: 15097348.5250\n",
            "Epoch 101/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2021177.5775 - val_loss: 15232325.6750\n",
            "Epoch 102/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1673843.0911 - val_loss: 15470358.0750\n",
            "Epoch 103/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1889700.0584 - val_loss: 15303234.1625\n",
            "Epoch 104/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2026285.0824 - val_loss: 15269511.8375\n",
            "Epoch 105/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1929183.1267 - val_loss: 15341353.9875\n",
            "Epoch 106/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 5183162.8188 - val_loss: 15608763.6000\n",
            "Epoch 107/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4269256.9811 - val_loss: 15908026.6438\n",
            "Epoch 108/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2183811.9887 - val_loss: 15050650.6750\n",
            "Epoch 109/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4265487.3970 - val_loss: 15410968.0875\n",
            "Epoch 110/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3614282.5119 - val_loss: 15027801.8500\n",
            "Epoch 111/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3907118.0664 - val_loss: 15033362.6750\n",
            "Epoch 112/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2244891.5112 - val_loss: 15018015.6250\n",
            "Epoch 113/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2476144.2755 - val_loss: 15039781.2000\n",
            "Epoch 114/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2145159.9809 - val_loss: 15101033.0750\n",
            "Epoch 115/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3134753.0879 - val_loss: 15102807.5500\n",
            "Epoch 116/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2617352.9072 - val_loss: 15124377.0500\n",
            "Epoch 117/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3499234.0147 - val_loss: 15190550.6250\n",
            "Epoch 118/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3547183.3544 - val_loss: 15202806.0500\n",
            "Epoch 119/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2123066.1533 - val_loss: 15032549.9000\n",
            "Epoch 120/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3163766.8669 - val_loss: 15060734.1000\n",
            "Epoch 121/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 6693948.0938 - val_loss: 18150831.5094\n",
            "Epoch 122/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3045829.7165 - val_loss: 15049192.6500\n",
            "Epoch 123/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2887583.5821 - val_loss: 15131873.7750\n",
            "Epoch 124/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2181205.2829 - val_loss: 15039170.9250\n",
            "Epoch 125/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1874227.4869 - val_loss: 15076379.5500\n",
            "Epoch 126/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2058523.4230 - val_loss: 15199826.1000\n",
            "Epoch 127/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3120396.9251 - val_loss: 15271270.2375\n",
            "Epoch 128/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2626043.6468 - val_loss: 15158175.3500\n",
            "Epoch 129/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2262937.2480 - val_loss: 15173164.2500\n",
            "Epoch 130/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3371893.6226 - val_loss: 15420779.3625\n",
            "Epoch 131/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3235695.1487 - val_loss: 15072211.3000\n",
            "Epoch 132/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4512097.9568 - val_loss: 15378280.7750\n",
            "Epoch 133/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3069006.9820 - val_loss: 15140574.8750\n",
            "Epoch 134/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2432661.8754 - val_loss: 15058012.8250\n",
            "Epoch 135/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2702168.6970 - val_loss: 15051719.6000\n",
            "Epoch 136/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2300993.9085 - val_loss: 15040747.3000\n",
            "Epoch 137/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1908459.7919 - val_loss: 15051097.9750\n",
            "Epoch 138/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2181614.1083 - val_loss: 15072060.1750\n",
            "Epoch 139/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2193392.8670 - val_loss: 15270269.0125\n",
            "Epoch 140/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1752746.7476 - val_loss: 15225546.1250\n",
            "Epoch 141/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1679572.2609 - val_loss: 15189739.7500\n",
            "Epoch 142/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1901140.5061 - val_loss: 15166532.1750\n",
            "Epoch 143/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1801434.7441 - val_loss: 15088395.9250\n",
            "Epoch 144/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1563920.3265 - val_loss: 15247427.6750\n",
            "Epoch 145/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1833768.6186 - val_loss: 15334036.5875\n",
            "Epoch 146/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2220282.7571 - val_loss: 15393461.4000\n",
            "Epoch 147/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3427103.2079 - val_loss: 15382037.1000\n",
            "Epoch 148/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2150828.1712 - val_loss: 15255983.9625\n",
            "Epoch 149/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2738262.1078 - val_loss: 15099226.9250\n",
            "Epoch 150/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2572442.0632 - val_loss: 15429502.4250\n",
            "Epoch 151/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1662013.5992 - val_loss: 15163392.7750\n",
            "Epoch 152/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1714803.6496 - val_loss: 15257134.1875\n",
            "Epoch 153/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2652767.9260 - val_loss: 15332098.8625\n",
            "Epoch 154/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2214038.6757 - val_loss: 15418772.4250\n",
            "Epoch 155/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1976332.9126 - val_loss: 15369300.6125\n",
            "Epoch 156/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1828091.3555 - val_loss: 15326624.8750\n",
            "Epoch 157/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2826368.2214 - val_loss: 15223353.0250\n",
            "Epoch 158/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4862665.3588 - val_loss: 15450051.6625\n",
            "Epoch 159/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2052701.4638 - val_loss: 15098904.4000\n",
            "Epoch 160/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2290194.2417 - val_loss: 15172576.3250\n",
            "Epoch 161/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1759795.4051 - val_loss: 15238732.0500\n",
            "Epoch 162/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1739045.2748 - val_loss: 15263084.4250\n",
            "Epoch 163/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1860510.2198 - val_loss: 15410721.8625\n",
            "Epoch 164/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2096470.4260 - val_loss: 15494455.7500\n",
            "Epoch 165/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2249808.1238 - val_loss: 15262619.0750\n",
            "Epoch 166/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1640558.6498 - val_loss: 15294446.8125\n",
            "Epoch 167/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1640217.3775 - val_loss: 15471610.0375\n",
            "Epoch 168/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3527809.3022 - val_loss: 15780309.7375\n",
            "Epoch 169/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2247525.7098 - val_loss: 15329136.6250\n",
            "Epoch 170/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1574069.6393 - val_loss: 15203484.4500\n",
            "Epoch 171/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1847053.5075 - val_loss: 15471838.3500\n",
            "Epoch 172/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1782353.6677 - val_loss: 15243534.9000\n",
            "Epoch 173/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1884853.9742 - val_loss: 15324376.9500\n",
            "Epoch 174/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3056135.6415 - val_loss: 15214858.0750\n",
            "Epoch 175/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2060960.2643 - val_loss: 15159531.3250\n",
            "Epoch 176/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2062119.9398 - val_loss: 15628785.1750\n",
            "Epoch 177/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2750741.4824 - val_loss: 15429339.5125\n",
            "Epoch 178/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1700330.8468 - val_loss: 15283847.3375\n",
            "Epoch 179/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1646061.7034 - val_loss: 15346940.1250\n",
            "Epoch 180/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1737578.3658 - val_loss: 15283083.4000\n",
            "Epoch 181/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4641094.0539 - val_loss: 15377990.9000\n",
            "Epoch 182/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 5595773.5968 - val_loss: 16119323.4500\n",
            "Epoch 183/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2872021.1172 - val_loss: 15490578.4875\n",
            "Epoch 184/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2217666.4861 - val_loss: 15178852.3000\n",
            "Epoch 185/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1716140.9572 - val_loss: 15160799.3750\n",
            "Epoch 186/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2274654.3359 - val_loss: 15295660.3500\n",
            "Epoch 187/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2350039.8190 - val_loss: 15266905.3375\n",
            "Epoch 188/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2071355.7818 - val_loss: 15197576.1000\n",
            "Epoch 189/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1961510.4090 - val_loss: 15356684.6125\n",
            "Epoch 190/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2050859.0584 - val_loss: 15109644.7500\n",
            "Epoch 191/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3102909.6041 - val_loss: 15529844.1875\n",
            "Epoch 192/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3221062.4697 - val_loss: 15351611.8875\n",
            "Epoch 193/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2065448.7774 - val_loss: 15249308.0375\n",
            "Epoch 194/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2019124.3847 - val_loss: 15420223.7500\n",
            "Epoch 195/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2202225.7075 - val_loss: 15221299.8750\n",
            "Epoch 196/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4306505.1647 - val_loss: 22137998.7250\n",
            "Epoch 197/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2686362.6126 - val_loss: 15093119.7500\n",
            "Epoch 198/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1927315.7737 - val_loss: 15434809.9750\n",
            "Epoch 199/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1939544.2260 - val_loss: 15150425.2000\n",
            "Epoch 200/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1608025.6192 - val_loss: 15128568.9000\n",
            "Epoch 201/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1850395.0219 - val_loss: 15398279.3375\n",
            "Epoch 202/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1987685.8647 - val_loss: 15314893.4625\n",
            "Epoch 203/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 5195389.0813 - val_loss: 15865288.2500\n",
            "Epoch 204/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 6327120.6804 - val_loss: 15932828.4938\n",
            "Epoch 205/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3544456.8847 - val_loss: 15480896.7250\n",
            "Epoch 206/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3889082.4084 - val_loss: 15266298.7500\n",
            "Epoch 207/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3020038.8338 - val_loss: 15287857.1125\n",
            "Epoch 208/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2052391.0379 - val_loss: 15079996.0500\n",
            "Epoch 209/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1873590.2811 - val_loss: 15242799.1875\n",
            "Epoch 210/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1754242.3626 - val_loss: 15302440.7000\n",
            "Epoch 211/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1747078.1330 - val_loss: 15190460.4250\n",
            "Epoch 212/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1704352.6659 - val_loss: 15163820.4250\n",
            "Epoch 213/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1557361.9723 - val_loss: 15283435.1500\n",
            "Epoch 214/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4733470.6173 - val_loss: 16090339.2125\n",
            "Epoch 215/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1938034.2734 - val_loss: 15121006.8750\n",
            "Epoch 216/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2620499.5838 - val_loss: 15591508.2125\n",
            "Epoch 217/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2680441.2961 - val_loss: 15328408.5000\n",
            "Epoch 218/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1547554.0013 - val_loss: 15084469.9250\n",
            "Epoch 219/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1556361.9969 - val_loss: 15261228.5250\n",
            "Epoch 220/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 5540693.1148 - val_loss: 15693940.0500\n",
            "Epoch 221/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 6043865.2484 - val_loss: 15615572.8875\n",
            "Epoch 222/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3617164.9491 - val_loss: 21424171.1500\n",
            "Epoch 223/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2408303.9562 - val_loss: 15076936.1750\n",
            "Epoch 224/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1772631.3843 - val_loss: 15273379.9250\n",
            "Epoch 225/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3560830.4732 - val_loss: 15378466.0125\n",
            "Epoch 226/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2577144.8000 - val_loss: 15225601.1875\n",
            "Epoch 227/2048\n",
            "90/90 [==============================] - 0s 3ms/step - loss: 1753563.6168 - val_loss: 15164095.2250\n",
            "Epoch 228/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1942816.4043 - val_loss: 15261062.6875\n",
            "Epoch 229/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1782756.1950 - val_loss: 15141700.2000\n",
            "Epoch 230/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1701596.4512 - val_loss: 15298015.8500\n",
            "Epoch 231/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2517834.5118 - val_loss: 15144120.4750\n",
            "Epoch 232/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2558319.8009 - val_loss: 15413795.3500\n",
            "Epoch 233/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1858887.2520 - val_loss: 15251635.2250\n",
            "Epoch 234/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4458112.5540 - val_loss: 15665938.6312\n",
            "Epoch 235/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2083492.2887 - val_loss: 15502334.4875\n",
            "Epoch 236/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2020850.8145 - val_loss: 15428475.0875\n",
            "Epoch 237/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1686331.0342 - val_loss: 15235810.8625\n",
            "Epoch 238/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1676146.8828 - val_loss: 15312315.9625\n",
            "Epoch 239/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1889503.5812 - val_loss: 15207585.2250\n",
            "Epoch 240/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3066325.5567 - val_loss: 15322023.4250\n",
            "Epoch 241/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2581895.7500 - val_loss: 15202716.1500\n",
            "Epoch 242/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1717616.3934 - val_loss: 15235104.3750\n",
            "Epoch 243/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1809454.6966 - val_loss: 15447888.1375\n",
            "Epoch 244/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1551249.8819 - val_loss: 15146333.2750\n",
            "Epoch 245/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2183845.9725 - val_loss: 15780549.8000\n",
            "Epoch 246/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2155490.6653 - val_loss: 15273378.9250\n",
            "Epoch 247/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2877796.8212 - val_loss: 15721148.9062\n",
            "Epoch 248/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2745719.9835 - val_loss: 15577508.5625\n",
            "Epoch 249/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1742450.8035 - val_loss: 15473963.5250\n",
            "Epoch 250/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1845866.2748 - val_loss: 15380893.9125\n",
            "Epoch 251/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1516596.0263 - val_loss: 15427294.3750\n",
            "Epoch 252/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1715646.7430 - val_loss: 15220593.0250\n",
            "Epoch 253/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2088205.0002 - val_loss: 15481319.7625\n",
            "Epoch 254/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2198315.6251 - val_loss: 15809728.9500\n",
            "Epoch 255/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1536302.8166 - val_loss: 15249181.3125\n",
            "Epoch 256/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1612489.4861 - val_loss: 15505561.9500\n",
            "Epoch 257/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1510598.5662 - val_loss: 15726639.3750\n",
            "Epoch 258/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2015955.9756 - val_loss: 15662506.6813\n",
            "Epoch 259/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1881398.6245 - val_loss: 15229220.7750\n",
            "Epoch 260/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3887618.0657 - val_loss: 16047852.3625\n",
            "Epoch 261/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2202630.8308 - val_loss: 15352665.8375\n",
            "Epoch 262/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1929179.3052 - val_loss: 15544622.1875\n",
            "Epoch 263/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4014548.4300 - val_loss: 15251839.6750\n",
            "Epoch 264/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 7198666.4685 - val_loss: 16923889.8086\n",
            "Epoch 265/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2052951.1172 - val_loss: 15222150.1000\n",
            "Epoch 266/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2455761.0266 - val_loss: 15557772.9875\n",
            "Epoch 267/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2155920.4257 - val_loss: 15275677.9875\n",
            "Epoch 268/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1506038.1356 - val_loss: 15161887.2000\n",
            "Epoch 269/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1599663.2236 - val_loss: 15147804.7000\n",
            "Epoch 270/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1890848.3680 - val_loss: 15235149.6500\n",
            "Epoch 271/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2355439.4377 - val_loss: 15379773.8125\n",
            "Epoch 272/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2133482.0943 - val_loss: 15212038.6750\n",
            "Epoch 273/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1669851.6405 - val_loss: 15392056.3500\n",
            "Epoch 274/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1472823.2705 - val_loss: 15527990.7250\n",
            "Epoch 275/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1840235.0014 - val_loss: 15425095.7000\n",
            "Epoch 276/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1628936.0446 - val_loss: 15370340.3000\n",
            "Epoch 277/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1572214.1439 - val_loss: 15508407.6875\n",
            "Epoch 278/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2860312.3442 - val_loss: 16111789.9563\n",
            "Epoch 279/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3968968.7339 - val_loss: 15430001.8500\n",
            "Epoch 280/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2179155.9956 - val_loss: 16817066.7609\n",
            "Epoch 281/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1640391.5718 - val_loss: 15187570.3000\n",
            "Epoch 282/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1867315.8336 - val_loss: 15305246.1125\n",
            "Epoch 283/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2362485.4785 - val_loss: 15292521.6250\n",
            "Epoch 284/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2912011.4121 - val_loss: 15774846.3375\n",
            "Epoch 285/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2348312.7404 - val_loss: 15830273.7375\n",
            "Epoch 286/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2339970.4110 - val_loss: 15533709.1500\n",
            "Epoch 287/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2307626.0846 - val_loss: 15211988.8500\n",
            "Epoch 288/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3293298.4772 - val_loss: 15684458.7625\n",
            "Epoch 289/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2042705.9335 - val_loss: 15346950.2125\n",
            "Epoch 290/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1637295.2142 - val_loss: 15243967.5500\n",
            "Epoch 291/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2158822.6034 - val_loss: 15198251.4500\n",
            "Epoch 292/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1813706.3879 - val_loss: 15277270.8625\n",
            "Epoch 293/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2435546.1276 - val_loss: 15704277.4000\n",
            "Epoch 294/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1917210.4417 - val_loss: 15209023.0250\n",
            "Epoch 295/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1883588.7307 - val_loss: 15392998.5000\n",
            "Epoch 296/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1552639.3158 - val_loss: 15279859.3250\n",
            "Epoch 297/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1927462.4102 - val_loss: 15330672.7375\n",
            "Epoch 298/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1993116.0080 - val_loss: 15525704.7875\n",
            "Epoch 299/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2556677.6974 - val_loss: 16622946.2719\n",
            "Epoch 300/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1913665.6218 - val_loss: 15142150.3250\n",
            "Epoch 301/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3354289.9319 - val_loss: 15308593.7250\n",
            "Epoch 302/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1843288.4607 - val_loss: 15493216.4500\n",
            "Epoch 303/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1664839.3066 - val_loss: 15298959.7250\n",
            "Epoch 304/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1557178.5261 - val_loss: 15241513.1750\n",
            "Epoch 305/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1612337.8567 - val_loss: 15310866.4125\n",
            "Epoch 306/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2243649.7226 - val_loss: 15595610.4625\n",
            "Epoch 307/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2071291.1469 - val_loss: 15242445.2000\n",
            "Epoch 308/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2276283.3539 - val_loss: 15683687.2875\n",
            "Epoch 309/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1571694.3451 - val_loss: 15456673.4500\n",
            "Epoch 310/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2322032.2947 - val_loss: 15582595.2125\n",
            "Epoch 311/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2442110.0187 - val_loss: 15376039.6000\n",
            "Epoch 312/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1723981.4073 - val_loss: 15308346.2750\n",
            "Epoch 313/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1403958.4037 - val_loss: 15332571.3250\n",
            "Epoch 314/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1975746.4016 - val_loss: 15264796.2375\n",
            "Epoch 315/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3413444.5889 - val_loss: 15433729.8000\n",
            "Epoch 316/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2228214.8278 - val_loss: 15364053.1125\n",
            "Epoch 317/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1827408.3908 - val_loss: 15290373.0500\n",
            "Epoch 318/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1846688.6821 - val_loss: 15514790.0125\n",
            "Epoch 319/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1570503.5523 - val_loss: 15310718.4000\n",
            "Epoch 320/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1474487.8550 - val_loss: 15395686.5625\n",
            "Epoch 321/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1329231.5341 - val_loss: 15369541.3750\n",
            "Epoch 322/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1613858.9707 - val_loss: 15558952.2375\n",
            "Epoch 323/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1443206.9365 - val_loss: 15545546.2750\n",
            "Epoch 324/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2730993.7653 - val_loss: 15593908.2000\n",
            "Epoch 325/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3854614.7556 - val_loss: 15494054.0125\n",
            "Epoch 326/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4249542.2842 - val_loss: 15579254.0000\n",
            "Epoch 327/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3204487.3399 - val_loss: 15261955.2625\n",
            "Epoch 328/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1939298.7266 - val_loss: 15241628.7375\n",
            "Epoch 329/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2090378.3925 - val_loss: 15149789.5750\n",
            "Epoch 330/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1997879.7476 - val_loss: 15306250.4500\n",
            "Epoch 331/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1724167.9551 - val_loss: 15292707.8000\n",
            "Epoch 332/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2233306.6420 - val_loss: 15548160.4375\n",
            "Epoch 333/2048\n",
            "90/90 [==============================] - 0s 3ms/step - loss: 2394982.5386 - val_loss: 15409614.9875\n",
            "Epoch 334/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1988640.3696 - val_loss: 15265831.5625\n",
            "Epoch 335/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1873399.2404 - val_loss: 15418493.9375\n",
            "Epoch 336/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1535816.4030 - val_loss: 15229899.4500\n",
            "Epoch 337/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1655173.3310 - val_loss: 15301843.1500\n",
            "Epoch 338/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1571475.3052 - val_loss: 15370812.4750\n",
            "Epoch 339/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1430115.1184 - val_loss: 15469348.0750\n",
            "Epoch 340/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1483098.1603 - val_loss: 15320905.1250\n",
            "Epoch 341/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1595898.9870 - val_loss: 15334783.3875\n",
            "Epoch 342/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1616366.0413 - val_loss: 15560492.7750\n",
            "Epoch 343/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1494878.6101 - val_loss: 15410116.8750\n",
            "Epoch 344/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1837479.0140 - val_loss: 15399001.0000\n",
            "Epoch 345/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1388025.6048 - val_loss: 15641630.6813\n",
            "Epoch 346/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1427463.9660 - val_loss: 15379563.7875\n",
            "Epoch 347/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3331081.0172 - val_loss: 15719114.1937\n",
            "Epoch 348/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1677344.3300 - val_loss: 15518860.4750\n",
            "Epoch 349/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1361814.0911 - val_loss: 15252412.8750\n",
            "Epoch 350/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1397430.8362 - val_loss: 15264089.0250\n",
            "Epoch 351/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2473807.6541 - val_loss: 16056723.2562\n",
            "Epoch 352/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2022762.9510 - val_loss: 15595966.9250\n",
            "Epoch 353/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1976496.9300 - val_loss: 15817182.5437\n",
            "Epoch 354/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1973967.8581 - val_loss: 15420285.9750\n",
            "Epoch 355/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1636968.4879 - val_loss: 15451633.6500\n",
            "Epoch 356/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1329169.7876 - val_loss: 15344669.7875\n",
            "Epoch 357/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1551154.4331 - val_loss: 15691791.8750\n",
            "Epoch 358/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1679181.2736 - val_loss: 15534149.4625\n",
            "Epoch 359/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2932210.4746 - val_loss: 15727484.0813\n",
            "Epoch 360/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2125056.6334 - val_loss: 15333566.1750\n",
            "Epoch 361/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1497215.4518 - val_loss: 15344909.6500\n",
            "Epoch 362/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1334889.1533 - val_loss: 15594034.9500\n",
            "Epoch 363/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3681582.8633 - val_loss: 15672842.9563\n",
            "Epoch 364/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2914450.1632 - val_loss: 15716318.8313\n",
            "Epoch 365/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1766527.2864 - val_loss: 15511760.3500\n",
            "Epoch 366/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1634766.1162 - val_loss: 15434222.8125\n",
            "Epoch 367/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2096861.0265 - val_loss: 15257011.5750\n",
            "Epoch 368/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1648118.2785 - val_loss: 15285453.7250\n",
            "Epoch 369/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1513832.2281 - val_loss: 15253022.5500\n",
            "Epoch 370/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1398442.8499 - val_loss: 15462897.3000\n",
            "Epoch 371/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1772783.4234 - val_loss: 15274840.2000\n",
            "Epoch 372/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2207818.8787 - val_loss: 15360358.3375\n",
            "Epoch 373/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1536217.5471 - val_loss: 15541570.5000\n",
            "Epoch 374/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1907744.2054 - val_loss: 15438336.4500\n",
            "Epoch 375/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2141046.3557 - val_loss: 15321450.5500\n",
            "Epoch 376/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3153726.1452 - val_loss: 15441650.3500\n",
            "Epoch 377/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1742102.9007 - val_loss: 15461229.5250\n",
            "Epoch 378/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1565830.2040 - val_loss: 15472314.2375\n",
            "Epoch 379/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1534562.2089 - val_loss: 15525874.5875\n",
            "Epoch 380/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2848389.4851 - val_loss: 15476794.8375\n",
            "Epoch 381/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2140686.8151 - val_loss: 15339758.5750\n",
            "Epoch 382/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1748079.1435 - val_loss: 15447540.0250\n",
            "Epoch 383/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2217884.4655 - val_loss: 15441907.5375\n",
            "Epoch 384/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2896221.8721 - val_loss: 15757412.0250\n",
            "Epoch 385/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1467132.4284 - val_loss: 15439668.5000\n",
            "Epoch 386/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1569574.9884 - val_loss: 15612353.5875\n",
            "Epoch 387/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1608477.5781 - val_loss: 15447148.3250\n",
            "Epoch 388/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1833218.1365 - val_loss: 15582831.8625\n",
            "Epoch 389/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1786048.4557 - val_loss: 15530003.9875\n",
            "Epoch 390/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3026739.7292 - val_loss: 15471743.6250\n",
            "Epoch 391/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1998696.3799 - val_loss: 15452129.1250\n",
            "Epoch 392/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1829774.1713 - val_loss: 15491864.2250\n",
            "Epoch 393/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1388688.4704 - val_loss: 15449423.5000\n",
            "Epoch 394/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1936853.9385 - val_loss: 15295256.6500\n",
            "Epoch 395/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1666749.0437 - val_loss: 15662672.7000\n",
            "Epoch 396/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2303846.3577 - val_loss: 15918928.7688\n",
            "Epoch 397/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1526685.3874 - val_loss: 15419643.8500\n",
            "Epoch 398/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1246801.7975 - val_loss: 15429948.0875\n",
            "Epoch 399/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1472759.1314 - val_loss: 15407666.2625\n",
            "Epoch 400/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1560954.5715 - val_loss: 15503345.5250\n",
            "Epoch 401/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2149482.7614 - val_loss: 15263796.4750\n",
            "Epoch 402/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4391869.8063 - val_loss: 16317186.7812\n",
            "Epoch 403/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2052013.0185 - val_loss: 15397714.9250\n",
            "Epoch 404/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1798232.0998 - val_loss: 15435521.3250\n",
            "Epoch 405/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1710396.0448 - val_loss: 15280658.8625\n",
            "Epoch 406/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1494621.0505 - val_loss: 15426951.0875\n",
            "Epoch 407/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2780043.5793 - val_loss: 15620935.3125\n",
            "Epoch 408/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2061516.4421 - val_loss: 15445570.0125\n",
            "Epoch 409/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1670347.3284 - val_loss: 15813450.1438\n",
            "Epoch 410/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1653687.2625 - val_loss: 15546177.1750\n",
            "Epoch 411/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2056548.4782 - val_loss: 15542413.4500\n",
            "Epoch 412/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1432676.0977 - val_loss: 15362330.8375\n",
            "Epoch 413/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1541585.0324 - val_loss: 15644511.5813\n",
            "Epoch 414/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2204344.5963 - val_loss: 15836978.9375\n",
            "Epoch 415/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2260452.4525 - val_loss: 15558230.8875\n",
            "Epoch 416/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2790844.5397 - val_loss: 15798124.2125\n",
            "Epoch 417/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1518437.3200 - val_loss: 15536416.4375\n",
            "Epoch 418/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1392745.9162 - val_loss: 15303471.6250\n",
            "Epoch 419/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2193322.0346 - val_loss: 15604015.6750\n",
            "Epoch 420/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1988134.4356 - val_loss: 15820475.2750\n",
            "Epoch 421/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1593294.2702 - val_loss: 15366960.1250\n",
            "Epoch 422/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1830050.5356 - val_loss: 15879083.2250\n",
            "Epoch 423/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1743128.3679 - val_loss: 15357659.1875\n",
            "Epoch 424/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1540526.1168 - val_loss: 15308156.8125\n",
            "Epoch 425/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1425791.8073 - val_loss: 15272913.0750\n",
            "Epoch 426/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2094239.0737 - val_loss: 15773051.0750\n",
            "Epoch 427/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1790868.3284 - val_loss: 15650848.2250\n",
            "Epoch 428/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1888039.0008 - val_loss: 15612537.0000\n",
            "Epoch 429/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1707041.0976 - val_loss: 15434658.5375\n",
            "Epoch 430/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1416304.9821 - val_loss: 15730562.1000\n",
            "Epoch 431/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1763062.6710 - val_loss: 15598827.5750\n",
            "Epoch 432/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2154956.5984 - val_loss: 15295414.6500\n",
            "Epoch 433/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1416718.9986 - val_loss: 15341780.4875\n",
            "Epoch 434/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1628976.2048 - val_loss: 15501808.9375\n",
            "Epoch 435/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1890203.3344 - val_loss: 15307906.2250\n",
            "Epoch 436/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1619390.7334 - val_loss: 15723536.3500\n",
            "Epoch 437/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1714493.7021 - val_loss: 15607244.6000\n",
            "Epoch 438/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1563024.3899 - val_loss: 15493612.2500\n",
            "Epoch 439/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1425272.3343 - val_loss: 15519366.4250\n",
            "Epoch 440/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1297125.4470 - val_loss: 15571185.4125\n",
            "Epoch 441/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1605439.7019 - val_loss: 15625027.0625\n",
            "Epoch 442/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1995644.2293 - val_loss: 15454128.8250\n",
            "Epoch 443/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2096744.5663 - val_loss: 15656531.0750\n",
            "Epoch 444/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1568160.0387 - val_loss: 15727485.7375\n",
            "Epoch 445/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2288374.6656 - val_loss: 15606776.2875\n",
            "Epoch 446/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2060968.4998 - val_loss: 15677812.3812\n",
            "Epoch 447/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1655626.9306 - val_loss: 15668865.1000\n",
            "Epoch 448/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1399400.5975 - val_loss: 15407068.7250\n",
            "Epoch 449/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3451886.4819 - val_loss: 15743225.0125\n",
            "Epoch 450/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2362525.1327 - val_loss: 15735333.1062\n",
            "Epoch 451/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1646039.5737 - val_loss: 15412980.1875\n",
            "Epoch 452/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1624888.4322 - val_loss: 15389029.8500\n",
            "Epoch 453/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1471441.1511 - val_loss: 15368292.8375\n",
            "Epoch 454/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3056391.2031 - val_loss: 19096580.0984\n",
            "Epoch 455/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1519825.7544 - val_loss: 15384056.3750\n",
            "Epoch 456/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2298785.0605 - val_loss: 15495898.5125\n",
            "Epoch 457/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1537553.6954 - val_loss: 15642720.7125\n",
            "Epoch 458/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1499071.5631 - val_loss: 15782515.9000\n",
            "Epoch 459/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1428124.4405 - val_loss: 15366738.1250\n",
            "Epoch 460/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1668275.8764 - val_loss: 15704273.4437\n",
            "Epoch 461/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1442108.2152 - val_loss: 15794394.2625\n",
            "Epoch 462/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1737641.7276 - val_loss: 15564522.9250\n",
            "Epoch 463/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1447123.1715 - val_loss: 15771769.5000\n",
            "Epoch 464/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1581042.7657 - val_loss: 15450867.2750\n",
            "Epoch 465/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1994162.7594 - val_loss: 15538936.7875\n",
            "Epoch 466/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2887282.5196 - val_loss: 15633026.9250\n",
            "Epoch 467/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2693599.5103 - val_loss: 15636234.3750\n",
            "Epoch 468/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2685116.9841 - val_loss: 24385533.1625\n",
            "Epoch 469/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2408828.1863 - val_loss: 15359796.2000\n",
            "Epoch 470/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1798792.7170 - val_loss: 15537248.9625\n",
            "Epoch 471/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1907189.1900 - val_loss: 15414543.7875\n",
            "Epoch 472/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1708467.5702 - val_loss: 15399376.3250\n",
            "Epoch 473/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1691131.4531 - val_loss: 15867323.3063\n",
            "Epoch 474/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1828287.6409 - val_loss: 15848978.8875\n",
            "Epoch 475/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2092550.7585 - val_loss: 15636956.0250\n",
            "Epoch 476/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1966244.8765 - val_loss: 15380326.4500\n",
            "Epoch 477/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2348811.3056 - val_loss: 15512868.7375\n",
            "Epoch 478/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1759173.0128 - val_loss: 15590523.8125\n",
            "Epoch 479/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1809124.0839 - val_loss: 15232574.4000\n",
            "Epoch 480/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1525590.5003 - val_loss: 15396210.5125\n",
            "Epoch 481/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1435515.0312 - val_loss: 15403991.7000\n",
            "Epoch 482/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1304066.7581 - val_loss: 15426152.8000\n",
            "Epoch 483/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1638538.8724 - val_loss: 15705931.1813\n",
            "Epoch 484/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1334260.8931 - val_loss: 15674205.6312\n",
            "Epoch 485/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2126191.7531 - val_loss: 15989144.8375\n",
            "Epoch 486/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1436416.7762 - val_loss: 16251350.9437\n",
            "Epoch 487/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1567618.1447 - val_loss: 15457569.5500\n",
            "Epoch 488/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2207033.8212 - val_loss: 15923208.7250\n",
            "Epoch 489/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4743536.4397 - val_loss: 16742397.3219\n",
            "Epoch 490/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1908068.9611 - val_loss: 15596944.2875\n",
            "Epoch 491/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3552890.4080 - val_loss: 15235260.9000\n",
            "Epoch 492/2048\n",
            "90/90 [==============================] - 0s 3ms/step - loss: 4181717.7333 - val_loss: 27519261.2000\n",
            "Epoch 493/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1952664.0378 - val_loss: 15273674.9000\n",
            "Epoch 494/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1355654.3150 - val_loss: 15472175.6375\n",
            "Epoch 495/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3974721.8960 - val_loss: 15697225.8125\n",
            "Epoch 496/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2248267.4628 - val_loss: 15992527.6750\n",
            "Epoch 497/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2763249.7512 - val_loss: 15566622.5375\n",
            "Epoch 498/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2077235.8124 - val_loss: 15340132.6500\n",
            "Epoch 499/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2984916.1732 - val_loss: 15657821.7625\n",
            "Epoch 500/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1934313.5467 - val_loss: 15557923.7125\n",
            "Epoch 501/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1527070.1536 - val_loss: 15861826.1312\n",
            "Epoch 502/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1920014.6314 - val_loss: 15475808.3125\n",
            "Epoch 503/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1837064.5423 - val_loss: 15449843.7875\n",
            "Epoch 504/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1502193.7243 - val_loss: 15344850.4250\n",
            "Epoch 505/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2471207.1782 - val_loss: 15785195.0375\n",
            "Epoch 506/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3177683.9033 - val_loss: 16063631.9250\n",
            "Epoch 507/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1757248.6670 - val_loss: 15456963.0750\n",
            "Epoch 508/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1723300.1072 - val_loss: 15407925.8875\n",
            "Epoch 509/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2707321.8454 - val_loss: 15916627.2812\n",
            "Epoch 510/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2062728.2910 - val_loss: 15730828.1062\n",
            "Epoch 511/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1961806.6852 - val_loss: 15457767.5750\n",
            "Epoch 512/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1830115.6046 - val_loss: 15645567.1625\n",
            "Epoch 513/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2521194.6673 - val_loss: 15542866.8000\n",
            "Epoch 514/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2802589.4840 - val_loss: 15451056.0250\n",
            "Epoch 515/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1562387.2912 - val_loss: 15535327.4750\n",
            "Epoch 516/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1364787.2753 - val_loss: 15439715.1250\n",
            "Epoch 517/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1522735.2260 - val_loss: 15515694.1250\n",
            "Epoch 518/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2592912.5289 - val_loss: 15681569.0813\n",
            "Epoch 519/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2041994.2701 - val_loss: 15451133.3375\n",
            "Epoch 520/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1615524.6413 - val_loss: 15948864.0875\n",
            "Epoch 521/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1620978.2335 - val_loss: 15760668.5062\n",
            "Epoch 522/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2015755.9252 - val_loss: 15532299.1500\n",
            "Epoch 523/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1385999.0105 - val_loss: 15620152.1375\n",
            "Epoch 524/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1419446.4732 - val_loss: 15576388.0875\n",
            "Epoch 525/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1331936.9473 - val_loss: 15704358.1937\n",
            "Epoch 526/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1277742.7011 - val_loss: 15430875.6875\n",
            "Epoch 527/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1291830.1073 - val_loss: 15654360.1125\n",
            "Epoch 528/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1463320.0109 - val_loss: 15661684.9625\n",
            "Epoch 529/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3066201.6056 - val_loss: 15801993.4000\n",
            "Epoch 530/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1983525.0054 - val_loss: 15729586.6625\n",
            "Epoch 531/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1611114.0816 - val_loss: 15543319.5000\n",
            "Epoch 532/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3658835.2090 - val_loss: 15854725.5250\n",
            "Epoch 533/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2029880.0823 - val_loss: 15554743.2875\n",
            "Epoch 534/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2917083.6805 - val_loss: 15318200.2625\n",
            "Epoch 535/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1275318.2982 - val_loss: 15559425.2000\n",
            "Epoch 536/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1453089.7324 - val_loss: 15587695.0000\n",
            "Epoch 537/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1313244.3768 - val_loss: 15369822.2750\n",
            "Epoch 538/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1927780.6141 - val_loss: 15707971.8500\n",
            "Epoch 539/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1521624.0486 - val_loss: 15882920.0938\n",
            "Epoch 540/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1459290.2407 - val_loss: 15623248.9500\n",
            "Epoch 541/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1739453.0849 - val_loss: 15604091.9125\n",
            "Epoch 542/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1360302.3420 - val_loss: 15609705.3125\n",
            "Epoch 543/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1221713.4622 - val_loss: 15657017.7625\n",
            "Epoch 544/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1307825.5599 - val_loss: 15458039.0125\n",
            "Epoch 545/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1780505.4986 - val_loss: 15908154.7000\n",
            "Epoch 546/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1964273.7508 - val_loss: 15461893.8125\n",
            "Epoch 547/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1516060.1363 - val_loss: 15619778.0875\n",
            "Epoch 548/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1319256.2052 - val_loss: 15804744.4688\n",
            "Epoch 549/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1538580.5562 - val_loss: 15743339.9938\n",
            "Epoch 550/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3395994.3109 - val_loss: 15643953.6250\n",
            "Epoch 551/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3648921.5402 - val_loss: 16318810.5594\n",
            "Epoch 552/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2479386.3862 - val_loss: 15560123.6125\n",
            "Epoch 553/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1351610.6811 - val_loss: 15449704.8875\n",
            "Epoch 554/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1750430.7638 - val_loss: 15662789.9062\n",
            "Epoch 555/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1664359.5877 - val_loss: 15371433.8500\n",
            "Epoch 556/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1330119.2234 - val_loss: 15846468.4812\n",
            "Epoch 557/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1531095.9945 - val_loss: 15413123.2750\n",
            "Epoch 558/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1616602.0855 - val_loss: 15449851.4250\n",
            "Epoch 559/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2419915.8476 - val_loss: 16012964.0563\n",
            "Epoch 560/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1408777.9061 - val_loss: 15519165.0625\n",
            "Epoch 561/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1212423.9593 - val_loss: 15447260.2000\n",
            "Epoch 562/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1219854.3077 - val_loss: 15682481.9688\n",
            "Epoch 563/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1336771.2195 - val_loss: 15459114.1000\n",
            "Epoch 564/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1841439.1650 - val_loss: 15849830.7250\n",
            "Epoch 565/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2755176.3663 - val_loss: 15760404.7438\n",
            "Epoch 566/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2243221.3036 - val_loss: 15799890.5875\n",
            "Epoch 567/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1980807.9255 - val_loss: 15521233.2250\n",
            "Epoch 568/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1533246.1046 - val_loss: 15707621.7125\n",
            "Epoch 569/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1425635.7862 - val_loss: 15817812.9187\n",
            "Epoch 570/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1258016.9210 - val_loss: 15584430.6250\n",
            "Epoch 571/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2808202.2083 - val_loss: 15539869.1000\n",
            "Epoch 572/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1542339.3367 - val_loss: 15383693.1375\n",
            "Epoch 573/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2105046.1119 - val_loss: 15468067.2125\n",
            "Epoch 574/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1755121.8826 - val_loss: 15636502.1500\n",
            "Epoch 575/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2092021.3610 - val_loss: 15778920.5188\n",
            "Epoch 576/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1714631.5573 - val_loss: 15331123.8625\n",
            "Epoch 577/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1277075.4347 - val_loss: 15672461.1062\n",
            "Epoch 578/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1374058.7234 - val_loss: 15411003.0750\n",
            "Epoch 579/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1777460.1445 - val_loss: 15876101.1375\n",
            "Epoch 580/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1938991.4369 - val_loss: 15724237.8938\n",
            "Epoch 581/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1530544.8850 - val_loss: 15648967.2250\n",
            "Epoch 582/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1517858.5223 - val_loss: 15726950.9000\n",
            "Epoch 583/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1185301.0991 - val_loss: 15535522.9875\n",
            "Epoch 584/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2427769.6271 - val_loss: 15803597.4125\n",
            "Epoch 585/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1987959.8582 - val_loss: 15626972.1125\n",
            "Epoch 586/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2429684.7971 - val_loss: 15749774.2750\n",
            "Epoch 587/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2166616.2554 - val_loss: 15535433.1250\n",
            "Epoch 588/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1916470.1021 - val_loss: 15535517.3125\n",
            "Epoch 589/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1144486.2403 - val_loss: 15715192.2688\n",
            "Epoch 590/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2638697.0168 - val_loss: 15748707.2812\n",
            "Epoch 591/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1434960.6016 - val_loss: 15623680.8625\n",
            "Epoch 592/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1680050.4405 - val_loss: 15542396.7750\n",
            "Epoch 593/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1556988.2067 - val_loss: 15738539.4062\n",
            "Epoch 594/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1387844.1531 - val_loss: 15647108.5625\n",
            "Epoch 595/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1200013.1576 - val_loss: 15716092.0250\n",
            "Epoch 596/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1483647.5101 - val_loss: 15763135.9125\n",
            "Epoch 597/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1362943.3985 - val_loss: 15472760.0125\n",
            "Epoch 598/2048\n",
            "90/90 [==============================] - 0s 3ms/step - loss: 1634784.8595 - val_loss: 15672604.7750\n",
            "Epoch 599/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1529682.7603 - val_loss: 15695264.1000\n",
            "Epoch 600/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1552563.5582 - val_loss: 15449671.1875\n",
            "Epoch 601/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2413040.8851 - val_loss: 15579735.9250\n",
            "Epoch 602/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1728906.9861 - val_loss: 15709538.0312\n",
            "Epoch 603/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1193059.9814 - val_loss: 15566124.9750\n",
            "Epoch 604/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1173407.5830 - val_loss: 16137943.4812\n",
            "Epoch 605/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1217683.3893 - val_loss: 15590226.7125\n",
            "Epoch 606/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1980162.9446 - val_loss: 15653461.2000\n",
            "Epoch 607/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2680667.0643 - val_loss: 15664312.3625\n",
            "Epoch 608/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1294693.6362 - val_loss: 15545500.2750\n",
            "Epoch 609/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1242799.3547 - val_loss: 15706837.4750\n",
            "Epoch 610/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3962534.5608 - val_loss: 15982710.8625\n",
            "Epoch 611/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1465427.4238 - val_loss: 15853755.7750\n",
            "Epoch 612/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1293777.8820 - val_loss: 15735620.2125\n",
            "Epoch 613/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1958914.3402 - val_loss: 15986650.8125\n",
            "Epoch 614/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1939627.3221 - val_loss: 15713076.2937\n",
            "Epoch 615/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1610710.8082 - val_loss: 15967301.3688\n",
            "Epoch 616/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1652872.7439 - val_loss: 16028514.3562\n",
            "Epoch 617/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1444764.4289 - val_loss: 15636487.5625\n",
            "Epoch 618/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1401066.2871 - val_loss: 15422407.5000\n",
            "Epoch 619/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1150444.7907 - val_loss: 15774829.8438\n",
            "Epoch 620/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1156873.1576 - val_loss: 15847740.0500\n",
            "Epoch 621/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1482937.4612 - val_loss: 16004915.0563\n",
            "Epoch 622/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1365377.8106 - val_loss: 15739775.3562\n",
            "Epoch 623/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1200155.7784 - val_loss: 15616831.2750\n",
            "Epoch 624/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1184552.6702 - val_loss: 15633476.3250\n",
            "Epoch 625/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1405884.9208 - val_loss: 15819502.5500\n",
            "Epoch 626/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1163143.1428 - val_loss: 15669882.2875\n",
            "Epoch 627/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1213869.6085 - val_loss: 15717685.9750\n",
            "Epoch 628/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1525418.5994 - val_loss: 15581408.9125\n",
            "Epoch 629/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1874692.5024 - val_loss: 15647802.5250\n",
            "Epoch 630/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1961728.6752 - val_loss: 15524420.5500\n",
            "Epoch 631/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1919958.2019 - val_loss: 15953197.5375\n",
            "Epoch 632/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1807402.1134 - val_loss: 16146193.2312\n",
            "Epoch 633/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2240408.7684 - val_loss: 15676425.1250\n",
            "Epoch 634/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1273568.7906 - val_loss: 15903834.5062\n",
            "Epoch 635/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1133017.9781 - val_loss: 15992924.5375\n",
            "Epoch 636/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1265721.6862 - val_loss: 15573681.4125\n",
            "Epoch 637/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1568034.7556 - val_loss: 15829821.2000\n",
            "Epoch 638/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1861544.0883 - val_loss: 15622544.7500\n",
            "Epoch 639/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1225681.3833 - val_loss: 15884504.5188\n",
            "Epoch 640/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1372593.6340 - val_loss: 15878083.7375\n",
            "Epoch 641/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2011849.5765 - val_loss: 15835607.1125\n",
            "Epoch 642/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2183652.6360 - val_loss: 15754607.3313\n",
            "Epoch 643/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1190971.7735 - val_loss: 15876774.2000\n",
            "Epoch 644/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1120842.4171 - val_loss: 15772555.2188\n",
            "Epoch 645/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1744470.5259 - val_loss: 15809999.9437\n",
            "Epoch 646/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1235053.8788 - val_loss: 16180280.2812\n",
            "Epoch 647/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1203510.8847 - val_loss: 15665563.0375\n",
            "Epoch 648/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1560551.3123 - val_loss: 15792231.2438\n",
            "Epoch 649/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1202344.6898 - val_loss: 15351819.5500\n",
            "Epoch 650/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2043083.9268 - val_loss: 15826390.4750\n",
            "Epoch 651/2048\n",
            "90/90 [==============================] - 0s 3ms/step - loss: 2260918.1297 - val_loss: 16409481.9750\n",
            "Epoch 652/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1802176.6134 - val_loss: 16105095.3750\n",
            "Epoch 653/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1827354.6689 - val_loss: 15975464.5938\n",
            "Epoch 654/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1386551.6095 - val_loss: 15918712.0188\n",
            "Epoch 655/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1447753.9648 - val_loss: 15771309.7000\n",
            "Epoch 656/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2207442.7047 - val_loss: 15740902.9625\n",
            "Epoch 657/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1728341.5797 - val_loss: 16097049.8438\n",
            "Epoch 658/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1548156.2517 - val_loss: 16202085.3625\n",
            "Epoch 659/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2452180.4357 - val_loss: 15617350.7375\n",
            "Epoch 660/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2286739.6146 - val_loss: 15855181.6188\n",
            "Epoch 661/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1353032.6325 - val_loss: 15669771.2625\n",
            "Epoch 662/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1283677.7535 - val_loss: 15535532.3125\n",
            "Epoch 663/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2340437.0937 - val_loss: 15788623.0437\n",
            "Epoch 664/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1459262.7939 - val_loss: 15681628.1625\n",
            "Epoch 665/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1576149.4053 - val_loss: 15893719.9812\n",
            "Epoch 666/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1566073.8605 - val_loss: 15840283.1500\n",
            "Epoch 667/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1717559.6703 - val_loss: 15552030.8750\n",
            "Epoch 668/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1560146.9947 - val_loss: 15649731.4500\n",
            "Epoch 669/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1320343.1977 - val_loss: 15849688.9625\n",
            "Epoch 670/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2101476.5730 - val_loss: 16261935.3125\n",
            "Epoch 671/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1185263.3711 - val_loss: 15678292.6000\n",
            "Epoch 672/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1221694.2490 - val_loss: 15944951.2000\n",
            "Epoch 673/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1452464.5431 - val_loss: 15876240.7125\n",
            "Epoch 674/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2405504.3961 - val_loss: 16060284.2812\n",
            "Epoch 675/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1197448.6693 - val_loss: 15872915.6937\n",
            "Epoch 676/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1194040.8139 - val_loss: 15997953.1375\n",
            "Epoch 677/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1201951.8335 - val_loss: 15803193.1438\n",
            "Epoch 678/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1832344.3276 - val_loss: 15856966.3125\n",
            "Epoch 679/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1239137.0929 - val_loss: 15672896.5250\n",
            "Epoch 680/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1296714.4134 - val_loss: 15827658.7188\n",
            "Epoch 681/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1401817.5341 - val_loss: 16211437.3625\n",
            "Epoch 682/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1478286.8561 - val_loss: 16361674.9531\n",
            "Epoch 683/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1387633.9979 - val_loss: 16107825.6312\n",
            "Epoch 684/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1939407.9911 - val_loss: 16042627.5563\n",
            "Epoch 685/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1601818.0783 - val_loss: 15896594.2000\n",
            "Epoch 686/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1664533.0155 - val_loss: 16422837.7438\n",
            "Epoch 687/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1686484.9668 - val_loss: 16117052.4000\n",
            "Epoch 688/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1388516.2432 - val_loss: 15979150.2250\n",
            "Epoch 689/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1994184.4124 - val_loss: 15927400.8750\n",
            "Epoch 690/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1288445.0249 - val_loss: 15562357.8500\n",
            "Epoch 691/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1327494.3691 - val_loss: 15750686.1687\n",
            "Epoch 692/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1030632.3637 - val_loss: 16016358.9437\n",
            "Epoch 693/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1606022.9021 - val_loss: 15896479.3625\n",
            "Epoch 694/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2403606.8438 - val_loss: 15583700.7875\n",
            "Epoch 695/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1470018.0204 - val_loss: 16004957.2812\n",
            "Epoch 696/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4171499.3377 - val_loss: 15369375.0750\n",
            "Epoch 697/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1967668.2493 - val_loss: 15986379.9688\n",
            "Epoch 698/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1494278.6675 - val_loss: 15999599.1188\n",
            "Epoch 699/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1192932.4740 - val_loss: 15953113.0500\n",
            "Epoch 700/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1658836.9533 - val_loss: 16006302.7312\n",
            "Epoch 701/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1325801.2540 - val_loss: 16172084.6687\n",
            "Epoch 702/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1350983.8961 - val_loss: 15972229.3063\n",
            "Epoch 703/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1146616.5876 - val_loss: 16073013.1250\n",
            "Epoch 704/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1307893.9774 - val_loss: 15514046.7125\n",
            "Epoch 705/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2121812.4212 - val_loss: 16166359.8750\n",
            "Epoch 706/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1721978.4602 - val_loss: 15577079.4625\n",
            "Epoch 707/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1957986.6089 - val_loss: 15729125.7750\n",
            "Epoch 708/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3803680.3943 - val_loss: 15384814.4375\n",
            "Epoch 709/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1543737.3371 - val_loss: 15696454.6875\n",
            "Epoch 710/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1216599.3319 - val_loss: 16009339.4938\n",
            "Epoch 711/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1112234.8281 - val_loss: 15701516.4375\n",
            "Epoch 712/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1341051.3150 - val_loss: 15865574.0312\n",
            "Epoch 713/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1146337.5153 - val_loss: 16089393.2312\n",
            "Epoch 714/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1045577.0542 - val_loss: 15694592.0250\n",
            "Epoch 715/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1228907.0259 - val_loss: 15911991.6188\n",
            "Epoch 716/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1324282.1161 - val_loss: 15793732.0563\n",
            "Epoch 717/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1874075.4366 - val_loss: 16306111.5844\n",
            "Epoch 718/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1074175.0194 - val_loss: 15938912.1875\n",
            "Epoch 719/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1174528.6667 - val_loss: 16205967.4563\n",
            "Epoch 720/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1808029.3195 - val_loss: 15913520.7812\n",
            "Epoch 721/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4351468.5527 - val_loss: 15724885.6250\n",
            "Epoch 722/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2749085.1005 - val_loss: 16124862.9688\n",
            "Epoch 723/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1218632.3102 - val_loss: 15914666.7875\n",
            "Epoch 724/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1105468.9354 - val_loss: 16208994.2250\n",
            "Epoch 725/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1283015.2176 - val_loss: 16037982.0813\n",
            "Epoch 726/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1142723.6816 - val_loss: 15527935.0375\n",
            "Epoch 727/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1486224.7274 - val_loss: 16031072.0625\n",
            "Epoch 728/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1551874.4599 - val_loss: 15926384.1312\n",
            "Epoch 729/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1792905.5615 - val_loss: 15965201.8500\n",
            "Epoch 730/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1302860.0518 - val_loss: 16131580.3187\n",
            "Epoch 731/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1169056.3886 - val_loss: 15695948.1625\n",
            "Epoch 732/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1147074.7054 - val_loss: 16343568.0563\n",
            "Epoch 733/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1006283.2263 - val_loss: 15948339.8375\n",
            "Epoch 734/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1005866.1896 - val_loss: 16167454.2125\n",
            "Epoch 735/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2530059.4189 - val_loss: 16671473.1297\n",
            "Epoch 736/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1878916.8406 - val_loss: 16423495.4000\n",
            "Epoch 737/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1110037.6628 - val_loss: 16172755.0188\n",
            "Epoch 738/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3179446.5068 - val_loss: 16230076.5375\n",
            "Epoch 739/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1718685.3441 - val_loss: 16351408.9781\n",
            "Epoch 740/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1597345.3690 - val_loss: 15985781.1813\n",
            "Epoch 741/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2522628.5252 - val_loss: 15963957.7812\n",
            "Epoch 742/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2004860.8697 - val_loss: 16338132.3812\n",
            "Epoch 743/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1727105.4443 - val_loss: 15257780.5500\n",
            "Epoch 744/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2012947.9187 - val_loss: 17436101.7352\n",
            "Epoch 745/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1639285.7380 - val_loss: 16059048.1312\n",
            "Epoch 746/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1341580.4219 - val_loss: 15929936.3187\n",
            "Epoch 747/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2266344.0868 - val_loss: 15621728.3250\n",
            "Epoch 748/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1215665.8980 - val_loss: 15381304.2500\n",
            "Epoch 749/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1153179.8691 - val_loss: 16008973.5250\n",
            "Epoch 750/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1255575.8734 - val_loss: 16211676.3438\n",
            "Epoch 751/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1083691.8332 - val_loss: 15930706.9812\n",
            "Epoch 752/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1902568.8701 - val_loss: 15909428.9563\n",
            "Epoch 753/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1090246.3629 - val_loss: 15793225.1500\n",
            "Epoch 754/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1113150.0988 - val_loss: 16241725.7875\n",
            "Epoch 755/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1003719.4239 - val_loss: 15701985.0875\n",
            "Epoch 756/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1134904.1501 - val_loss: 15608529.5375\n",
            "Epoch 757/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1747926.3544 - val_loss: 16852739.9312\n",
            "Epoch 758/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1555268.6837 - val_loss: 15541219.5625\n",
            "Epoch 759/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1163062.1084 - val_loss: 16212215.2688\n",
            "Epoch 760/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1576434.2524 - val_loss: 16048395.6750\n",
            "Epoch 761/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1401975.5535 - val_loss: 16170470.2875\n",
            "Epoch 762/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1997872.5256 - val_loss: 16780463.6281\n",
            "Epoch 763/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1394753.8654 - val_loss: 15991198.0375\n",
            "Epoch 764/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1293267.8161 - val_loss: 16380920.1687\n",
            "Epoch 765/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1095600.3215 - val_loss: 16015139.6438\n",
            "Epoch 766/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1326431.1193 - val_loss: 15300437.3250\n",
            "Epoch 767/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1646314.8680 - val_loss: 16112090.6062\n",
            "Epoch 768/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1157479.3173 - val_loss: 16095187.6750\n",
            "Epoch 769/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1517405.2408 - val_loss: 16525346.7219\n",
            "Epoch 770/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1165620.7446 - val_loss: 15888307.4437\n",
            "Epoch 771/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1380704.7922 - val_loss: 16395946.8969\n",
            "Epoch 772/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1531662.3493 - val_loss: 15812567.1500\n",
            "Epoch 773/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1280267.8809 - val_loss: 15843061.1625\n",
            "Epoch 774/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1113923.8854 - val_loss: 16399299.2188\n",
            "Epoch 775/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1499772.5572 - val_loss: 15868522.7562\n",
            "Epoch 776/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1879711.9583 - val_loss: 16537308.3438\n",
            "Epoch 777/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1688648.4471 - val_loss: 16069907.3562\n",
            "Epoch 778/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1559207.7907 - val_loss: 15867641.9000\n",
            "Epoch 779/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1967200.6427 - val_loss: 16344684.0250\n",
            "Epoch 780/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1029772.4347 - val_loss: 16714211.7391\n",
            "Epoch 781/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1810585.9157 - val_loss: 16526720.3125\n",
            "Epoch 782/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1192516.4200 - val_loss: 16708951.0062\n",
            "Epoch 783/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1909919.5624 - val_loss: 16184907.2562\n",
            "Epoch 784/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 923066.5612 - val_loss: 16205058.6750\n",
            "Epoch 785/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1013544.0397 - val_loss: 16063280.8000\n",
            "Epoch 786/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1110027.2700 - val_loss: 16297069.9344\n",
            "Epoch 787/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 888753.4108 - val_loss: 16130390.9750\n",
            "Epoch 788/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1047583.1867 - val_loss: 16927409.9187\n",
            "Epoch 789/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1020756.4846 - val_loss: 15990686.9375\n",
            "Epoch 790/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1005277.8541 - val_loss: 16588988.2219\n",
            "Epoch 791/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 5163858.8054 - val_loss: 28789963.5000\n",
            "Epoch 792/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3164854.6308 - val_loss: 15780495.3313\n",
            "Epoch 793/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 5842587.9180 - val_loss: 17334040.5785\n",
            "Epoch 794/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1243677.1040 - val_loss: 15472070.1750\n",
            "Epoch 795/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1174684.2360 - val_loss: 16299254.6000\n",
            "Epoch 796/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1062857.1923 - val_loss: 16288222.6000\n",
            "Epoch 797/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1056771.7004 - val_loss: 16108174.9688\n",
            "Epoch 798/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1010713.0255 - val_loss: 16216755.4375\n",
            "Epoch 799/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1213864.5486 - val_loss: 16563508.8281\n",
            "Epoch 800/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1036923.0615 - val_loss: 15968298.7875\n",
            "Epoch 801/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2255260.0386 - val_loss: 16096024.4688\n",
            "Epoch 802/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2889086.5017 - val_loss: 15858138.3500\n",
            "Epoch 803/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1516466.3712 - val_loss: 16024273.8562\n",
            "Epoch 804/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1675879.4985 - val_loss: 16168163.0062\n",
            "Epoch 805/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2017793.7283 - val_loss: 15814822.8812\n",
            "Epoch 806/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1078363.2268 - val_loss: 16173199.6188\n",
            "Epoch 807/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1167181.9219 - val_loss: 16611788.7188\n",
            "Epoch 808/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1009753.2605 - val_loss: 15943431.5500\n",
            "Epoch 809/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 976399.5140 - val_loss: 16413290.3344\n",
            "Epoch 810/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 902009.5595 - val_loss: 15805924.4437\n",
            "Epoch 811/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 927959.9431 - val_loss: 16219384.4750\n",
            "Epoch 812/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1101974.5186 - val_loss: 16343129.8187\n",
            "Epoch 813/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1056803.1342 - val_loss: 16157153.9938\n",
            "Epoch 814/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1094891.8989 - val_loss: 16334207.1656\n",
            "Epoch 815/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1218701.6313 - val_loss: 16189435.6500\n",
            "Epoch 816/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1130099.7384 - val_loss: 16534180.7750\n",
            "Epoch 817/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1419416.7030 - val_loss: 16573616.5375\n",
            "Epoch 818/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1448930.4103 - val_loss: 16726668.5047\n",
            "Epoch 819/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1657122.3809 - val_loss: 16244770.3625\n",
            "Epoch 820/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1149795.6431 - val_loss: 16806618.0500\n",
            "Epoch 821/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1833297.0009 - val_loss: 15840553.5875\n",
            "Epoch 822/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1606420.7267 - val_loss: 16494119.0250\n",
            "Epoch 823/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1866764.6139 - val_loss: 16798679.6891\n",
            "Epoch 824/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1094583.4947 - val_loss: 15920633.0563\n",
            "Epoch 825/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2120306.9808 - val_loss: 16548386.6000\n",
            "Epoch 826/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1003430.2942 - val_loss: 16495490.8063\n",
            "Epoch 827/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 815144.1106 - val_loss: 15826460.7750\n",
            "Epoch 828/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 821969.3467 - val_loss: 16224906.5500\n",
            "Epoch 829/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 989426.2472 - val_loss: 16558067.0500\n",
            "Epoch 830/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1401544.6198 - val_loss: 16202691.2688\n",
            "Epoch 831/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1123678.0310 - val_loss: 16092782.8500\n",
            "Epoch 832/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 935018.8306 - val_loss: 17255327.4992\n",
            "Epoch 833/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 995485.0390 - val_loss: 16278492.6875\n",
            "Epoch 834/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1180622.8022 - val_loss: 16351680.5813\n",
            "Epoch 835/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1525964.7228 - val_loss: 17064593.4094\n",
            "Epoch 836/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1095236.9001 - val_loss: 16599409.4594\n",
            "Epoch 837/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1283599.4629 - val_loss: 16535170.2469\n",
            "Epoch 838/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1104988.6995 - val_loss: 16704422.4688\n",
            "Epoch 839/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 795708.1233 - val_loss: 16502916.3469\n",
            "Epoch 840/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1152608.3417 - val_loss: 16851828.7875\n",
            "Epoch 841/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1753487.7441 - val_loss: 16461036.0594\n",
            "Epoch 842/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1241469.2223 - val_loss: 16270545.4875\n",
            "Epoch 843/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1297565.4667 - val_loss: 17719753.3535\n",
            "Epoch 844/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1040626.5418 - val_loss: 16874497.5266\n",
            "Epoch 845/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1558665.9841 - val_loss: 16765867.6125\n",
            "Epoch 846/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1468606.3311 - val_loss: 16440896.1625\n",
            "Epoch 847/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 834866.8222 - val_loss: 16305045.8125\n",
            "Epoch 848/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1071124.4419 - val_loss: 16631246.1094\n",
            "Epoch 849/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1466792.4240 - val_loss: 17559827.7059\n",
            "Epoch 850/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1063516.9881 - val_loss: 16508695.8344\n",
            "Epoch 851/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1903469.0761 - val_loss: 17842206.3811\n",
            "Epoch 852/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1915870.0520 - val_loss: 16256444.5000\n",
            "Epoch 853/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1654075.7243 - val_loss: 16865951.2844\n",
            "Epoch 854/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3092462.4045 - val_loss: 17094986.6766\n",
            "Epoch 855/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1247426.4601 - val_loss: 15830282.2000\n",
            "Epoch 856/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 998666.2919 - val_loss: 17045029.1539\n",
            "Epoch 857/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1430402.8216 - val_loss: 16669368.2000\n",
            "Epoch 858/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 879525.8748 - val_loss: 16511544.0375\n",
            "Epoch 859/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1273940.0950 - val_loss: 16997428.9750\n",
            "Epoch 860/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1302699.5360 - val_loss: 16402299.6500\n",
            "Epoch 861/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 836188.7324 - val_loss: 16999895.2422\n",
            "Epoch 862/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 864655.8955 - val_loss: 17207666.2078\n",
            "Epoch 863/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1216750.1316 - val_loss: 17397583.3641\n",
            "Epoch 864/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1439714.5977 - val_loss: 16103155.3313\n",
            "Epoch 865/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2192300.8152 - val_loss: 17788427.9640\n",
            "Epoch 866/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2170187.0837 - val_loss: 16099917.7000\n",
            "Epoch 867/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1759706.9271 - val_loss: 17055627.6812\n",
            "Epoch 868/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1179460.0546 - val_loss: 17531672.7395\n",
            "Epoch 869/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 954349.9412 - val_loss: 17056260.2266\n",
            "Epoch 870/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1217895.2133 - val_loss: 17237398.9016\n",
            "Epoch 871/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 864831.4487 - val_loss: 16330220.4812\n",
            "Epoch 872/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 810253.7382 - val_loss: 17149125.2461\n",
            "Epoch 873/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1324358.9788 - val_loss: 17169536.2797\n",
            "Epoch 874/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 970576.2959 - val_loss: 17537078.9098\n",
            "Epoch 875/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 869860.1145 - val_loss: 17451999.8203\n",
            "Epoch 876/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 634449.5588 - val_loss: 17231228.7250\n",
            "Epoch 877/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 730020.0219 - val_loss: 18500926.3301\n",
            "Epoch 878/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1524975.8300 - val_loss: 17140741.8352\n",
            "Epoch 879/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2203013.3981 - val_loss: 17978133.6619\n",
            "Epoch 880/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1816433.5777 - val_loss: 17430377.8574\n",
            "Epoch 881/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1200208.9123 - val_loss: 17584290.5918\n",
            "Epoch 882/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 753759.6185 - val_loss: 17112989.2000\n",
            "Epoch 883/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1065802.7203 - val_loss: 16836635.1375\n",
            "Epoch 884/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 777776.9527 - val_loss: 17356269.9219\n",
            "Epoch 885/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 933350.8939 - val_loss: 17624257.9945\n",
            "Epoch 886/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1007115.6122 - val_loss: 17524470.1867\n",
            "Epoch 887/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1523983.2829 - val_loss: 16974632.5063\n",
            "Epoch 888/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1158166.3410 - val_loss: 17303010.9836\n",
            "Epoch 889/2048\n",
            "90/90 [==============================] - 0s 3ms/step - loss: 827396.3918 - val_loss: 17312582.6141\n",
            "Epoch 890/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 627633.0869 - val_loss: 18908889.7125\n",
            "Epoch 891/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1312021.0605 - val_loss: 16984270.2078\n",
            "Epoch 892/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1286534.9739 - val_loss: 17364086.3664\n",
            "Epoch 893/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1131220.6363 - val_loss: 17303569.7703\n",
            "Epoch 894/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 691873.1007 - val_loss: 17927555.9320\n",
            "Epoch 895/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 869801.2921 - val_loss: 18363037.7142\n",
            "Epoch 896/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4744337.4665 - val_loss: 17112364.2063\n",
            "Epoch 897/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1850646.7571 - val_loss: 18490607.3469\n",
            "Epoch 898/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 661969.8975 - val_loss: 17479863.9691\n",
            "Epoch 899/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 836645.7460 - val_loss: 17488326.5027\n",
            "Epoch 900/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 650929.5086 - val_loss: 17804126.7211\n",
            "Epoch 901/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 904267.7691 - val_loss: 18411832.8701\n",
            "Epoch 902/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 861695.9302 - val_loss: 17085848.1391\n",
            "Epoch 903/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1187895.0700 - val_loss: 17441897.9070\n",
            "Epoch 904/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 567827.0896 - val_loss: 18774842.2691\n",
            "Epoch 905/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 900913.0155 - val_loss: 18867541.6836\n",
            "Epoch 906/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 779967.1753 - val_loss: 18958938.4867\n",
            "Epoch 907/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 531846.9345 - val_loss: 19848047.4750\n",
            "Epoch 908/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2163802.0278 - val_loss: 20574481.2789\n",
            "Epoch 909/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 950113.6010 - val_loss: 18812963.9980\n",
            "Epoch 910/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 596311.5534 - val_loss: 17774970.4367\n",
            "Epoch 911/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 5266268.2064 - val_loss: 20416021.5227\n",
            "Epoch 912/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2952262.6732 - val_loss: 16527563.7625\n",
            "Epoch 913/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 727421.5020 - val_loss: 17741666.3141\n",
            "Epoch 914/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 583795.4195 - val_loss: 17823896.5715\n",
            "Epoch 915/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 627403.4738 - val_loss: 18492422.7415\n",
            "Epoch 916/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 885585.7704 - val_loss: 17356265.0539\n",
            "Epoch 917/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 591546.0001 - val_loss: 18139026.1323\n",
            "Epoch 918/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 653134.0560 - val_loss: 19085666.2664\n",
            "Epoch 919/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1245422.2339 - val_loss: 18259885.9507\n",
            "Epoch 920/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3740843.9093 - val_loss: 20115965.9398\n",
            "Epoch 921/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1258513.3031 - val_loss: 21265209.4094\n",
            "Epoch 922/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1022270.3553 - val_loss: 19099479.9711\n",
            "Epoch 923/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 720773.0990 - val_loss: 18197929.7301\n",
            "Epoch 924/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 564929.4518 - val_loss: 18202391.9854\n",
            "Epoch 925/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 840689.7540 - val_loss: 19552411.7188\n",
            "Epoch 926/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 838738.3255 - val_loss: 19368267.4172\n",
            "Epoch 927/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 775578.5590 - val_loss: 18583830.8033\n",
            "Epoch 928/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 608479.8671 - val_loss: 18769931.6850\n",
            "Epoch 929/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1138320.0049 - val_loss: 19842468.7312\n",
            "Epoch 930/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1040983.0198 - val_loss: 18694982.2875\n",
            "Epoch 931/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 443091.0990 - val_loss: 19817641.6750\n",
            "Epoch 932/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 479209.7039 - val_loss: 19824305.9453\n",
            "Epoch 933/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 433623.0261 - val_loss: 19324746.0688\n",
            "Epoch 934/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1030919.1202 - val_loss: 18666318.2321\n",
            "Epoch 935/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2990384.6831 - val_loss: 19678140.4172\n",
            "Epoch 936/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1619328.0609 - val_loss: 19448926.3906\n",
            "Epoch 937/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 888699.6987 - val_loss: 21713098.2469\n",
            "Epoch 938/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 433171.5057 - val_loss: 19405882.5328\n",
            "Epoch 939/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 387809.4994 - val_loss: 19439600.3891\n",
            "Epoch 940/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 611169.5534 - val_loss: 20393166.0391\n",
            "Epoch 941/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 630072.7538 - val_loss: 20288449.1547\n",
            "Epoch 942/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1344546.8453 - val_loss: 19501296.6125\n",
            "Epoch 943/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1052454.0720 - val_loss: 20488549.2133\n",
            "Epoch 944/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 734799.9440 - val_loss: 19063904.4363\n",
            "Epoch 945/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1202676.9644 - val_loss: 35774659.4000\n",
            "Epoch 946/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 775064.4993 - val_loss: 21992386.2750\n",
            "Epoch 947/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 328024.6590 - val_loss: 20838051.0625\n",
            "Epoch 948/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 533382.9876 - val_loss: 20862777.2031\n",
            "Epoch 949/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 554516.4809 - val_loss: 21343520.1938\n",
            "Epoch 950/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 241364.1701 - val_loss: 22048650.8406\n",
            "Epoch 951/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1278989.2462 - val_loss: 20439058.5969\n",
            "Epoch 952/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1593263.9484 - val_loss: 21892996.5094\n",
            "Epoch 953/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 830441.7030 - val_loss: 22233888.1125\n",
            "Epoch 954/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 505380.2115 - val_loss: 20628504.5609\n",
            "Epoch 955/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 278902.9952 - val_loss: 21582222.9984\n",
            "Epoch 956/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 478933.8875 - val_loss: 21089558.8016\n",
            "Epoch 957/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2478160.1055 - val_loss: 21230693.4109\n",
            "Epoch 958/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1068563.1134 - val_loss: 20432813.2844\n",
            "Epoch 959/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 342404.4149 - val_loss: 20125468.0922\n",
            "Epoch 960/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 396376.4101 - val_loss: 21651877.0125\n",
            "Epoch 961/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 257688.8304 - val_loss: 21177573.1812\n",
            "Epoch 962/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 351476.0197 - val_loss: 22163060.1500\n",
            "Epoch 963/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 207010.4368 - val_loss: 22296761.3031\n",
            "Epoch 964/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 399579.2773 - val_loss: 21316148.2141\n",
            "Epoch 965/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 362531.2035 - val_loss: 21485517.3344\n",
            "Epoch 966/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 314849.7073 - val_loss: 21907691.0375\n",
            "Epoch 967/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 203794.3161 - val_loss: 21485912.5250\n",
            "Epoch 968/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 730923.5354 - val_loss: 20475216.0750\n",
            "Epoch 969/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1450923.1333 - val_loss: 23990875.4625\n",
            "Epoch 970/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 392001.6611 - val_loss: 22798762.9531\n",
            "Epoch 971/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 489795.9332 - val_loss: 21795271.9391\n",
            "Epoch 972/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1409966.5680 - val_loss: 22983462.0250\n",
            "Epoch 973/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4203268.4515 - val_loss: 23218623.7312\n",
            "Epoch 974/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 593023.0836 - val_loss: 21397875.5719\n",
            "Epoch 975/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1485333.6219 - val_loss: 27546062.8250\n",
            "Epoch 976/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 6261951.8314 - val_loss: 22046111.7094\n",
            "Epoch 977/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 457238.4681 - val_loss: 20373800.8031\n",
            "Epoch 978/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 272054.8506 - val_loss: 20570944.5070\n",
            "Epoch 979/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 309836.7006 - val_loss: 20971854.0156\n",
            "Epoch 980/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2597377.0017 - val_loss: 24483245.4375\n",
            "Epoch 981/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2443380.7279 - val_loss: 20121995.3297\n",
            "Epoch 982/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 993288.8395 - val_loss: 20913822.6602\n",
            "Epoch 983/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 578531.9629 - val_loss: 20366285.5844\n",
            "Epoch 984/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 551193.5810 - val_loss: 21736881.7625\n",
            "Epoch 985/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 595153.1668 - val_loss: 23187458.4625\n",
            "Epoch 986/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 307353.0326 - val_loss: 20661988.1359\n",
            "Epoch 987/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 295156.4862 - val_loss: 21268099.4430\n",
            "Epoch 988/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1319174.0469 - val_loss: 24083297.0000\n",
            "Epoch 989/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1107379.0746 - val_loss: 21771358.0578\n",
            "Epoch 990/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 908794.9914 - val_loss: 22791422.4125\n",
            "Epoch 991/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 870447.6814 - val_loss: 19989035.9125\n",
            "Epoch 992/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 415059.7178 - val_loss: 22821039.2312\n",
            "Epoch 993/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 216573.9988 - val_loss: 22937053.3781\n",
            "Epoch 994/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 437943.8809 - val_loss: 23230006.6875\n",
            "Epoch 995/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1319529.8426 - val_loss: 22086922.6656\n",
            "Epoch 996/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1066735.1082 - val_loss: 23955965.8250\n",
            "Epoch 997/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 348026.2214 - val_loss: 23729249.7312\n",
            "Epoch 998/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 253653.3755 - val_loss: 24343398.2000\n",
            "Epoch 999/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 525894.6307 - val_loss: 23688519.2375\n",
            "Epoch 1000/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 326747.2683 - val_loss: 22734442.1969\n",
            "Epoch 1001/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2224238.7469 - val_loss: 22929105.6687\n",
            "Epoch 1002/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 554628.2759 - val_loss: 21420545.7320\n",
            "Epoch 1003/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 255846.9490 - val_loss: 23769556.8000\n",
            "Epoch 1004/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 158410.5336 - val_loss: 24053334.1938\n",
            "Epoch 1005/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 196652.4465 - val_loss: 24941645.3875\n",
            "Epoch 1006/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 474935.0983 - val_loss: 23900435.4438\n",
            "Epoch 1007/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 269395.9606 - val_loss: 23433354.9875\n",
            "Epoch 1008/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 274028.9268 - val_loss: 23558895.5844\n",
            "Epoch 1009/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 296279.6870 - val_loss: 24897505.8625\n",
            "Epoch 1010/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 313517.6484 - val_loss: 25922636.6125\n",
            "Epoch 1011/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 522797.3862 - val_loss: 24524420.9750\n",
            "Epoch 1012/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 222498.0947 - val_loss: 26387439.1875\n",
            "Epoch 1013/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 177156.7041 - val_loss: 24579513.2500\n",
            "Epoch 1014/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 260611.4718 - val_loss: 26863062.9375\n",
            "Epoch 1015/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 731804.7052 - val_loss: 26651251.5250\n",
            "Epoch 1016/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 419358.8719 - val_loss: 26144819.5500\n",
            "Epoch 1017/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 159004.3905 - val_loss: 26040111.0625\n",
            "Epoch 1018/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 177067.7653 - val_loss: 27043227.1750\n",
            "Epoch 1019/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 116850.9854 - val_loss: 25908596.0000\n",
            "Epoch 1020/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 627956.8467 - val_loss: 27296283.8000\n",
            "Epoch 1021/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 167212.6906 - val_loss: 26762484.1250\n",
            "Epoch 1022/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 232594.6345 - val_loss: 23052101.5625\n",
            "Epoch 1023/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 953543.3959 - val_loss: 26475132.3000\n",
            "Epoch 1024/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2713680.2365 - val_loss: 24863601.8000\n",
            "Epoch 1025/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 492443.9818 - val_loss: 22937001.3625\n",
            "Epoch 1026/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 245996.2599 - val_loss: 24494295.8250\n",
            "Epoch 1027/2048\n",
            "90/90 [==============================] - 0s 3ms/step - loss: 1447272.7222 - val_loss: 16885143.2875\n",
            "Epoch 1028/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1296317.5335 - val_loss: 23635876.8500\n",
            "Epoch 1029/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 532204.6218 - val_loss: 24676293.6500\n",
            "Epoch 1030/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 319737.3561 - val_loss: 24161794.6187\n",
            "Epoch 1031/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 710819.8771 - val_loss: 24469498.8813\n",
            "Epoch 1032/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 350083.2580 - val_loss: 23247223.7719\n",
            "Epoch 1033/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 352286.2561 - val_loss: 26357679.9000\n",
            "Epoch 1034/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 179394.8538 - val_loss: 26105625.3500\n",
            "Epoch 1035/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 308227.1652 - val_loss: 26578245.1125\n",
            "Epoch 1036/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 607570.5385 - val_loss: 26325362.8250\n",
            "Epoch 1037/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 343780.3179 - val_loss: 27959066.4000\n",
            "Epoch 1038/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 164209.1980 - val_loss: 24632384.4438\n",
            "Epoch 1039/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 137949.5300 - val_loss: 26504799.5625\n",
            "Epoch 1040/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 322444.4910 - val_loss: 26087810.4125\n",
            "Epoch 1041/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 646583.0242 - val_loss: 24428368.5375\n",
            "Epoch 1042/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1227828.4257 - val_loss: 24943890.1500\n",
            "Epoch 1043/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 767696.2281 - val_loss: 27556005.4750\n",
            "Epoch 1044/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1994172.3561 - val_loss: 22963208.6625\n",
            "Epoch 1045/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 791737.7244 - val_loss: 25161387.3750\n",
            "Epoch 1046/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 365783.5227 - val_loss: 25604921.4750\n",
            "Epoch 1047/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 252265.2953 - val_loss: 25033996.2875\n",
            "Epoch 1048/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 762023.9725 - val_loss: 25127473.1250\n",
            "Epoch 1049/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 510413.2893 - val_loss: 26740778.6250\n",
            "Epoch 1050/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 240958.7566 - val_loss: 26417012.7250\n",
            "Epoch 1051/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 558806.9649 - val_loss: 24993335.0188\n",
            "Epoch 1052/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 435640.0166 - val_loss: 28796691.6500\n",
            "Epoch 1053/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 661346.6260 - val_loss: 24624670.3000\n",
            "Epoch 1054/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 523602.7122 - val_loss: 25044020.7312\n",
            "Epoch 1055/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 333653.3337 - val_loss: 25410155.2500\n",
            "Epoch 1056/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 121551.2109 - val_loss: 26238429.3375\n",
            "Epoch 1057/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 203286.2729 - val_loss: 26565573.6625\n",
            "Epoch 1058/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 838618.7480 - val_loss: 25796323.0500\n",
            "Epoch 1059/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 691649.7829 - val_loss: 26216238.6500\n",
            "Epoch 1060/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 570647.3028 - val_loss: 27945973.9000\n",
            "Epoch 1061/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 842872.0558 - val_loss: 28865180.9750\n",
            "Epoch 1062/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 495678.1766 - val_loss: 27468131.8000\n",
            "Epoch 1063/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 270416.3879 - val_loss: 25595276.6750\n",
            "Epoch 1064/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 210697.6299 - val_loss: 27320843.3000\n",
            "Epoch 1065/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 238030.2883 - val_loss: 27351206.9000\n",
            "Epoch 1066/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 255104.8065 - val_loss: 24698120.0375\n",
            "Epoch 1067/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 332205.5061 - val_loss: 27313045.0500\n",
            "Epoch 1068/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2188934.1499 - val_loss: 21799594.8578\n",
            "Epoch 1069/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 934855.7998 - val_loss: 23901346.6562\n",
            "Epoch 1070/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 201750.5844 - val_loss: 25109686.2125\n",
            "Epoch 1071/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 223809.3652 - val_loss: 25981778.0125\n",
            "Epoch 1072/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2890694.0512 - val_loss: 25669165.4000\n",
            "Epoch 1073/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2208376.8251 - val_loss: 24826126.8500\n",
            "Epoch 1074/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1127989.1955 - val_loss: 25470580.5125\n",
            "Epoch 1075/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1027971.7116 - val_loss: 26014382.0250\n",
            "Epoch 1076/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 787110.5646 - val_loss: 23860597.2500\n",
            "Epoch 1077/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 663499.5018 - val_loss: 25129588.6250\n",
            "Epoch 1078/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 739225.3723 - val_loss: 28456297.9250\n",
            "Epoch 1079/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 349266.1439 - val_loss: 26686999.7125\n",
            "Epoch 1080/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 138986.0192 - val_loss: 24856438.2563\n",
            "Epoch 1081/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 106516.3393 - val_loss: 26832370.3000\n",
            "Epoch 1082/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 162359.0061 - val_loss: 25575003.6375\n",
            "Epoch 1083/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 226015.5255 - val_loss: 24797012.7500\n",
            "Epoch 1084/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 911241.4790 - val_loss: 25796779.1625\n",
            "Epoch 1085/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 351172.3299 - val_loss: 26060123.8000\n",
            "Epoch 1086/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2127983.9021 - val_loss: 23957921.9563\n",
            "Epoch 1087/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1554453.8465 - val_loss: 24785828.4250\n",
            "Epoch 1088/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 995850.2438 - val_loss: 23491918.7250\n",
            "Epoch 1089/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 695151.4670 - val_loss: 23766767.8000\n",
            "Epoch 1090/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 222224.7097 - val_loss: 24474392.5938\n",
            "Epoch 1091/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 138713.6482 - val_loss: 25811918.2375\n",
            "Epoch 1092/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 466795.8062 - val_loss: 24599978.9563\n",
            "Epoch 1093/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 175439.2124 - val_loss: 24638601.1938\n",
            "Epoch 1094/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 893417.0854 - val_loss: 23001988.6344\n",
            "Epoch 1095/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 303997.0108 - val_loss: 25165450.8875\n",
            "Epoch 1096/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 235544.7511 - val_loss: 25216175.3000\n",
            "Epoch 1097/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 237004.6764 - val_loss: 26737471.3375\n",
            "Epoch 1098/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 138146.8732 - val_loss: 23987684.4750\n",
            "Epoch 1099/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 109793.4115 - val_loss: 26120214.8250\n",
            "Epoch 1100/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 178970.4186 - val_loss: 23144692.0750\n",
            "Epoch 1101/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3424933.1586 - val_loss: 26851784.3500\n",
            "Epoch 1102/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2776615.4699 - val_loss: 22484126.1687\n",
            "Epoch 1103/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1210495.8565 - val_loss: 24628961.4500\n",
            "Epoch 1104/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1098293.3133 - val_loss: 22967047.2312\n",
            "Epoch 1105/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 440828.4248 - val_loss: 27350461.5500\n",
            "Epoch 1106/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 206666.8776 - val_loss: 27158109.1500\n",
            "Epoch 1107/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 152141.9447 - val_loss: 25712822.4750\n",
            "Epoch 1108/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 185043.3827 - val_loss: 25386197.0250\n",
            "Epoch 1109/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 226981.3349 - val_loss: 25323768.2375\n",
            "Epoch 1110/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 382338.2522 - val_loss: 24437443.8250\n",
            "Epoch 1111/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 353071.0542 - val_loss: 24869911.2875\n",
            "Epoch 1112/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 122786.6215 - val_loss: 25101200.1687\n",
            "Epoch 1113/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 113221.3943 - val_loss: 26786827.5250\n",
            "Epoch 1114/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 128574.8434 - val_loss: 27102638.3500\n",
            "Epoch 1115/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 218734.3293 - val_loss: 25325673.0312\n",
            "Epoch 1116/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 167863.3582 - val_loss: 25912564.9500\n",
            "Epoch 1117/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 251420.5346 - val_loss: 25527771.7000\n",
            "Epoch 1118/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2449848.6749 - val_loss: 30112441.6000\n",
            "Epoch 1119/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1316364.1420 - val_loss: 25652172.1625\n",
            "Epoch 1120/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 354303.2291 - val_loss: 27288989.4000\n",
            "Epoch 1121/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 267080.0819 - val_loss: 27984368.0500\n",
            "Epoch 1122/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 662183.7750 - val_loss: 24705622.3750\n",
            "Epoch 1123/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 354307.5504 - val_loss: 25368031.0500\n",
            "Epoch 1124/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 211456.8687 - val_loss: 26111199.8500\n",
            "Epoch 1125/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 357634.4912 - val_loss: 29721778.2000\n",
            "Epoch 1126/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 349306.1122 - val_loss: 27133549.7500\n",
            "Epoch 1127/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 126706.8986 - val_loss: 25582803.0625\n",
            "Epoch 1128/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 185875.5694 - val_loss: 28707833.1500\n",
            "Epoch 1129/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 130562.1491 - val_loss: 25764305.7125\n",
            "Epoch 1130/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 183732.9180 - val_loss: 24895452.9625\n",
            "Epoch 1131/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 429953.6919 - val_loss: 25268653.6000\n",
            "Epoch 1132/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 361780.6538 - val_loss: 25554267.3000\n",
            "Epoch 1133/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 275862.9695 - val_loss: 25346471.1375\n",
            "Epoch 1134/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 204166.1215 - val_loss: 25911424.7125\n",
            "Epoch 1135/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 350200.0222 - val_loss: 29473655.8000\n",
            "Epoch 1136/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 427861.9863 - val_loss: 29335309.4750\n",
            "Epoch 1137/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 501891.8077 - val_loss: 28355291.6750\n",
            "Epoch 1138/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 362538.0424 - val_loss: 27024608.2000\n",
            "Epoch 1139/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1021348.3263 - val_loss: 27593665.1500\n",
            "Epoch 1140/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 954996.9901 - val_loss: 28139571.9500\n",
            "Epoch 1141/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 340893.5684 - val_loss: 25792994.4000\n",
            "Epoch 1142/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 183474.0252 - val_loss: 26711269.3125\n",
            "Epoch 1143/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1443314.5751 - val_loss: 28892303.9500\n",
            "Epoch 1144/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 576677.3848 - val_loss: 26715118.1875\n",
            "Epoch 1145/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 177981.1526 - val_loss: 27288223.0250\n",
            "Epoch 1146/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 163331.0524 - val_loss: 29487687.5000\n",
            "Epoch 1147/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 355066.5057 - val_loss: 28216030.6250\n",
            "Epoch 1148/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 284695.1454 - val_loss: 27916575.3000\n",
            "Epoch 1149/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 491789.2066 - val_loss: 29658862.2750\n",
            "Epoch 1150/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 582759.0232 - val_loss: 26733280.6250\n",
            "Epoch 1151/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 168891.8111 - val_loss: 29125773.4500\n",
            "Epoch 1152/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1607370.3349 - val_loss: 22185717.2141\n",
            "Epoch 1153/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 707417.3314 - val_loss: 24741921.1500\n",
            "Epoch 1154/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1143268.6315 - val_loss: 23552459.8625\n",
            "Epoch 1155/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1247733.4493 - val_loss: 25416254.7750\n",
            "Epoch 1156/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 545854.0645 - val_loss: 22250352.2031\n",
            "Epoch 1157/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1388751.2063 - val_loss: 21665619.9812\n",
            "Epoch 1158/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 847622.7875 - val_loss: 24561919.6687\n",
            "Epoch 1159/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 466212.7483 - val_loss: 22658709.2406\n",
            "Epoch 1160/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 197550.1073 - val_loss: 26910599.1250\n",
            "Epoch 1161/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 899537.7035 - val_loss: 24773000.0938\n",
            "Epoch 1162/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 474474.6648 - val_loss: 25293121.7125\n",
            "Epoch 1163/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 167078.1256 - val_loss: 26709473.1625\n",
            "Epoch 1164/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 156511.6720 - val_loss: 25285046.6875\n",
            "Epoch 1165/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 150002.5830 - val_loss: 26511653.8875\n",
            "Epoch 1166/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 208003.9324 - val_loss: 24976624.4625\n",
            "Epoch 1167/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 181452.0804 - val_loss: 27828238.3750\n",
            "Epoch 1168/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 122178.2429 - val_loss: 26166785.6500\n",
            "Epoch 1169/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 333716.2151 - val_loss: 25814943.1500\n",
            "Epoch 1170/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 291838.5040 - val_loss: 25074980.7375\n",
            "Epoch 1171/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 817749.7348 - val_loss: 27548337.4500\n",
            "Epoch 1172/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1447089.6380 - val_loss: 24532361.7563\n",
            "Epoch 1173/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 687227.4622 - val_loss: 26966841.1000\n",
            "Epoch 1174/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 328661.6662 - val_loss: 27525333.6750\n",
            "Epoch 1175/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 148111.0138 - val_loss: 27205694.8500\n",
            "Epoch 1176/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 439602.9532 - val_loss: 31655582.5500\n",
            "Epoch 1177/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 966563.7694 - val_loss: 26632404.7000\n",
            "Epoch 1178/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1223762.6741 - val_loss: 26935471.1375\n",
            "Epoch 1179/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2239032.7322 - val_loss: 23334767.7188\n",
            "Epoch 1180/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 534399.9569 - val_loss: 23359709.1313\n",
            "Epoch 1181/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 342854.4966 - val_loss: 25027084.6250\n",
            "Epoch 1182/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 713631.1098 - val_loss: 26364299.8250\n",
            "Epoch 1183/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 315032.5616 - val_loss: 27435184.4500\n",
            "Epoch 1184/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1559576.8643 - val_loss: 21795390.6250\n",
            "Epoch 1185/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 607998.2823 - val_loss: 24916743.8813\n",
            "Epoch 1186/2048\n",
            "90/90 [==============================] - 0s 3ms/step - loss: 536743.6223 - val_loss: 24368738.0125\n",
            "Epoch 1187/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 284994.6220 - val_loss: 26299137.9875\n",
            "Epoch 1188/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 406669.0965 - val_loss: 25303438.6625\n",
            "Epoch 1189/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 304267.2893 - val_loss: 26057726.2750\n",
            "Epoch 1190/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 124656.7568 - val_loss: 25909116.3875\n",
            "Epoch 1191/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 373043.8699 - val_loss: 27052231.6000\n",
            "Epoch 1192/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 856305.9696 - val_loss: 33189191.2000\n",
            "Epoch 1193/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 768429.7898 - val_loss: 27128109.1500\n",
            "Epoch 1194/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3012173.9970 - val_loss: 22128044.8719\n",
            "Epoch 1195/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 594293.4445 - val_loss: 23268669.2000\n",
            "Epoch 1196/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 574564.0552 - val_loss: 26568276.5500\n",
            "Epoch 1197/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 975339.4442 - val_loss: 25251941.4625\n",
            "Epoch 1198/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 717434.9861 - val_loss: 25480876.6750\n",
            "Epoch 1199/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 293601.9634 - val_loss: 24911012.9563\n",
            "Epoch 1200/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 236455.8473 - val_loss: 25131412.3125\n",
            "Epoch 1201/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 490204.4397 - val_loss: 25651262.5875\n",
            "Epoch 1202/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 546202.2970 - val_loss: 24167890.2125\n",
            "Epoch 1203/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 153029.1760 - val_loss: 27391232.6750\n",
            "Epoch 1204/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 494789.1406 - val_loss: 25580874.8000\n",
            "Epoch 1205/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 127114.3958 - val_loss: 27577413.2000\n",
            "Epoch 1206/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 152978.5301 - val_loss: 29104478.4500\n",
            "Epoch 1207/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 232612.3161 - val_loss: 30206481.1500\n",
            "Epoch 1208/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 448318.4674 - val_loss: 27792367.0750\n",
            "Epoch 1209/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 271700.6575 - val_loss: 27246664.1750\n",
            "Epoch 1210/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 185390.0994 - val_loss: 26785841.5625\n",
            "Epoch 1211/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 232350.4356 - val_loss: 30595687.4500\n",
            "Epoch 1212/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 744212.5894 - val_loss: 27365361.2000\n",
            "Epoch 1213/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 943921.3309 - val_loss: 27765167.5125\n",
            "Epoch 1214/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1709836.5803 - val_loss: 26127535.1750\n",
            "Epoch 1215/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 489755.1113 - val_loss: 24624542.1750\n",
            "Epoch 1216/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 678768.9428 - val_loss: 30766201.6500\n",
            "Epoch 1217/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 263072.8004 - val_loss: 27045510.5375\n",
            "Epoch 1218/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 158630.8150 - val_loss: 26628755.1625\n",
            "Epoch 1219/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 113726.1828 - val_loss: 28958166.1500\n",
            "Epoch 1220/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 391306.2775 - val_loss: 30099842.3250\n",
            "Epoch 1221/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 728014.0139 - val_loss: 27539361.7500\n",
            "Epoch 1222/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 264528.6066 - val_loss: 30048179.5250\n",
            "Epoch 1223/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 872504.7627 - val_loss: 26995083.5375\n",
            "Epoch 1224/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1202001.4242 - val_loss: 29386640.5250\n",
            "Epoch 1225/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 713177.2740 - val_loss: 26575384.3000\n",
            "Epoch 1226/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 785073.7661 - val_loss: 27084332.6500\n",
            "Epoch 1227/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 503901.6533 - val_loss: 26593964.4000\n",
            "Epoch 1228/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 251591.9734 - val_loss: 27580725.3000\n",
            "Epoch 1229/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 183223.0566 - val_loss: 24901595.5063\n",
            "Epoch 1230/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 187212.2349 - val_loss: 28933558.5500\n",
            "Epoch 1231/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 441706.2437 - val_loss: 27459007.7500\n",
            "Epoch 1232/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1046576.8960 - val_loss: 26739941.4875\n",
            "Epoch 1233/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 287164.2324 - val_loss: 26093506.4500\n",
            "Epoch 1234/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 199065.0895 - val_loss: 29473727.8750\n",
            "Epoch 1235/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 380608.6671 - val_loss: 28358318.9500\n",
            "Epoch 1236/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 957601.9435 - val_loss: 24523164.7375\n",
            "Epoch 1237/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 694527.2563 - val_loss: 27028382.9875\n",
            "Epoch 1238/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 782793.6479 - val_loss: 27165141.4625\n",
            "Epoch 1239/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 716612.6463 - val_loss: 28554250.3000\n",
            "Epoch 1240/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 346672.8666 - val_loss: 27275820.8875\n",
            "Epoch 1241/2048\n",
            "90/90 [==============================] - 0s 3ms/step - loss: 1372114.8144 - val_loss: 24908323.5750\n",
            "Epoch 1242/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 809973.1371 - val_loss: 27131941.0750\n",
            "Epoch 1243/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 375849.7944 - val_loss: 26441614.3750\n",
            "Epoch 1244/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 607480.0826 - val_loss: 22975365.9688\n",
            "Epoch 1245/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 772660.8495 - val_loss: 25289243.1500\n",
            "Epoch 1246/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 376747.6310 - val_loss: 25334301.1625\n",
            "Epoch 1247/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 102482.6426 - val_loss: 26187968.9250\n",
            "Epoch 1248/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 282123.2079 - val_loss: 25238206.4875\n",
            "Epoch 1249/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 535935.5264 - val_loss: 24391185.3875\n",
            "Epoch 1250/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 414986.1216 - val_loss: 23655347.9375\n",
            "Epoch 1251/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 748101.0923 - val_loss: 27660623.2500\n",
            "Epoch 1252/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1090567.1482 - val_loss: 24531340.1438\n",
            "Epoch 1253/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 699270.3118 - val_loss: 25747383.9750\n",
            "Epoch 1254/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 291213.3854 - val_loss: 27332442.8000\n",
            "Epoch 1255/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1108919.1827 - val_loss: 29056021.0750\n",
            "Epoch 1256/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 997593.3533 - val_loss: 27087867.1500\n",
            "Epoch 1257/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 741680.6619 - val_loss: 26216462.3500\n",
            "Epoch 1258/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 402848.5484 - val_loss: 26586984.7250\n",
            "Epoch 1259/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 196676.0365 - val_loss: 28102954.3000\n",
            "Epoch 1260/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 265306.2228 - val_loss: 29575704.3000\n",
            "Epoch 1261/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 880514.3903 - val_loss: 28387824.4000\n",
            "Epoch 1262/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 249159.2604 - val_loss: 24900315.8500\n",
            "Epoch 1263/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 242061.5385 - val_loss: 26383655.1250\n",
            "Epoch 1264/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 454519.5462 - val_loss: 25689965.8750\n",
            "Epoch 1265/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 239786.1772 - val_loss: 29257001.1000\n",
            "Epoch 1266/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 293568.1025 - val_loss: 28866319.1250\n",
            "Epoch 1267/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 503608.0466 - val_loss: 29527357.7000\n",
            "Epoch 1268/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1052448.8648 - val_loss: 28468190.8000\n",
            "Epoch 1269/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 332829.0318 - val_loss: 25524422.1000\n",
            "Epoch 1270/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 442511.1598 - val_loss: 23782213.4750\n",
            "Epoch 1271/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 214496.2783 - val_loss: 26342600.1750\n",
            "Epoch 1272/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 354993.0211 - val_loss: 28744090.8250\n",
            "Epoch 1273/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 232336.1817 - val_loss: 27974170.0750\n",
            "Epoch 1274/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 117720.7612 - val_loss: 27115347.0625\n",
            "Epoch 1275/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 898998.4766 - val_loss: 24876247.0312\n",
            "Epoch 1276/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 313470.6871 - val_loss: 26450192.2500\n",
            "Epoch 1277/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1136256.6292 - val_loss: 26352770.5250\n",
            "Epoch 1278/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 547945.7256 - val_loss: 26706669.5125\n",
            "Epoch 1279/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 551156.0886 - val_loss: 27105352.9000\n",
            "Epoch 1280/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 214668.1231 - val_loss: 26527172.3625\n",
            "Epoch 1281/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 174045.9066 - val_loss: 26726431.2000\n",
            "Epoch 1282/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 309529.1482 - val_loss: 25360961.3313\n",
            "Epoch 1283/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2405260.1724 - val_loss: 25290294.9875\n",
            "Epoch 1284/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 464120.4209 - val_loss: 27597029.5000\n",
            "Epoch 1285/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 239600.9086 - val_loss: 27319840.0250\n",
            "Epoch 1286/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 235436.7428 - val_loss: 27123601.9000\n",
            "Epoch 1287/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 253145.7917 - val_loss: 25750718.9625\n",
            "Epoch 1288/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1216031.4410 - val_loss: 25154391.4000\n",
            "Epoch 1289/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 659214.0497 - val_loss: 27818058.7500\n",
            "Epoch 1290/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 881434.5766 - val_loss: 25902706.3500\n",
            "Epoch 1291/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 635390.5741 - val_loss: 27964518.4000\n",
            "Epoch 1292/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 196267.7905 - val_loss: 28092501.4500\n",
            "Epoch 1293/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 117658.5693 - val_loss: 27222949.8125\n",
            "Epoch 1294/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 540184.1497 - val_loss: 26383441.0250\n",
            "Epoch 1295/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 655616.4532 - val_loss: 27393113.6750\n",
            "Epoch 1296/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 190054.3321 - val_loss: 24711523.7750\n",
            "Epoch 1297/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 209056.0093 - val_loss: 26865624.3625\n",
            "Epoch 1298/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 106219.5943 - val_loss: 28182251.4500\n",
            "Epoch 1299/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 96855.5090 - val_loss: 26384464.7375\n",
            "Epoch 1300/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 148431.2935 - val_loss: 25735788.5625\n",
            "Epoch 1301/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 149028.0686 - val_loss: 29692906.1750\n",
            "Epoch 1302/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 102654.9742 - val_loss: 26344341.8250\n",
            "Epoch 1303/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 110962.7110 - val_loss: 29717827.1500\n",
            "Epoch 1304/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 73684.7522 - val_loss: 27755168.7750\n",
            "Epoch 1305/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 99280.9857 - val_loss: 27419561.2500\n",
            "Epoch 1306/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 111234.8004 - val_loss: 28632904.4750\n",
            "Epoch 1307/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 263377.0435 - val_loss: 28806970.1500\n",
            "Epoch 1308/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 171898.0303 - val_loss: 28129945.4500\n",
            "Epoch 1309/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 383531.9653 - val_loss: 30233158.2750\n",
            "Epoch 1310/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1742263.2709 - val_loss: 27463111.3500\n",
            "Epoch 1311/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 404095.2235 - val_loss: 33185966.7000\n",
            "Epoch 1312/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 3541729.6221 - val_loss: 26512076.9500\n",
            "Epoch 1313/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 724143.7602 - val_loss: 27620809.5500\n",
            "Epoch 1314/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1465138.3292 - val_loss: 26626465.2000\n",
            "Epoch 1315/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 762690.1582 - val_loss: 28843380.8000\n",
            "Epoch 1316/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 342199.8767 - val_loss: 26019537.5875\n",
            "Epoch 1317/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1972758.3644 - val_loss: 29118844.8000\n",
            "Epoch 1318/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 459812.3702 - val_loss: 28124497.9000\n",
            "Epoch 1319/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 286870.9595 - val_loss: 27856412.2500\n",
            "Epoch 1320/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 564068.9336 - val_loss: 26337142.0000\n",
            "Epoch 1321/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 396368.0714 - val_loss: 26442250.3000\n",
            "Epoch 1322/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 916881.9173 - val_loss: 24163946.2750\n",
            "Epoch 1323/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 782268.4133 - val_loss: 26624532.2625\n",
            "Epoch 1324/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 498886.5309 - val_loss: 29229174.1000\n",
            "Epoch 1325/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 538442.1494 - val_loss: 24497528.7875\n",
            "Epoch 1326/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 248882.5959 - val_loss: 25969014.8375\n",
            "Epoch 1327/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 563637.5428 - val_loss: 26465094.0875\n",
            "Epoch 1328/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 436373.9208 - val_loss: 25238580.4000\n",
            "Epoch 1329/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 282194.3434 - val_loss: 27116993.3250\n",
            "Epoch 1330/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 258169.7399 - val_loss: 25995477.9125\n",
            "Epoch 1331/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 582886.7290 - val_loss: 26473644.5250\n",
            "Epoch 1332/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1747103.4651 - val_loss: 24506992.3875\n",
            "Epoch 1333/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 594885.4663 - val_loss: 26810297.3125\n",
            "Epoch 1334/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 194096.7707 - val_loss: 26259073.9250\n",
            "Epoch 1335/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 119407.3863 - val_loss: 24644199.4438\n",
            "Epoch 1336/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 302018.3807 - val_loss: 26460803.2250\n",
            "Epoch 1337/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1328689.9595 - val_loss: 29240153.7750\n",
            "Epoch 1338/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 318574.1051 - val_loss: 26737268.5000\n",
            "Epoch 1339/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 507613.5616 - val_loss: 27997216.1000\n",
            "Epoch 1340/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 417276.0043 - val_loss: 26049458.7625\n",
            "Epoch 1341/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1100015.5046 - val_loss: 24131146.6625\n",
            "Epoch 1342/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 266729.5386 - val_loss: 25661625.5750\n",
            "Epoch 1343/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 144826.3292 - val_loss: 26184085.8750\n",
            "Epoch 1344/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 418618.8374 - val_loss: 29169133.1000\n",
            "Epoch 1345/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1699091.4198 - val_loss: 26273991.2750\n",
            "Epoch 1346/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 619890.2293 - val_loss: 27021677.3000\n",
            "Epoch 1347/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 395029.9699 - val_loss: 23692088.4375\n",
            "Epoch 1348/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 914578.5607 - val_loss: 24764424.8875\n",
            "Epoch 1349/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 827478.4719 - val_loss: 26154667.4500\n",
            "Epoch 1350/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 351697.4811 - val_loss: 28006048.5250\n",
            "Epoch 1351/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 504836.7737 - val_loss: 25884272.7500\n",
            "Epoch 1352/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 209799.8297 - val_loss: 26066467.8000\n",
            "Epoch 1353/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 458915.4484 - val_loss: 26681298.8250\n",
            "Epoch 1354/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 861657.4073 - val_loss: 29795244.1500\n",
            "Epoch 1355/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 625653.6686 - val_loss: 26297589.8125\n",
            "Epoch 1356/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 278018.8672 - val_loss: 22910443.4406\n",
            "Epoch 1357/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 193936.2602 - val_loss: 29661215.8250\n",
            "Epoch 1358/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 680454.9640 - val_loss: 25622064.2375\n",
            "Epoch 1359/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 332759.5982 - val_loss: 26098828.8500\n",
            "Epoch 1360/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 584616.1165 - val_loss: 25858216.7625\n",
            "Epoch 1361/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 454564.4454 - val_loss: 25446877.2750\n",
            "Epoch 1362/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 560983.0505 - val_loss: 28485918.0250\n",
            "Epoch 1363/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1147791.8699 - val_loss: 25432617.5625\n",
            "Epoch 1364/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 721416.8752 - val_loss: 25702318.8500\n",
            "Epoch 1365/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 325036.3629 - val_loss: 26618166.9000\n",
            "Epoch 1366/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 258302.7777 - val_loss: 25685172.1000\n",
            "Epoch 1367/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 644432.5790 - val_loss: 28465352.9750\n",
            "Epoch 1368/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 142495.2428 - val_loss: 28923497.1000\n",
            "Epoch 1369/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 201757.2633 - val_loss: 28154615.3250\n",
            "Epoch 1370/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 196957.7000 - val_loss: 28369617.7500\n",
            "Epoch 1371/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 386395.6305 - val_loss: 26878778.5500\n",
            "Epoch 1372/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 407203.1159 - val_loss: 26768419.4250\n",
            "Epoch 1373/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 250250.3387 - val_loss: 26226492.1125\n",
            "Epoch 1374/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 152219.9386 - val_loss: 27812186.8750\n",
            "Epoch 1375/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 119528.6243 - val_loss: 27747396.6500\n",
            "Epoch 1376/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1108985.4398 - val_loss: 28195441.6500\n",
            "Epoch 1377/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 153146.5887 - val_loss: 26558425.4500\n",
            "Epoch 1378/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 268630.3691 - val_loss: 27276683.7750\n",
            "Epoch 1379/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 568316.3146 - val_loss: 25891343.1250\n",
            "Epoch 1380/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1022374.4682 - val_loss: 25232402.8625\n",
            "Epoch 1381/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 503392.2793 - val_loss: 26204730.3250\n",
            "Epoch 1382/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 696890.4030 - val_loss: 25256508.9750\n",
            "Epoch 1383/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 349303.6044 - val_loss: 28023594.3500\n",
            "Epoch 1384/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 215861.9264 - val_loss: 27055124.7500\n",
            "Epoch 1385/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 695122.4486 - val_loss: 27022510.3000\n",
            "Epoch 1386/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 161580.6329 - val_loss: 27585509.0000\n",
            "Epoch 1387/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 79565.1788 - val_loss: 26350026.7375\n",
            "Epoch 1388/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 139091.0033 - val_loss: 27501615.1500\n",
            "Epoch 1389/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 448597.0886 - val_loss: 26108815.3625\n",
            "Epoch 1390/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 526051.8774 - val_loss: 25077515.8125\n",
            "Epoch 1391/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 428952.6717 - val_loss: 24691703.4062\n",
            "Epoch 1392/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 628837.0098 - val_loss: 25424828.5750\n",
            "Epoch 1393/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 675351.9196 - val_loss: 24884489.2000\n",
            "Epoch 1394/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 391449.8458 - val_loss: 26190590.6875\n",
            "Epoch 1395/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 175632.5037 - val_loss: 26521304.9250\n",
            "Epoch 1396/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 293249.8945 - val_loss: 25328776.0250\n",
            "Epoch 1397/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 602947.5715 - val_loss: 26696009.5625\n",
            "Epoch 1398/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 346984.6455 - val_loss: 27768143.5250\n",
            "Epoch 1399/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 228081.3368 - val_loss: 26095730.0875\n",
            "Epoch 1400/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 384105.8017 - val_loss: 27659606.8500\n",
            "Epoch 1401/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 218321.9641 - val_loss: 27549122.7000\n",
            "Epoch 1402/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 281336.8728 - val_loss: 25462810.0625\n",
            "Epoch 1403/2048\n",
            "90/90 [==============================] - 0s 3ms/step - loss: 621624.2847 - val_loss: 24531250.0437\n",
            "Epoch 1404/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 339500.0379 - val_loss: 25514318.8875\n",
            "Epoch 1405/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 912262.3612 - val_loss: 25055285.1000\n",
            "Epoch 1406/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1375366.2622 - val_loss: 30759806.4000\n",
            "Epoch 1407/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 379225.7321 - val_loss: 26832632.3250\n",
            "Epoch 1408/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 294048.5272 - val_loss: 24957631.3500\n",
            "Epoch 1409/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1424312.1528 - val_loss: 29656842.7250\n",
            "Epoch 1410/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1629347.7887 - val_loss: 26916306.8500\n",
            "Epoch 1411/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 939319.7339 - val_loss: 27004241.9000\n",
            "Epoch 1412/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 396649.0551 - val_loss: 25353041.8000\n",
            "Epoch 1413/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1121110.4797 - val_loss: 25549608.6375\n",
            "Epoch 1414/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 938036.5720 - val_loss: 22779443.9563\n",
            "Epoch 1415/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1423364.9945 - val_loss: 22784141.0688\n",
            "Epoch 1416/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 726150.3872 - val_loss: 25332037.6250\n",
            "Epoch 1417/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1000143.0308 - val_loss: 26393744.2125\n",
            "Epoch 1418/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 717752.9567 - val_loss: 25885860.9750\n",
            "Epoch 1419/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 460505.0915 - val_loss: 25031455.5375\n",
            "Epoch 1420/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 302003.3331 - val_loss: 26227347.4625\n",
            "Epoch 1421/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 259248.7533 - val_loss: 25156236.2875\n",
            "Epoch 1422/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 303166.1700 - val_loss: 25800655.5750\n",
            "Epoch 1423/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 186030.9243 - val_loss: 25407136.6875\n",
            "Epoch 1424/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 303093.0737 - val_loss: 25641363.1875\n",
            "Epoch 1425/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 154197.3626 - val_loss: 24114165.7375\n",
            "Epoch 1426/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 133830.7955 - val_loss: 24642765.1750\n",
            "Epoch 1427/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 543305.6682 - val_loss: 25598235.0625\n",
            "Epoch 1428/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1609129.5013 - val_loss: 25639170.2000\n",
            "Epoch 1429/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1268523.2686 - val_loss: 25305379.2250\n",
            "Epoch 1430/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1488535.0111 - val_loss: 25399336.5750\n",
            "Epoch 1431/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 573885.8318 - val_loss: 25233911.0625\n",
            "Epoch 1432/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1341854.6421 - val_loss: 31614517.0500\n",
            "Epoch 1433/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 313516.2185 - val_loss: 27148040.2250\n",
            "Epoch 1434/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 390536.0022 - val_loss: 24251113.2625\n",
            "Epoch 1435/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 220395.0214 - val_loss: 26920417.7125\n",
            "Epoch 1436/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 209250.1867 - val_loss: 27080765.7000\n",
            "Epoch 1437/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 323812.9667 - val_loss: 26489079.0125\n",
            "Epoch 1438/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 340468.5738 - val_loss: 27337610.3000\n",
            "Epoch 1439/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 237687.7231 - val_loss: 25553502.9750\n",
            "Epoch 1440/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 885264.3089 - val_loss: 30413122.1000\n",
            "Epoch 1441/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1292495.0302 - val_loss: 26475327.6875\n",
            "Epoch 1442/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 220388.2110 - val_loss: 27516969.0250\n",
            "Epoch 1443/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 511341.1133 - val_loss: 25791252.4250\n",
            "Epoch 1444/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 718578.2232 - val_loss: 23129798.7344\n",
            "Epoch 1445/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1867089.5065 - val_loss: 26077305.4625\n",
            "Epoch 1446/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 765725.5344 - val_loss: 26614141.0250\n",
            "Epoch 1447/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 314302.0435 - val_loss: 25256452.5750\n",
            "Epoch 1448/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 202499.8338 - val_loss: 26218467.1250\n",
            "Epoch 1449/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 532525.2627 - val_loss: 24982336.9875\n",
            "Epoch 1450/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 490607.8840 - val_loss: 25178711.4750\n",
            "Epoch 1451/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 369872.5758 - val_loss: 25990957.4750\n",
            "Epoch 1452/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 339758.0121 - val_loss: 26154352.7875\n",
            "Epoch 1453/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 219301.9580 - val_loss: 25656856.0500\n",
            "Epoch 1454/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 144812.8857 - val_loss: 27322380.1250\n",
            "Epoch 1455/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 187738.8761 - val_loss: 24839133.6625\n",
            "Epoch 1456/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 148857.7155 - val_loss: 25108936.5750\n",
            "Epoch 1457/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 118153.5461 - val_loss: 26639781.8250\n",
            "Epoch 1458/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 160196.0039 - val_loss: 26473402.8500\n",
            "Epoch 1459/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 240409.7364 - val_loss: 28726653.1500\n",
            "Epoch 1460/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 861723.5408 - val_loss: 25585732.8000\n",
            "Epoch 1461/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 769076.1549 - val_loss: 26680119.4250\n",
            "Epoch 1462/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1950942.0879 - val_loss: 23450003.7625\n",
            "Epoch 1463/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1483523.0151 - val_loss: 26092965.1000\n",
            "Epoch 1464/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1281400.3707 - val_loss: 27699050.9750\n",
            "Epoch 1465/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 352256.6626 - val_loss: 28201746.5000\n",
            "Epoch 1466/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 237092.2774 - val_loss: 29144834.7250\n",
            "Epoch 1467/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 245831.5734 - val_loss: 26189878.3750\n",
            "Epoch 1468/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 386916.7793 - val_loss: 26757034.7000\n",
            "Epoch 1469/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 210864.5314 - val_loss: 25507584.7250\n",
            "Epoch 1470/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 263557.7013 - val_loss: 25269019.2375\n",
            "Epoch 1471/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 857853.8370 - val_loss: 29889961.0000\n",
            "Epoch 1472/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1094314.3147 - val_loss: 28859945.1250\n",
            "Epoch 1473/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1506421.2266 - val_loss: 24535397.2750\n",
            "Epoch 1474/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 582147.7691 - val_loss: 25328556.6625\n",
            "Epoch 1475/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1210495.1346 - val_loss: 23009241.0437\n",
            "Epoch 1476/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 554777.7138 - val_loss: 24421869.1687\n",
            "Epoch 1477/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 321744.5785 - val_loss: 25888815.9250\n",
            "Epoch 1478/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 260282.3766 - val_loss: 25558321.6125\n",
            "Epoch 1479/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 485790.8735 - val_loss: 26044792.9125\n",
            "Epoch 1480/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1239622.0575 - val_loss: 22977899.1313\n",
            "Epoch 1481/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2084091.1012 - val_loss: 24625325.7875\n",
            "Epoch 1482/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 694130.4242 - val_loss: 25329964.7875\n",
            "Epoch 1483/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 327259.5290 - val_loss: 26737880.3000\n",
            "Epoch 1484/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 481641.2563 - val_loss: 26069441.8500\n",
            "Epoch 1485/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 326318.1942 - val_loss: 24870494.2125\n",
            "Epoch 1486/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 203778.8636 - val_loss: 24343171.5437\n",
            "Epoch 1487/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 155360.6441 - val_loss: 25023662.0500\n",
            "Epoch 1488/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 203263.5377 - val_loss: 24318557.0625\n",
            "Epoch 1489/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 165053.2514 - val_loss: 26790917.8500\n",
            "Epoch 1490/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 174980.5837 - val_loss: 27002679.6750\n",
            "Epoch 1491/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 191572.3166 - val_loss: 23519288.9187\n",
            "Epoch 1492/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 218270.7176 - val_loss: 25885865.2375\n",
            "Epoch 1493/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 124478.6471 - val_loss: 26850352.3000\n",
            "Epoch 1494/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 263778.1262 - val_loss: 28464699.7000\n",
            "Epoch 1495/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1325668.5874 - val_loss: 30588999.1500\n",
            "Epoch 1496/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 832194.1742 - val_loss: 27186175.3000\n",
            "Epoch 1497/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 263880.6015 - val_loss: 26377497.8375\n",
            "Epoch 1498/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 277852.3527 - val_loss: 25848920.0375\n",
            "Epoch 1499/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 148968.9004 - val_loss: 27247031.5250\n",
            "Epoch 1500/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 774649.3162 - val_loss: 26335511.9750\n",
            "Epoch 1501/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1663143.2482 - val_loss: 24768052.7312\n",
            "Epoch 1502/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 795634.9686 - val_loss: 28660841.9000\n",
            "Epoch 1503/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 244069.4378 - val_loss: 26224742.7375\n",
            "Epoch 1504/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 348484.3411 - val_loss: 24646781.1875\n",
            "Epoch 1505/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 237188.9392 - val_loss: 25362300.9500\n",
            "Epoch 1506/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 573691.2345 - val_loss: 26494264.3125\n",
            "Epoch 1507/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 427136.2742 - val_loss: 26904070.5500\n",
            "Epoch 1508/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 274370.3084 - val_loss: 26093967.1125\n",
            "Epoch 1509/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 175837.1018 - val_loss: 26004141.2875\n",
            "Epoch 1510/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 184827.8035 - val_loss: 23409992.9594\n",
            "Epoch 1511/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 917498.0577 - val_loss: 27776738.9000\n",
            "Epoch 1512/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 330654.0629 - val_loss: 27514958.0500\n",
            "Epoch 1513/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 157382.9581 - val_loss: 29919547.6500\n",
            "Epoch 1514/2048\n",
            "90/90 [==============================] - 0s 3ms/step - loss: 104801.7408 - val_loss: 27718521.5500\n",
            "Epoch 1515/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 386027.3834 - val_loss: 27077443.5250\n",
            "Epoch 1516/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 311928.2697 - val_loss: 26701719.5125\n",
            "Epoch 1517/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 617189.8315 - val_loss: 23467008.9688\n",
            "Epoch 1518/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 231678.2453 - val_loss: 29297900.9000\n",
            "Epoch 1519/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 185128.4554 - val_loss: 26788035.8000\n",
            "Epoch 1520/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 128418.0007 - val_loss: 26966883.0000\n",
            "Epoch 1521/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 327690.6963 - val_loss: 27048065.5625\n",
            "Epoch 1522/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 325722.1948 - val_loss: 31350861.0000\n",
            "Epoch 1523/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 229043.3477 - val_loss: 30047116.9500\n",
            "Epoch 1524/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 301492.6120 - val_loss: 31102368.0000\n",
            "Epoch 1525/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 763596.4938 - val_loss: 28675003.9000\n",
            "Epoch 1526/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 666393.1377 - val_loss: 27644794.8250\n",
            "Epoch 1527/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1693495.0221 - val_loss: 29273301.6500\n",
            "Epoch 1528/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1169872.1616 - val_loss: 25454930.0750\n",
            "Epoch 1529/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 443927.1691 - val_loss: 28226863.7500\n",
            "Epoch 1530/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1806818.4682 - val_loss: 23570368.9375\n",
            "Epoch 1531/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 684996.6634 - val_loss: 25161418.6875\n",
            "Epoch 1532/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 339825.7791 - val_loss: 27107997.3000\n",
            "Epoch 1533/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 331179.8601 - val_loss: 25625392.0750\n",
            "Epoch 1534/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 292255.8136 - val_loss: 27073304.5500\n",
            "Epoch 1535/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 375501.2521 - val_loss: 24854947.8625\n",
            "Epoch 1536/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 528416.9021 - val_loss: 25533812.2625\n",
            "Epoch 1537/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1908332.0645 - val_loss: 26408220.9500\n",
            "Epoch 1538/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 488669.1290 - val_loss: 28676403.8250\n",
            "Epoch 1539/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 800671.4535 - val_loss: 27893658.3000\n",
            "Epoch 1540/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 230223.8646 - val_loss: 28035377.0750\n",
            "Epoch 1541/2048\n",
            "90/90 [==============================] - 0s 3ms/step - loss: 280294.7128 - val_loss: 27071963.9750\n",
            "Epoch 1542/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 412488.8862 - val_loss: 27357518.9250\n",
            "Epoch 1543/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 205532.7107 - val_loss: 27463887.2250\n",
            "Epoch 1544/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 189704.3545 - val_loss: 26863431.3750\n",
            "Epoch 1545/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 187676.8064 - val_loss: 27618561.7250\n",
            "Epoch 1546/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 645262.5019 - val_loss: 28408476.4750\n",
            "Epoch 1547/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 235996.1650 - val_loss: 25770899.9750\n",
            "Epoch 1548/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 330265.2658 - val_loss: 28104750.3000\n",
            "Epoch 1549/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2575900.2501 - val_loss: 26790067.2375\n",
            "Epoch 1550/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1775845.7194 - val_loss: 26884877.5750\n",
            "Epoch 1551/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 757597.7595 - val_loss: 24399587.6438\n",
            "Epoch 1552/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 349124.9669 - val_loss: 30112087.6500\n",
            "Epoch 1553/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 884359.6769 - val_loss: 30129470.9000\n",
            "Epoch 1554/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 518431.3599 - val_loss: 27196855.0000\n",
            "Epoch 1555/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 322432.6987 - val_loss: 28531651.1500\n",
            "Epoch 1556/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 271633.5561 - val_loss: 26886270.5000\n",
            "Epoch 1557/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 253543.6613 - val_loss: 24649758.8250\n",
            "Epoch 1558/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 589395.6486 - val_loss: 27839271.8000\n",
            "Epoch 1559/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 525867.2957 - val_loss: 28007850.3750\n",
            "Epoch 1560/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 340351.5734 - val_loss: 29464896.7500\n",
            "Epoch 1561/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1885276.3132 - val_loss: 32115370.6000\n",
            "Epoch 1562/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 934132.0053 - val_loss: 25749153.6000\n",
            "Epoch 1563/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 640019.6116 - val_loss: 28144755.8250\n",
            "Epoch 1564/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 348881.1635 - val_loss: 28421870.6500\n",
            "Epoch 1565/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 951359.5923 - val_loss: 25563940.3500\n",
            "Epoch 1566/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 742501.8428 - val_loss: 29360907.5000\n",
            "Epoch 1567/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1979398.1294 - val_loss: 28305478.8000\n",
            "Epoch 1568/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1001790.1838 - val_loss: 25937053.7375\n",
            "Epoch 1569/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 507386.6041 - val_loss: 25772334.5125\n",
            "Epoch 1570/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 728728.0320 - val_loss: 24985864.6250\n",
            "Epoch 1571/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 320629.9464 - val_loss: 27945292.8750\n",
            "Epoch 1572/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 189994.3000 - val_loss: 27449810.4500\n",
            "Epoch 1573/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 165906.0532 - val_loss: 27695777.4000\n",
            "Epoch 1574/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 296916.6543 - val_loss: 27930603.0000\n",
            "Epoch 1575/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 153516.4755 - val_loss: 24678333.5000\n",
            "Epoch 1576/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 211146.3163 - val_loss: 28701099.6250\n",
            "Epoch 1577/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 313936.3925 - val_loss: 26299085.0625\n",
            "Epoch 1578/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 168201.0274 - val_loss: 28030278.2750\n",
            "Epoch 1579/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 132709.6383 - val_loss: 27696123.9500\n",
            "Epoch 1580/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 179864.0478 - val_loss: 27833847.9000\n",
            "Epoch 1581/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 133492.2087 - val_loss: 30310868.2000\n",
            "Epoch 1582/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 140807.9708 - val_loss: 26348611.8500\n",
            "Epoch 1583/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 306988.5911 - val_loss: 26836169.3000\n",
            "Epoch 1584/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 409131.6242 - val_loss: 27006306.8750\n",
            "Epoch 1585/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 859141.9815 - val_loss: 23732700.7375\n",
            "Epoch 1586/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 294443.5606 - val_loss: 27121318.5500\n",
            "Epoch 1587/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 235488.2548 - val_loss: 29981203.9500\n",
            "Epoch 1588/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 214927.5230 - val_loss: 26886569.0500\n",
            "Epoch 1589/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 420536.9556 - val_loss: 25739862.1375\n",
            "Epoch 1590/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 634810.8530 - val_loss: 23720484.4000\n",
            "Epoch 1591/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 587504.4727 - val_loss: 28860486.8500\n",
            "Epoch 1592/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 961926.2155 - val_loss: 26714782.4250\n",
            "Epoch 1593/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 306526.2313 - val_loss: 27380684.8500\n",
            "Epoch 1594/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 205045.3428 - val_loss: 25839570.0875\n",
            "Epoch 1595/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 155063.6462 - val_loss: 28594023.1000\n",
            "Epoch 1596/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 220483.7527 - val_loss: 28087494.6000\n",
            "Epoch 1597/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 838135.4257 - val_loss: 26009173.6375\n",
            "Epoch 1598/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 192365.8310 - val_loss: 25148234.4125\n",
            "Epoch 1599/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 165820.9379 - val_loss: 25616199.0375\n",
            "Epoch 1600/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 302461.2619 - val_loss: 26157050.1250\n",
            "Epoch 1601/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 107345.4941 - val_loss: 27180192.2500\n",
            "Epoch 1602/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 247614.1255 - val_loss: 28459388.8000\n",
            "Epoch 1603/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 259355.1378 - val_loss: 27736513.1250\n",
            "Epoch 1604/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 164935.3138 - val_loss: 24250488.1562\n",
            "Epoch 1605/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 169060.5229 - val_loss: 25784860.1000\n",
            "Epoch 1606/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 451489.8565 - val_loss: 27005520.8000\n",
            "Epoch 1607/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 716767.1017 - val_loss: 24850366.6062\n",
            "Epoch 1608/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 433102.1106 - val_loss: 24939771.7625\n",
            "Epoch 1609/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 330859.7472 - val_loss: 23437609.1938\n",
            "Epoch 1610/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 356850.0863 - val_loss: 26314760.0125\n",
            "Epoch 1611/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 894597.3820 - val_loss: 28262176.7000\n",
            "Epoch 1612/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1317328.2266 - val_loss: 24843525.8250\n",
            "Epoch 1613/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 828452.7305 - val_loss: 23734593.8625\n",
            "Epoch 1614/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 442204.4326 - val_loss: 30649099.3000\n",
            "Epoch 1615/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 419135.3164 - val_loss: 26579749.8875\n",
            "Epoch 1616/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1368360.2242 - val_loss: 21775000.0953\n",
            "Epoch 1617/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 997726.6226 - val_loss: 24111648.6687\n",
            "Epoch 1618/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 410627.3695 - val_loss: 25025659.9250\n",
            "Epoch 1619/2048\n",
            "90/90 [==============================] - 0s 3ms/step - loss: 338462.2148 - val_loss: 24714014.4000\n",
            "Epoch 1620/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2502635.7356 - val_loss: 24243800.7875\n",
            "Epoch 1621/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 460018.2405 - val_loss: 26030224.8500\n",
            "Epoch 1622/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 111382.4032 - val_loss: 27375904.9750\n",
            "Epoch 1623/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 94646.3807 - val_loss: 27365571.8750\n",
            "Epoch 1624/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 99440.1331 - val_loss: 27254675.5750\n",
            "Epoch 1625/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 228731.2493 - val_loss: 25254905.7875\n",
            "Epoch 1626/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 97941.0221 - val_loss: 26268983.2000\n",
            "Epoch 1627/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 877405.7168 - val_loss: 23499870.6875\n",
            "Epoch 1628/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1084648.5967 - val_loss: 26415937.8750\n",
            "Epoch 1629/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 190964.5363 - val_loss: 30133529.9500\n",
            "Epoch 1630/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 607804.1119 - val_loss: 28775897.1500\n",
            "Epoch 1631/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 346932.9219 - val_loss: 28590438.7000\n",
            "Epoch 1632/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 635402.1285 - val_loss: 25087021.8750\n",
            "Epoch 1633/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 280196.6482 - val_loss: 26649158.9000\n",
            "Epoch 1634/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 179863.4913 - val_loss: 27490985.8000\n",
            "Epoch 1635/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 562776.1925 - val_loss: 26981487.2250\n",
            "Epoch 1636/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1344170.5824 - val_loss: 26736009.0250\n",
            "Epoch 1637/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 621618.3479 - val_loss: 27818348.6000\n",
            "Epoch 1638/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 151995.9812 - val_loss: 27969654.6500\n",
            "Epoch 1639/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 373951.9883 - val_loss: 26392878.5750\n",
            "Epoch 1640/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 282222.8687 - val_loss: 25484826.5625\n",
            "Epoch 1641/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 101266.2854 - val_loss: 26239320.0250\n",
            "Epoch 1642/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 90151.6409 - val_loss: 26904696.4500\n",
            "Epoch 1643/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 148549.8783 - val_loss: 26213828.3250\n",
            "Epoch 1644/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 518307.9854 - val_loss: 25145190.9250\n",
            "Epoch 1645/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1975401.2010 - val_loss: 23045303.0625\n",
            "Epoch 1646/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1262429.3763 - val_loss: 24979545.4375\n",
            "Epoch 1647/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 388688.9458 - val_loss: 25410840.3250\n",
            "Epoch 1648/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 182071.8331 - val_loss: 28605371.8500\n",
            "Epoch 1649/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 361021.9309 - val_loss: 27059595.1000\n",
            "Epoch 1650/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 341501.7214 - val_loss: 26913573.0500\n",
            "Epoch 1651/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 358443.2580 - val_loss: 26750818.8000\n",
            "Epoch 1652/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 178465.7925 - val_loss: 26777287.5500\n",
            "Epoch 1653/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 491010.7019 - val_loss: 23787407.4125\n",
            "Epoch 1654/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 403871.5985 - val_loss: 26389968.1750\n",
            "Epoch 1655/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 276994.7602 - val_loss: 27115054.4500\n",
            "Epoch 1656/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 135189.7612 - val_loss: 24635859.1313\n",
            "Epoch 1657/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 191673.5441 - val_loss: 25695706.0625\n",
            "Epoch 1658/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 157867.8343 - val_loss: 27258202.6000\n",
            "Epoch 1659/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 132488.1386 - val_loss: 29431735.2500\n",
            "Epoch 1660/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 125961.3659 - val_loss: 29925966.0500\n",
            "Epoch 1661/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 680731.8059 - val_loss: 22911080.8375\n",
            "Epoch 1662/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 448362.2647 - val_loss: 25589554.6375\n",
            "Epoch 1663/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 464711.9951 - val_loss: 24374087.4750\n",
            "Epoch 1664/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1176209.7656 - val_loss: 25282100.4750\n",
            "Epoch 1665/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 302038.5060 - val_loss: 27416418.4250\n",
            "Epoch 1666/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 253232.0267 - val_loss: 26378695.6750\n",
            "Epoch 1667/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 334574.9250 - val_loss: 25189760.8000\n",
            "Epoch 1668/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 683336.4942 - val_loss: 29694709.8000\n",
            "Epoch 1669/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 716974.4418 - val_loss: 27715663.5500\n",
            "Epoch 1670/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 433112.8407 - val_loss: 27501356.8000\n",
            "Epoch 1671/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 252194.0466 - val_loss: 26413539.1625\n",
            "Epoch 1672/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 190233.8559 - val_loss: 25312889.4500\n",
            "Epoch 1673/2048\n",
            "90/90 [==============================] - 0s 3ms/step - loss: 325489.9866 - val_loss: 28258024.3750\n",
            "Epoch 1674/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 367763.1955 - val_loss: 28190262.2750\n",
            "Epoch 1675/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 445637.1656 - val_loss: 29127391.2500\n",
            "Epoch 1676/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 258730.5075 - val_loss: 29706359.1000\n",
            "Epoch 1677/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 303304.1380 - val_loss: 28180749.6000\n",
            "Epoch 1678/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 126690.4995 - val_loss: 27244458.5000\n",
            "Epoch 1679/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 234462.2925 - val_loss: 25856303.2375\n",
            "Epoch 1680/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 184074.2003 - val_loss: 29006616.9000\n",
            "Epoch 1681/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1308636.6102 - val_loss: 22775686.5437\n",
            "Epoch 1682/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2084228.6710 - val_loss: 24533353.1250\n",
            "Epoch 1683/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2126564.4223 - val_loss: 27806681.4500\n",
            "Epoch 1684/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 806657.4380 - val_loss: 22736517.7906\n",
            "Epoch 1685/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 262384.8686 - val_loss: 25461464.5500\n",
            "Epoch 1686/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 720736.9108 - val_loss: 26888099.6250\n",
            "Epoch 1687/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 157600.0404 - val_loss: 25142391.8750\n",
            "Epoch 1688/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 157386.7240 - val_loss: 27020519.5000\n",
            "Epoch 1689/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 235594.2738 - val_loss: 25072759.4000\n",
            "Epoch 1690/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 103119.7552 - val_loss: 26189608.9750\n",
            "Epoch 1691/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 239829.0416 - val_loss: 27253177.2500\n",
            "Epoch 1692/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 224903.5963 - val_loss: 26100095.0000\n",
            "Epoch 1693/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 152304.5018 - val_loss: 27937212.9250\n",
            "Epoch 1694/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 99798.3827 - val_loss: 26510259.8375\n",
            "Epoch 1695/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 98540.6402 - val_loss: 23489461.3562\n",
            "Epoch 1696/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 115947.9273 - val_loss: 23651556.4438\n",
            "Epoch 1697/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 199429.1342 - val_loss: 26527978.3250\n",
            "Epoch 1698/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 286316.9782 - val_loss: 24875913.8250\n",
            "Epoch 1699/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 111519.1111 - val_loss: 26504286.2500\n",
            "Epoch 1700/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 292514.7012 - val_loss: 27160539.5500\n",
            "Epoch 1701/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 414417.4634 - val_loss: 24706041.6875\n",
            "Epoch 1702/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 601109.4463 - val_loss: 27503288.8500\n",
            "Epoch 1703/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 549762.5859 - val_loss: 25434988.2250\n",
            "Epoch 1704/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 142007.6322 - val_loss: 26986529.7500\n",
            "Epoch 1705/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 426297.2887 - val_loss: 25194710.5000\n",
            "Epoch 1706/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 165846.9498 - val_loss: 25133765.7500\n",
            "Epoch 1707/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 243577.7687 - val_loss: 25827928.2375\n",
            "Epoch 1708/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 508455.3321 - val_loss: 28103248.5000\n",
            "Epoch 1709/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 222977.1799 - val_loss: 27190931.1500\n",
            "Epoch 1710/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 263130.2859 - val_loss: 26037640.1625\n",
            "Epoch 1711/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 248564.7328 - val_loss: 27341935.7000\n",
            "Epoch 1712/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 581693.5041 - val_loss: 23168307.9156\n",
            "Epoch 1713/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 346962.0578 - val_loss: 25316646.7750\n",
            "Epoch 1714/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 331207.7869 - val_loss: 24689938.1750\n",
            "Epoch 1715/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 882088.6833 - val_loss: 27702077.0250\n",
            "Epoch 1716/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1096530.2332 - val_loss: 28149860.6500\n",
            "Epoch 1717/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 626165.2176 - val_loss: 26795149.7500\n",
            "Epoch 1718/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 936654.2748 - val_loss: 30312537.2000\n",
            "Epoch 1719/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 341947.2541 - val_loss: 25738927.4500\n",
            "Epoch 1720/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 269242.0241 - val_loss: 27476867.6250\n",
            "Epoch 1721/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 277336.6029 - val_loss: 25866925.9750\n",
            "Epoch 1722/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 824975.5848 - val_loss: 24824392.9750\n",
            "Epoch 1723/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 850410.0455 - val_loss: 22963402.5063\n",
            "Epoch 1724/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 306128.7152 - val_loss: 25488154.7625\n",
            "Epoch 1725/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 206038.5970 - val_loss: 26378867.1250\n",
            "Epoch 1726/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 322157.6466 - val_loss: 27393423.7500\n",
            "Epoch 1727/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 162649.9773 - val_loss: 29896302.4500\n",
            "Epoch 1728/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 121377.3790 - val_loss: 29444936.8000\n",
            "Epoch 1729/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 229355.2320 - val_loss: 27237849.6500\n",
            "Epoch 1730/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 329968.7754 - val_loss: 28899927.5500\n",
            "Epoch 1731/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 592777.1668 - val_loss: 25940726.7375\n",
            "Epoch 1732/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 855855.9591 - val_loss: 29405050.0500\n",
            "Epoch 1733/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2327097.5076 - val_loss: 19359963.8680\n",
            "Epoch 1734/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 874265.1853 - val_loss: 22977418.6500\n",
            "Epoch 1735/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 282666.8800 - val_loss: 23610397.7000\n",
            "Epoch 1736/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 339168.8258 - val_loss: 23982663.6750\n",
            "Epoch 1737/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 155332.7630 - val_loss: 25206141.2000\n",
            "Epoch 1738/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 443517.7316 - val_loss: 24767612.7625\n",
            "Epoch 1739/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 252293.2530 - val_loss: 28863528.5500\n",
            "Epoch 1740/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 147558.7304 - val_loss: 26708592.8000\n",
            "Epoch 1741/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 109621.3763 - val_loss: 27306947.4500\n",
            "Epoch 1742/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 344919.0696 - val_loss: 26743574.4250\n",
            "Epoch 1743/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 201170.8204 - val_loss: 27298890.1500\n",
            "Epoch 1744/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 822198.7259 - val_loss: 26871581.7500\n",
            "Epoch 1745/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 277503.8639 - val_loss: 27064036.0500\n",
            "Epoch 1746/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 119583.7187 - val_loss: 26270583.3750\n",
            "Epoch 1747/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 346060.3012 - val_loss: 31114236.2000\n",
            "Epoch 1748/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2097943.0092 - val_loss: 25483842.4625\n",
            "Epoch 1749/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 571300.1427 - val_loss: 25247059.1875\n",
            "Epoch 1750/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 215103.4807 - val_loss: 26166602.0625\n",
            "Epoch 1751/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1234858.3673 - val_loss: 26617172.3750\n",
            "Epoch 1752/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1521871.0148 - val_loss: 26565379.5750\n",
            "Epoch 1753/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 279252.3327 - val_loss: 27648977.1750\n",
            "Epoch 1754/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 218469.1860 - val_loss: 24046540.2437\n",
            "Epoch 1755/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2154107.8079 - val_loss: 26110920.6250\n",
            "Epoch 1756/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1073140.2791 - val_loss: 25171395.7250\n",
            "Epoch 1757/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 312566.8874 - val_loss: 25156486.7000\n",
            "Epoch 1758/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 149393.8714 - val_loss: 25488315.1375\n",
            "Epoch 1759/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 114982.3913 - val_loss: 25779296.8000\n",
            "Epoch 1760/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 113172.8171 - val_loss: 26135051.9000\n",
            "Epoch 1761/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 86190.3994 - val_loss: 26294142.6375\n",
            "Epoch 1762/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1014404.8342 - val_loss: 25850271.1625\n",
            "Epoch 1763/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 384116.3320 - val_loss: 25312341.2750\n",
            "Epoch 1764/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 147862.1801 - val_loss: 24486638.1625\n",
            "Epoch 1765/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 917720.5134 - val_loss: 26365541.7250\n",
            "Epoch 1766/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 300447.4150 - val_loss: 26920689.1000\n",
            "Epoch 1767/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 636686.4186 - val_loss: 22953361.7594\n",
            "Epoch 1768/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 161280.5004 - val_loss: 26283288.8500\n",
            "Epoch 1769/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 178577.3611 - val_loss: 27406991.6750\n",
            "Epoch 1770/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 324714.6631 - val_loss: 27190978.3500\n",
            "Epoch 1771/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 281987.6828 - val_loss: 27256964.9500\n",
            "Epoch 1772/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 157812.0762 - val_loss: 28609278.1750\n",
            "Epoch 1773/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 391471.8275 - val_loss: 26279018.3625\n",
            "Epoch 1774/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 521890.6031 - val_loss: 29718678.1000\n",
            "Epoch 1775/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 727938.0560 - val_loss: 24946309.3875\n",
            "Epoch 1776/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1619184.9918 - val_loss: 24211715.5688\n",
            "Epoch 1777/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 655786.8910 - val_loss: 23296975.9281\n",
            "Epoch 1778/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 841904.2169 - val_loss: 27899676.0250\n",
            "Epoch 1779/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 540629.7324 - val_loss: 26529503.3625\n",
            "Epoch 1780/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 166223.3811 - val_loss: 29557779.6500\n",
            "Epoch 1781/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 230444.6306 - val_loss: 29427583.6500\n",
            "Epoch 1782/2048\n",
            "90/90 [==============================] - 0s 3ms/step - loss: 196641.1601 - val_loss: 27830354.8250\n",
            "Epoch 1783/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 234852.1586 - val_loss: 27817875.0500\n",
            "Epoch 1784/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 142626.3556 - val_loss: 28156181.1500\n",
            "Epoch 1785/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 234279.8052 - val_loss: 26697394.3000\n",
            "Epoch 1786/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 364918.9503 - val_loss: 29146427.6000\n",
            "Epoch 1787/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 387915.8318 - val_loss: 28661983.2500\n",
            "Epoch 1788/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 185320.7307 - val_loss: 27244290.2750\n",
            "Epoch 1789/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 219777.0727 - val_loss: 28147861.4000\n",
            "Epoch 1790/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 128784.3020 - val_loss: 26964367.3875\n",
            "Epoch 1791/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 590580.5123 - val_loss: 27722355.9750\n",
            "Epoch 1792/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 254226.9730 - val_loss: 28036473.8750\n",
            "Epoch 1793/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 162898.1161 - val_loss: 25492143.7000\n",
            "Epoch 1794/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 134093.0970 - val_loss: 27901010.9250\n",
            "Epoch 1795/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 237338.4214 - val_loss: 26346626.8000\n",
            "Epoch 1796/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 179712.3218 - val_loss: 22690505.8125\n",
            "Epoch 1797/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1258962.5408 - val_loss: 29394799.7250\n",
            "Epoch 1798/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 794269.7607 - val_loss: 25077102.8250\n",
            "Epoch 1799/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 231275.0234 - val_loss: 24862906.6250\n",
            "Epoch 1800/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 258655.2564 - val_loss: 26006666.2500\n",
            "Epoch 1801/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 671557.1881 - val_loss: 24709411.6375\n",
            "Epoch 1802/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 271517.6521 - val_loss: 27408014.8000\n",
            "Epoch 1803/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 181848.4113 - val_loss: 26509504.0250\n",
            "Epoch 1804/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 407118.7455 - val_loss: 24977796.4750\n",
            "Epoch 1805/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 245525.7802 - val_loss: 23555457.8938\n",
            "Epoch 1806/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 452459.2564 - val_loss: 26623612.1625\n",
            "Epoch 1807/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 191513.8279 - val_loss: 26650319.0375\n",
            "Epoch 1808/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 117280.2849 - val_loss: 27793398.1500\n",
            "Epoch 1809/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 189033.5015 - val_loss: 26680921.3125\n",
            "Epoch 1810/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1414197.0538 - val_loss: 23503367.3687\n",
            "Epoch 1811/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 589778.4246 - val_loss: 24957831.2875\n",
            "Epoch 1812/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 182719.4088 - val_loss: 26357172.2750\n",
            "Epoch 1813/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 93642.8194 - val_loss: 26958371.3750\n",
            "Epoch 1814/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 383685.4148 - val_loss: 25957004.1875\n",
            "Epoch 1815/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 164013.8199 - val_loss: 27371144.4750\n",
            "Epoch 1816/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 644076.5549 - val_loss: 27764982.1000\n",
            "Epoch 1817/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 299267.1518 - val_loss: 24714732.7625\n",
            "Epoch 1818/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 636638.9514 - val_loss: 27191826.7250\n",
            "Epoch 1819/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 579686.8424 - val_loss: 30606580.9500\n",
            "Epoch 1820/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 373810.4195 - val_loss: 25674882.7750\n",
            "Epoch 1821/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 490610.9384 - val_loss: 25047814.4375\n",
            "Epoch 1822/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 907539.0922 - val_loss: 30495327.8500\n",
            "Epoch 1823/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 908231.9420 - val_loss: 29127357.6500\n",
            "Epoch 1824/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1361142.2008 - val_loss: 24506940.0750\n",
            "Epoch 1825/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 602712.2016 - val_loss: 26023525.4375\n",
            "Epoch 1826/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 214259.5412 - val_loss: 25418453.8250\n",
            "Epoch 1827/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 258561.7770 - val_loss: 24570925.9125\n",
            "Epoch 1828/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1258896.8048 - val_loss: 29034795.5000\n",
            "Epoch 1829/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 324595.9132 - val_loss: 30505818.3500\n",
            "Epoch 1830/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 397096.4932 - val_loss: 23441739.1125\n",
            "Epoch 1831/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 399841.7930 - val_loss: 25905241.6125\n",
            "Epoch 1832/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 494556.6404 - val_loss: 27608172.0000\n",
            "Epoch 1833/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 163994.0362 - val_loss: 27050922.3000\n",
            "Epoch 1834/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 55858.7070 - val_loss: 27107893.0250\n",
            "Epoch 1835/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 274017.7763 - val_loss: 28336437.7000\n",
            "Epoch 1836/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 195351.9558 - val_loss: 26218581.1875\n",
            "Epoch 1837/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 248319.7364 - val_loss: 29128294.3500\n",
            "Epoch 1838/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 350533.2429 - val_loss: 26388853.3250\n",
            "Epoch 1839/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 168856.7548 - val_loss: 28301744.1000\n",
            "Epoch 1840/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 168179.0105 - val_loss: 29405141.0500\n",
            "Epoch 1841/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 578683.2303 - val_loss: 26350101.9375\n",
            "Epoch 1842/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 643847.8623 - val_loss: 28958073.7500\n",
            "Epoch 1843/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2157606.1840 - val_loss: 28391083.2000\n",
            "Epoch 1844/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1115522.1380 - val_loss: 26177523.1000\n",
            "Epoch 1845/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1374385.9917 - val_loss: 25964513.2750\n",
            "Epoch 1846/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 253842.0878 - val_loss: 27294516.7500\n",
            "Epoch 1847/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 202866.3678 - val_loss: 26089486.2500\n",
            "Epoch 1848/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 126198.9464 - val_loss: 26525488.1875\n",
            "Epoch 1849/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 112900.6932 - val_loss: 25885006.5000\n",
            "Epoch 1850/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 142773.9983 - val_loss: 26825972.3125\n",
            "Epoch 1851/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 578104.6405 - val_loss: 23798327.5625\n",
            "Epoch 1852/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 578278.8377 - val_loss: 23378285.1000\n",
            "Epoch 1853/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 371988.7804 - val_loss: 25662885.9000\n",
            "Epoch 1854/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 335555.5924 - val_loss: 28643844.3250\n",
            "Epoch 1855/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 363930.6224 - val_loss: 26822746.9875\n",
            "Epoch 1856/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 304052.4831 - val_loss: 27184939.1500\n",
            "Epoch 1857/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 188717.7631 - val_loss: 25471738.2000\n",
            "Epoch 1858/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 581715.3630 - val_loss: 24243295.7937\n",
            "Epoch 1859/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 338369.4673 - val_loss: 25846923.4875\n",
            "Epoch 1860/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 492420.5719 - val_loss: 25683763.6875\n",
            "Epoch 1861/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 639810.6110 - val_loss: 28248312.4750\n",
            "Epoch 1862/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 503201.9732 - val_loss: 26060903.1250\n",
            "Epoch 1863/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 233280.7533 - val_loss: 25702882.6250\n",
            "Epoch 1864/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1202837.7380 - val_loss: 27839629.9250\n",
            "Epoch 1865/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 341542.4364 - val_loss: 26380461.0625\n",
            "Epoch 1866/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1243033.7626 - val_loss: 29537589.5500\n",
            "Epoch 1867/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 341190.6439 - val_loss: 28343921.8500\n",
            "Epoch 1868/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 729422.4347 - val_loss: 29805391.4250\n",
            "Epoch 1869/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 906224.8212 - val_loss: 24776340.5500\n",
            "Epoch 1870/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 169631.7092 - val_loss: 24529070.7437\n",
            "Epoch 1871/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 249730.1408 - val_loss: 26035873.1000\n",
            "Epoch 1872/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 465673.7512 - val_loss: 24829533.1750\n",
            "Epoch 1873/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1704225.8201 - val_loss: 31118720.3000\n",
            "Epoch 1874/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 720805.6243 - val_loss: 25814924.5750\n",
            "Epoch 1875/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 757065.5541 - val_loss: 25562638.0000\n",
            "Epoch 1876/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 711527.9998 - val_loss: 26720765.3000\n",
            "Epoch 1877/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 899179.0732 - val_loss: 26697379.7250\n",
            "Epoch 1878/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 359707.5912 - val_loss: 25382900.0625\n",
            "Epoch 1879/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 437031.8515 - val_loss: 28793605.0500\n",
            "Epoch 1880/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 156876.3245 - val_loss: 28181724.4000\n",
            "Epoch 1881/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 163804.7684 - val_loss: 26565103.1750\n",
            "Epoch 1882/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 167554.0285 - val_loss: 29039746.1750\n",
            "Epoch 1883/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 439553.3978 - val_loss: 29048039.2500\n",
            "Epoch 1884/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 527270.3794 - val_loss: 26451734.0375\n",
            "Epoch 1885/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 695949.9201 - val_loss: 24652051.1375\n",
            "Epoch 1886/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 352461.2735 - val_loss: 25205963.9875\n",
            "Epoch 1887/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 394175.5182 - val_loss: 24705841.5813\n",
            "Epoch 1888/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 449268.3026 - val_loss: 26480331.5500\n",
            "Epoch 1889/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 325870.9990 - val_loss: 25791918.8125\n",
            "Epoch 1890/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 84688.5849 - val_loss: 28250205.9250\n",
            "Epoch 1891/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 80304.5349 - val_loss: 27331082.5500\n",
            "Epoch 1892/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 489597.3544 - val_loss: 25730657.4500\n",
            "Epoch 1893/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 224061.6064 - val_loss: 28194980.6000\n",
            "Epoch 1894/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1050260.7168 - val_loss: 29010721.9500\n",
            "Epoch 1895/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1371550.2722 - val_loss: 23957731.6750\n",
            "Epoch 1896/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 990594.5159 - val_loss: 23793401.7000\n",
            "Epoch 1897/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 502343.3988 - val_loss: 26918998.2750\n",
            "Epoch 1898/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 200643.9049 - val_loss: 28260638.4500\n",
            "Epoch 1899/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 160409.8395 - val_loss: 27842827.6250\n",
            "Epoch 1900/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 397389.8721 - val_loss: 28524378.1500\n",
            "Epoch 1901/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 259740.1253 - val_loss: 24303058.7437\n",
            "Epoch 1902/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 322649.6327 - val_loss: 24976688.1750\n",
            "Epoch 1903/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 135056.5783 - val_loss: 25051021.7250\n",
            "Epoch 1904/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 145204.7790 - val_loss: 28834184.8000\n",
            "Epoch 1905/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 120043.8213 - val_loss: 28376411.9750\n",
            "Epoch 1906/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1585841.2513 - val_loss: 30688640.1000\n",
            "Epoch 1907/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2246303.1785 - val_loss: 20415903.4000\n",
            "Epoch 1908/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 467540.4916 - val_loss: 28399413.8000\n",
            "Epoch 1909/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 423778.7035 - val_loss: 20566396.7656\n",
            "Epoch 1910/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1151832.9150 - val_loss: 25845711.6625\n",
            "Epoch 1911/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1028320.8235 - val_loss: 24324101.0625\n",
            "Epoch 1912/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 414366.3396 - val_loss: 24461082.2812\n",
            "Epoch 1913/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 496121.8596 - val_loss: 25099809.4750\n",
            "Epoch 1914/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 302506.6273 - val_loss: 26950269.9250\n",
            "Epoch 1915/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 582022.7714 - val_loss: 24619148.4125\n",
            "Epoch 1916/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 177306.8070 - val_loss: 24052491.9937\n",
            "Epoch 1917/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 208530.9055 - val_loss: 23664984.4438\n",
            "Epoch 1918/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 271786.3534 - val_loss: 26193146.5750\n",
            "Epoch 1919/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 587914.6269 - val_loss: 30549386.2000\n",
            "Epoch 1920/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 904019.0635 - val_loss: 26427139.6625\n",
            "Epoch 1921/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 721770.8226 - val_loss: 26345405.2250\n",
            "Epoch 1922/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 617330.7073 - val_loss: 26184855.1000\n",
            "Epoch 1923/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 526002.4059 - val_loss: 28377628.5000\n",
            "Epoch 1924/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 221383.8630 - val_loss: 24974881.0000\n",
            "Epoch 1925/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 132745.7688 - val_loss: 24516076.1812\n",
            "Epoch 1926/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 110734.7265 - val_loss: 27776166.5500\n",
            "Epoch 1927/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 87986.9620 - val_loss: 26060855.5500\n",
            "Epoch 1928/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 248690.8356 - val_loss: 27591638.8000\n",
            "Epoch 1929/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 309520.7307 - val_loss: 26519890.6000\n",
            "Epoch 1930/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 393023.1771 - val_loss: 29568039.9500\n",
            "Epoch 1931/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 180554.4604 - val_loss: 27697386.2750\n",
            "Epoch 1932/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 143772.0183 - val_loss: 27603275.0250\n",
            "Epoch 1933/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 89949.4952 - val_loss: 26543240.2500\n",
            "Epoch 1934/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 94142.0956 - val_loss: 28027199.3750\n",
            "Epoch 1935/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 184077.3767 - val_loss: 28573903.8500\n",
            "Epoch 1936/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 153185.2966 - val_loss: 27230706.6250\n",
            "Epoch 1937/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 435938.3404 - val_loss: 27937752.7250\n",
            "Epoch 1938/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 218745.3402 - val_loss: 27470745.5500\n",
            "Epoch 1939/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 463492.7988 - val_loss: 26210354.2500\n",
            "Epoch 1940/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1335652.8350 - val_loss: 28536526.0000\n",
            "Epoch 1941/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 436805.3604 - val_loss: 29379141.8500\n",
            "Epoch 1942/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 466354.8889 - val_loss: 30111887.9500\n",
            "Epoch 1943/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1949727.8327 - val_loss: 26077897.2000\n",
            "Epoch 1944/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 312970.3834 - val_loss: 25019039.5875\n",
            "Epoch 1945/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 175352.4152 - val_loss: 24203977.1125\n",
            "Epoch 1946/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 222795.0172 - val_loss: 25159489.1125\n",
            "Epoch 1947/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 750173.4871 - val_loss: 24379822.1625\n",
            "Epoch 1948/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 176741.8811 - val_loss: 27116237.2500\n",
            "Epoch 1949/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 496852.6141 - val_loss: 24462742.7000\n",
            "Epoch 1950/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1801087.3921 - val_loss: 25804562.3500\n",
            "Epoch 1951/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1713814.8924 - val_loss: 30132616.2000\n",
            "Epoch 1952/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 559096.9409 - val_loss: 28920938.7500\n",
            "Epoch 1953/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 785482.0376 - val_loss: 28606730.8500\n",
            "Epoch 1954/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 450474.5646 - val_loss: 28925709.3500\n",
            "Epoch 1955/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 145213.0734 - val_loss: 26578792.8625\n",
            "Epoch 1956/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 82624.2316 - val_loss: 27739386.8000\n",
            "Epoch 1957/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 64232.7987 - val_loss: 26616952.6250\n",
            "Epoch 1958/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 75034.9877 - val_loss: 25971686.7250\n",
            "Epoch 1959/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 104880.4237 - val_loss: 26692499.2750\n",
            "Epoch 1960/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 104770.5356 - val_loss: 28280994.5750\n",
            "Epoch 1961/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 88801.6520 - val_loss: 27099696.2000\n",
            "Epoch 1962/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 62451.8139 - val_loss: 27792537.5500\n",
            "Epoch 1963/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 73375.1807 - val_loss: 26907391.1000\n",
            "Epoch 1964/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 450550.1202 - val_loss: 25363668.2375\n",
            "Epoch 1965/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 195324.6724 - val_loss: 27664774.3500\n",
            "Epoch 1966/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 166314.9125 - val_loss: 25963537.2500\n",
            "Epoch 1967/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 122031.3728 - val_loss: 25710373.7375\n",
            "Epoch 1968/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 293481.8603 - val_loss: 26080394.8125\n",
            "Epoch 1969/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 327538.5272 - val_loss: 28105752.6000\n",
            "Epoch 1970/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 178729.1728 - val_loss: 25623772.8000\n",
            "Epoch 1971/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 174267.7015 - val_loss: 27160051.1250\n",
            "Epoch 1972/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 138868.1074 - val_loss: 26047355.0750\n",
            "Epoch 1973/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 108168.0928 - val_loss: 25266665.0125\n",
            "Epoch 1974/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 154008.1277 - val_loss: 28335400.8750\n",
            "Epoch 1975/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 825993.1781 - val_loss: 26017973.8250\n",
            "Epoch 1976/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 281367.7972 - val_loss: 26497640.2500\n",
            "Epoch 1977/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1763000.0518 - val_loss: 25130925.3875\n",
            "Epoch 1978/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 518150.0916 - val_loss: 26649397.1500\n",
            "Epoch 1979/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 576586.7075 - val_loss: 29516081.8000\n",
            "Epoch 1980/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 360796.9900 - val_loss: 25428178.8250\n",
            "Epoch 1981/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 455115.3126 - val_loss: 27962142.5500\n",
            "Epoch 1982/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 201770.1933 - val_loss: 26633116.9500\n",
            "Epoch 1983/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 907149.7909 - val_loss: 30527978.5000\n",
            "Epoch 1984/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 2029111.3383 - val_loss: 24670482.1375\n",
            "Epoch 1985/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 522258.4335 - val_loss: 25843198.5000\n",
            "Epoch 1986/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 399397.9752 - val_loss: 27692303.2750\n",
            "Epoch 1987/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 355132.4608 - val_loss: 25341097.6500\n",
            "Epoch 1988/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 174929.6223 - val_loss: 25849075.1875\n",
            "Epoch 1989/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 759242.4804 - val_loss: 25690422.0500\n",
            "Epoch 1990/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 420305.5735 - val_loss: 28226520.0250\n",
            "Epoch 1991/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 479919.6686 - val_loss: 29261309.0750\n",
            "Epoch 1992/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 446522.8613 - val_loss: 28627513.0000\n",
            "Epoch 1993/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 304065.9733 - val_loss: 27633595.0750\n",
            "Epoch 1994/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 169822.4752 - val_loss: 28521853.0500\n",
            "Epoch 1995/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 268435.0568 - val_loss: 25611128.7250\n",
            "Epoch 1996/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 802326.4115 - val_loss: 26500151.6500\n",
            "Epoch 1997/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 446790.1136 - val_loss: 26842360.1000\n",
            "Epoch 1998/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 380412.6223 - val_loss: 25487139.8875\n",
            "Epoch 1999/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 550942.3987 - val_loss: 27099707.0750\n",
            "Epoch 2000/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 307388.1867 - val_loss: 27728300.1750\n",
            "Epoch 2001/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 169079.3114 - val_loss: 26734431.5500\n",
            "Epoch 2002/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 139427.4009 - val_loss: 28967904.1000\n",
            "Epoch 2003/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 547281.1062 - val_loss: 26142992.8500\n",
            "Epoch 2004/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1931256.9223 - val_loss: 22223581.9312\n",
            "Epoch 2005/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 272808.6557 - val_loss: 26421772.9750\n",
            "Epoch 2006/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 163119.1319 - val_loss: 24457167.4250\n",
            "Epoch 2007/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 261259.4235 - val_loss: 27171098.6000\n",
            "Epoch 2008/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 347118.3436 - val_loss: 28330042.5000\n",
            "Epoch 2009/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1790602.3126 - val_loss: 26617942.9500\n",
            "Epoch 2010/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 295051.2622 - val_loss: 26700962.4250\n",
            "Epoch 2011/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 496978.4795 - val_loss: 27669599.4750\n",
            "Epoch 2012/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 564276.3912 - val_loss: 27462145.5750\n",
            "Epoch 2013/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 247981.0514 - val_loss: 27204230.3000\n",
            "Epoch 2014/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 117663.0339 - val_loss: 26670070.7250\n",
            "Epoch 2015/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 115891.6078 - val_loss: 26962352.2125\n",
            "Epoch 2016/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 542301.8573 - val_loss: 25089053.0000\n",
            "Epoch 2017/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 787781.4110 - val_loss: 25800436.6375\n",
            "Epoch 2018/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 582020.4261 - val_loss: 27437343.0500\n",
            "Epoch 2019/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 290783.7021 - val_loss: 25659893.6750\n",
            "Epoch 2020/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 103058.1196 - val_loss: 27446879.9000\n",
            "Epoch 2021/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 66540.1525 - val_loss: 25181413.7875\n",
            "Epoch 2022/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 97822.6839 - val_loss: 26233630.6000\n",
            "Epoch 2023/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 100626.9245 - val_loss: 28342731.9000\n",
            "Epoch 2024/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 98213.4860 - val_loss: 27376043.0000\n",
            "Epoch 2025/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 235458.4657 - val_loss: 27365771.5500\n",
            "Epoch 2026/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 777770.6238 - val_loss: 26813672.6000\n",
            "Epoch 2027/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 517469.0533 - val_loss: 26734734.6000\n",
            "Epoch 2028/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 362179.6663 - val_loss: 27437030.2750\n",
            "Epoch 2029/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 504356.8461 - val_loss: 27180615.1250\n",
            "Epoch 2030/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 608161.9508 - val_loss: 26169648.3000\n",
            "Epoch 2031/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 649612.4174 - val_loss: 29046562.8500\n",
            "Epoch 2032/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 187254.8994 - val_loss: 26500745.9875\n",
            "Epoch 2033/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 253823.8403 - val_loss: 26906928.6875\n",
            "Epoch 2034/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 136316.5260 - val_loss: 28670825.1500\n",
            "Epoch 2035/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 178230.1005 - val_loss: 26941366.2375\n",
            "Epoch 2036/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 346624.8765 - val_loss: 24441819.8438\n",
            "Epoch 2037/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 352710.0056 - val_loss: 28097685.2000\n",
            "Epoch 2038/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 93185.9267 - val_loss: 26190460.2250\n",
            "Epoch 2039/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 190627.8764 - val_loss: 27331532.2250\n",
            "Epoch 2040/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 440339.6936 - val_loss: 27310533.2750\n",
            "Epoch 2041/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 497050.8144 - val_loss: 28624918.8250\n",
            "Epoch 2042/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 239841.0896 - val_loss: 26290580.0500\n",
            "Epoch 2043/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 154196.0211 - val_loss: 28820807.5500\n",
            "Epoch 2044/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 120119.1264 - val_loss: 26839921.8625\n",
            "Epoch 2045/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 222178.3346 - val_loss: 26677222.9250\n",
            "Epoch 2046/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 446546.1181 - val_loss: 29513155.6500\n",
            "Epoch 2047/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 1688419.5052 - val_loss: 22026604.9125\n",
            "Epoch 2048/2048\n",
            "90/90 [==============================] - 0s 2ms/step - loss: 4161097.3665 - val_loss: 27247408.8750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f907e94d978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6PTuuX8T-pt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "42dfdfc3-17fe-4c70-b2d0-fe12adff8c8b"
      },
      "source": [
        "for i in range(len(america_cases)):\n",
        "  test_input = array([i])\n",
        "  test_input = test_input.reshape((1, 1, 1))\n",
        "  test_output = model.predict(test_input, verbose=0)\n",
        "  print(f\"train: {america_cases[i]}      test: {test_output[0][0]}    off by = {(abs(test_output[0][0]-america_cases[i])*100)/america_cases[i]}%\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: 1      test: 1.2030653953552246    off by = 20.30653953552246%\n",
            "train: 1      test: 1.7984230518341064    off by = 79.84230518341064%\n",
            "train: 1      test: 2.331010103225708    off by = 133.1010103225708%\n",
            "train: 1      test: 2.4953384399414062    off by = 149.53384399414062%\n",
            "train: 1      test: 2.8063087463378906    off by = 180.63087463378906%\n",
            "train: 1      test: 2.7697548866271973    off by = 176.97548866271973%\n",
            "train: 1      test: 1.5138802528381348    off by = 51.38802528381348%\n",
            "train: 1      test: -1.2763829231262207    off by = 227.63829231262207%\n",
            "train: 1      test: -4.871111869812012    off by = 587.1111869812012%\n",
            "train: 1      test: -8.189630508422852    off by = 918.9630508422852%\n",
            "train: 1      test: -10.528168678283691    off by = 1152.8168678283691%\n",
            "train: 3      test: -11.478436470031738    off by = 482.6145490010579%\n",
            "train: 3      test: -10.502123832702637    off by = 450.0707944234212%\n",
            "train: 3      test: -6.860480308532715    off by = 328.6826769510905%\n",
            "train: 6      test: -0.19150686264038086    off by = 103.19178104400635%\n",
            "train: 6      test: 8.442121505737305    off by = 40.70202509562174%\n",
            "train: 14      test: 15.344761848449707    off by = 9.605441774640765%\n",
            "train: 18      test: 19.51030731201172    off by = 8.390596177842882%\n",
            "train: 19      test: 31.82623291015625    off by = 67.50648900082237%\n",
            "train: 20      test: 54.589088439941406    off by = 172.94544219970703%\n",
            "train: 22      test: 83.4381332397461    off by = 279.2642419988459%\n",
            "train: 34      test: 117.1773452758789    off by = 244.63925081140854%\n",
            "train: 74      test: 155.97804260253906    off by = 110.78113865207982%\n",
            "train: 95      test: 200.72540283203125    off by = 111.28989771792763%\n",
            "train: 105      test: 254.4877471923828    off by = 142.3692830403646%\n",
            "train: 121      test: 329.64276123046875    off by = 172.43203407476756%\n",
            "train: 200      test: 458.2518005371094    off by = 129.1259002685547%\n",
            "train: 271      test: 597.641357421875    off by = 120.53186620733395%\n",
            "train: 287      test: 687.6788940429688    off by = 139.60937074667902%\n",
            "train: 351      test: 777.9223022460938    off by = 121.63028554019765%\n",
            "train: 511      test: 909.7028198242188    off by = 78.02403519064946%\n",
            "train: 777      test: 2134.60107421875    off by = 174.7234329753861%\n",
            "train: 823      test: 2373.97802734375    off by = 188.45419530300728%\n",
            "train: 887      test: 2535.67724609375    off by = 185.871166414177%\n",
            "train: 1766      test: 2842.69580078125    off by = 60.96805213936863%\n",
            "train: 2988      test: 4050.2197265625    off by = 35.54952230798193%\n",
            "train: 4835      test: 5469.75390625    off by = 13.128312435367114%\n",
            "train: 5374      test: 7995.97412109375    off by = 48.789991088458315%\n",
            "train: 7123      test: 9336.5    off by = 31.075389583040852%\n",
            "train: 8459      test: 9787.71484375    off by = 15.707705919730465%\n",
            "train: 8789      test: 10157.4130859375    off by = 15.569610717231766%\n",
            "train: 11236      test: 10526.7451171875    off by = 6.31234320765842%\n",
            "train: 13963      test: 10875.9033203125    off by = 22.109121819719974%\n",
            "train: 16797      test: 11467.154296875    off by = 31.730938281389534%\n",
            "train: 17588      test: 15821.70703125    off by = 10.042602733397771%\n",
            "train: 18117      test: 16685.626953125    off by = 7.900717816829498%\n",
            "train: 18360      test: 17044.453125    off by = 7.165287990196078%\n",
            "train: 18695      test: 17998.01953125    off by = 3.7281651176785235%\n",
            "train: 18873      test: 19657.11328125    off by = 4.1546827809569224%\n",
            "train: 19970      test: 20060.263671875    off by = 0.4519963539058588%\n",
            "train: 19979      test: 20430.1171875    off by = 2.2579567921317385%\n",
            "train: 20258      test: 20793.544921875    off by = 2.6436218870322836%\n",
            "train: 20782      test: 21151.013671875    off by = 1.7756408039409104%\n",
            "train: 21352      test: 21502.845703125    off by = 0.7064710712111277%\n",
            "train: 21595      test: 21849.388671875    off by = 1.1779980174808984%\n",
            "train: 21841      test: 22187.587890625    off by = 1.5868682323382628%\n",
            "train: 22048      test: 22512.0078125    off by = 2.1045347083635706%\n",
            "train: 22541      test: 22798.66015625    off by = 1.1430733164012243%\n",
            "train: 22593      test: 23046.779296875    off by = 2.008495095272872%\n",
            "train: 23285      test: 23288.671875    off by = 0.01576927206356023%\n",
            "train: 23841      test: 23528.083984375    off by = 1.3125121245962836%\n",
            "train: 24128      test: 23765.484375    off by = 1.5024686049403182%\n",
            "train: 24132      test: 24001.30859375    off by = 0.541568897107575%\n",
            "train: 24487      test: 24235.97265625    off by = 1.025145357740842%\n",
            "train: 24601      test: 24469.849609375    off by = 0.5331099980691841%\n",
            "train: 24972      test: 24703.291015625    off by = 1.0760411035359603%\n",
            "train: 24998      test: 24936.603515625    off by = 0.24560558594687576%\n",
            "train: 25023      test: 25170.072265625    off by = 0.5877483340326899%\n",
            "train: 25398      test: 25403.953125    off by = 0.02343934561776518%\n",
            "train: 25434      test: 25638.470703125    off by = 0.8039266459267123%\n",
            "train: 25508      test: 25873.822265625    off by = 1.4341471915673514%\n",
            "train: 25612      test: 26110.181640625    off by = 1.9451102632555053%\n",
            "train: 26543      test: 26347.701171875    off by = 0.7357827981953811%\n",
            "train: 26857      test: 26586.505859375    off by = 1.0071643914994228%\n",
            "train: 26922      test: 26826.701171875    off by = 0.3539812351422628%\n",
            "train: 26957      test: 27068.384765625    off by = 0.41319421903401715%\n",
            "train: 27103      test: 27311.623046875    off by = 0.7697415299966793%\n",
            "train: 27143      test: 27556.470703125    off by = 1.523305099381056%\n",
            "train: 27326      test: 27802.97265625    off by = 1.7454902153626584%\n",
            "train: 27620      test: 28051.1640625    off by = 1.5610574312092687%\n",
            "train: 28065      test: 28301.052734375    off by = 0.8410929427222519%\n",
            "train: 28369      test: 28552.654296875    off by = 0.6473767030032782%\n",
            "train: 28391      test: 28805.9765625    off by = 1.4616482776231905%\n",
            "train: 28819      test: 29060.99609375    off by = 0.8397102389048892%\n",
            "train: 29288      test: 29317.70703125    off by = 0.10143072674815624%\n",
            "train: 29917      test: 29576.08984375    off by = 1.139519859110205%\n",
            "train: 30148      test: 29836.111328125    off by = 1.0345252483581%\n",
            "train: 30561      test: 30097.7578125    off by = 1.5157952537547854%\n",
            "train: 30613      test: 30360.978515625    off by = 0.8232498754614053%\n",
            "train: 30833      test: 30625.740234375    off by = 0.6722011014983946%\n",
            "train: 31667      test: 30892.015625    off by = 2.447293317965074%\n",
            "train: 32425      test: 31159.75    off by = 3.902081727062452%\n",
            "train: 32922      test: 31428.91015625    off by = 4.5352343227932685%\n",
            "train: 33323      test: 31699.4453125    off by = 4.872174436575339%\n",
            "train: 33901      test: 31971.318359375    off by = 5.69210831723253%\n",
            "train: 33955      test: 32244.482421875    off by = 5.037601467015167%\n",
            "train: 34272      test: 32518.888671875    off by = 5.115287488693394%\n",
            "train: 35527      test: 32794.49609375    off by = 7.691344347257016%\n",
            "train: 37289      test: 33071.2578125    off by = 11.31095547614578%\n",
            "train: 48529      test: 33349.1328125    off by = 31.279991731748026%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEdcxi3fUxDx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "f861b750-aeb1-4663-86e9-492875311fdf"
      },
      "source": [
        "x = [i+1 for i in range(len(america_cases))]\n",
        "plt.plot(x, america_cases)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f907b288400>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3SQnbt_DSwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}