{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NODE_for_dow_jones.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP6YNMhyK+nn0NrflMW8+ll",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saahil-jain/Covid_19_predictor/blob/master/NODE_for_dow_jones.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTq1U_aOc_8w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1309b03e-5b91-4d85-d78e-77c6776fc492"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from copy import deepcopy\n",
        "import tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(os.getcwd())\n",
        "if os.getcwd().split(\"/\")[-1] == \"Covid_19_predictor\":\n",
        "  print(\"Current working directory is already Covid_19_predictor\")\n",
        "elif os.path.isdir(\"Covid_19_predictor\"):\n",
        "  print(\"Covid_19_predictor already Exists\")\n",
        "else:\n",
        "  ! git clone https://github.com/saahil-jain/Covid_19_predictor.git"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Covid_19_predictor\n",
            "Current working directory is already Covid_19_predictor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3J7_ZDdEeIX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4775755f-6702-49bf-d138-dfe6bac7557b"
      },
      "source": [
        "%cd Covid_19_predictor/"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'Covid_19_predictor/'\n",
            "/content/Covid_19_predictor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZLNFa_7FDl-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f2c5b252-2321-44b2-a671-52eb80c9f782"
      },
      "source": [
        "data=pd.read_csv('DowJones.csv')\n",
        "data.set_index('Date')\n",
        "data.head()"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1977-09-02</td>\n",
              "      <td>872.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1977-09-09</td>\n",
              "      <td>857.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1977-09-16</td>\n",
              "      <td>856.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1977-09-23</td>\n",
              "      <td>839.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1977-09-30</td>\n",
              "      <td>847.11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date   Value\n",
              "0  1977-09-02  872.31\n",
              "1  1977-09-09  857.04\n",
              "2  1977-09-16  856.81\n",
              "3  1977-09-23  839.14\n",
              "4  1977-09-30  847.11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYosF7yHNNqe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a3796807-d856-4d5a-ad73-424bc7aece17"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Date', 'Value'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl0A9oTmFZcA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "b03137e5-62cf-47d8-987f-85069291c7d5"
      },
      "source": [
        "dow_values=list(data.Value)\n",
        "plt.plot(dow_values)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2896521ba8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3yV5f3/8deVPQhJgLDCXlUUGUZERaWt4mxRa11fFa0tavVbu77fH61arVpHW7W1tVZaqaO1amtVvoAiTlyMADKVFcIegQSy9/X749zn5KyQdVaS9/PxyIP7vs59n3PlfoTzue9rfC5jrUVERLq3uGhXQEREok/BQEREFAxERETBQEREUDAQEREgIdoVaK8+ffrYYcOGRbsaIiKdysqVKw9Za3P8yzttMBg2bBj5+fnRroaISKdijNkRrFzNRCIiomAgIiIKBiIigoKBiIigYCAiIigYiIgICgYiIoKCgYhIp7Fg7T6KK2rD8t4KBiIincDh8hpue3EVt7ywMizvr2AgItIJVNQ0ALC8sJjquoaQv7+CgYhIJ1BaXRfW91cwEBHpBA6UVnu2UxLjQ/7+CgYiIp3A7P+sA+DsMQEJR0NCwUBEpBMYPygLgDnXnxyW91cwEBGJcdZa3vniAADJCaFvIgIFAxGRmLetqAKAIb3SwvYZCgYiIjFuza4jAMy9IS9sn9FpVzoTEenqGhotizfu5401ewHon5kats9SMBARiVH/XL6Tu15f79lPTwpPfwGomUhEJGb5zzQ2xoTtsxQMRERilLVN20nx4f26VjAQEYlRZTX1nu0/XzcprJ+lYCAiEqPKvPIRhbOJCBQMRERiVll105PB6L49wvpZLQYDY8xgY8z7xpiNxpgNxpg7nPJexpjFxpgtzr/ZTrkxxjxhjNlqjFlrjJnk9V4zneO3GGNmepWfbIxZ55zzhAl3CBQR6QTKq+sZ3bcHa34xnUHZ4ZtwBq17MqgHfmKtHQtMAW4zxowFZgPvWmtHA+86+wAXAKOdn1nAU+AKHsA9wKnAZOAedwBxjvme13nnd/xXExHp3I5U1ZKZmkhmWmLYP6vFYGCt3WetXeVslwFfALnADOA557DngEuc7RnA89ZlKZBljBkAnAcsttYWW2tLgMXA+c5rPa21S621Fnje671ERLolay1LC4opPFwRkc9rU5+BMWYYMBFYBvSz1u5zXtoP9HO2c4FdXqftdsqOVb47SLmISLf1l48KABjWOz0in9fqYGCM6QG8CvzQWlvq/ZpzR2+DnhhCxphZxph8Y0x+UVFRuD9ORCRqHlz4JQDD+sRQMDDGJOIKBP+w1v7HKT7gNPHg/HvQKd8DDPY6fZBTdqzyQUHKA1hr51hr86y1eTk54VngQUQk2hobm+6tr548+BhHhk5rRhMZ4BngC2vtY14vzQPcI4JmAm94lV/vjCqaAhx1mpMWAdONMdlOx/F0YJHzWqkxZorzWdd7vZeISLdT5aShmDA4i5OH9orIZ7YmUd0ZwHXAOmPM507Zz4GHgVeMMTcBO4ArnNcWAhcCW4FK4EYAa22xMeZ+YIVz3H3W2mJn+/vAs0Aq8KbzIyLSLdXWNwIwY8LAiH1mi8HAWvsx0Ny4/68HOd4CtzXzXnOBuUHK84ETW6qLiEh3UNvgCgZJCZGbF6wZyCIiMcb9ZJAY5uR03hQMRERijDt1dbKeDEREuq/Cw5UAZKclRewzFQxERGJMSWUtAMMjNMcAFAxERGJOSYUrGGSkRG5lYgUDEZEYs/1QBelJ8fRMCX+COjcFAxGRGFNb30h2ehJxcZHL5h+5ZxAREWmWtZbhP1sIwPSx/SI6rBT0ZCAiEhOKymo8229vPEB8BJ8KQMFARCQiqusacCVoCK6spt5nP0HBQESka6mtb+S4u9/i/vlfNHtMVW2Dz365X3AINwUDEZEwaWy03DtvA2PucuXenPvJdrYeLAt6rDtTqdvukqqw18+bOpBFRMLAWsuIny8MKD/nsSUUPnyRT9kbn+9h68HySFUtKD0ZiIiEwePvbGn2tV3Fldz8Qj6l1XUA3PHS5/zhva0AzP/vqRGpnz89GYiIhMFflhQ0+9odL61m1c4jLNrwNmvume7zWo/kBC6dmBvRJHWgYCAiEhb+fQDedhY39Qc8+vYmn9fSkuJ5/MoJYatXc9RMJCISAUt/1rQW2KHypjkFz3+2w+e4lKT4iNXJm4KBiEiI+c8nuCJvEP0zUzhrTE6L56YlKhiIiHQJ7mUr3dzLV47MaTkldUKE01C4KRiIiISQtZapj7zvUxZnXLOJr50yNOg5Ywf0ZPmdX+flWVPCXr/mqANZRCRErLUsLSj2yTMEkJbk+qrNSg2ekjotKZ6+GSn0zUgJex2bo2AgIhIiUx56lwOlTYHgN5efxK6SKm45ewQACXHBG2Oy0yO3vGVz1EwkIhICtfWNPoEAICMlkR+fO8bzZBAf35R87rKJuZ7t5p4YIknBQEQkBN5cvy+gLNVvmKh3JtK05KbX0pOj30ijYCAiEgL+WUcBUv2GiXqvUZCe1BQA0qI0t8CbgoGISAh8tPVQQFlAMDBeTwZewUBPBiIindiu4krun7+RzQfKWLA2sJkoyS+/kPeaxulezUR6MhAR6cQefutLnvl4O9MfX+Ipu+ikAZ7txmOsbObdn6BgICLSidX7zTS++KQBPHnNJF783qmMzElneJ/mZxwnec009m4yihYFAxGRdjL4rlP8rUmDADh9ZB/e/ck0Uo6RZ+gSr6GlkV7vOBgFAxGRdjhYVs1bG/a3+/xEryeDusbmm5MiJfrPJiIindDHWwJHDx2rWcjtnR+fTYXfYvcx8GCgYCAi0h7FFbU++2vvnU7PlJZnEo/q28Oz/furJrBg7T7OO6F/yOvXVgoGIiLtcKC02me/NYHA34wJucyYkNvygRGgYCAi0gZPvr+VdbuPkug1hyAnIzmKNQoNBQMRkTb4zSLXmsWTh/Vi8vBePDMzr9lspJ1J5/8NREQipM5rXsHywmJys1LJSEkMSEjXGSkYiIi0wqb9ZYy+802fsgGZ0VuMJtRaDAbGmLnGmIPGmPVeZfcaY/YYYz53fi70eu1nxpitxphNxpjzvMrPd8q2GmNme5UPN8Ysc8pfNsZEf5UHERE/X+wrDSjLSov+OgSh0pong2eB84OUP26tneD8LAQwxowFrgJOcM75kzEm3hgTDzwJXACMBa52jgV4xHmvUUAJcFNHfiERkXCwBE4MS07o/M1Dbi0GA2vtEqC4le83A3jJWltjrd0ObAUmOz9brbUF1tpa4CVghjHGAF8D/u2c/xxwSRt/BxGRsCuuqAsom/aVnCjUJDw60mdwuzFmrdOMlO2U5QK7vI7Z7ZQ1V94bOGKtrfcrD8oYM8sYk2+MyS8qKupA1UVE2uZvn2z32Y+PMwzt3fKM486ivcHgKWAkMAHYBzwashodg7V2jrU2z1qbl5PTdSKyiMQ2ay27S6p8yk4emt3M0Z1Tu+YZWGsPuLeNMX8B5ju7e4DBXocOcspopvwwkGWMSXCeDryPFxGJCTX1TUNK/3D1RLLTkhg3KDOKNQq9dj0ZGGMGeO1eCrhHGs0DrjLGJBtjhgOjgeXACmC0M3IoCVcn8zxrrQXeBy53zp8JvNGeOomIhMuqHSWe7W+MH8jU0X3ITO06I4mgFU8Gxph/AtOAPsaY3cA9wDRjzATAAoXAzQDW2g3GmFeAjUA9cJu1tsF5n9uBRUA8MNdau8H5iP8HvGSMeQBYDTwTst9ORCQE3t7oagz5+nF9o1yT8GkxGFhrrw5S3OwXtrX2V8CvgpQvBBYGKS/ANdpIRCQmlVbVkZoYzzM3nBLtqoSNZiCLiLSgpLKWkX27zsihYBQMRCSqGhotizbsp7a+seWDo6Skso7stK6dHEHBQESi6m+fbOfmF1byzhcHWj44CrYfquDzXUfold61g4FSWItIVDQ0Wh5YsJENe105f8qqA2f4xoL5a/YCcOrw3lGuSXjpyUBEoqLwcAV/+6SQ5dtd2W6WFrQ2601klVTWkRBnuObUIdGuSlgpGIhIVLyyYpfP/murY3O+6aHyGnKzU6NdjbBTMBCRiKuqbeDpJQUB5U+8uyUKtQm0raicYbMXcP/8jRwqr6FPj86/rGVLFAxEJOJeWrEzaPljizdHuCbBLVi7D4BnPt5OUVkNfXp07c5jUDAQkSjISIntVA71jU1rF2wrKmdETo8o1iYyFAxEJOIOlFZHuwoBnvu0kH/l78Ja69Nc1Wghq4vlIQpGQ0tFJOIKD1XQv2cK+2MkKKzcUcI981zp0ryfCtwOltVEukoRpycDEYm4wxW19MlI4vgBPQNea2y03PLCSuav3Rux+lTW1nu2/29N4OfuPVIVUNbVKBiISMQdKq+hd3oy/7n1dH535QRG921qkz9aVcdbG/Zz+4urI1afu19f79l2L3x/+1dHecqMiVhVokbBQEQiqqKmnsPltfTukURqUjyXTMzlrR+exUXjXMukbHS+jMPhvS8P8OV+3/evb2ik8HClZ7+k0jUT2nt94zsvGhu2OsUKBQMRiZgtB8o44Z5F7DlSRY7X2P34OOP58r3jpc/D9vnfeTaf83/3EcsKDlPX4EqMt+lAWdBj3bmIBmSmkJulSWciIiEzc+5yz3Zvv7H7aUmu8SyHyps6a0vDlK/oyjlLudfpMP7HMtech+9PG+l5PTUxnh4prvq4g0ZXp2AgIhHR0GjZe7Rp9FDvdN9ZvSmJgV9HOw5VBpS1V6PfKKElW4oAGJydBsCtXsHg7989laxUV7C645wxIatDLNPQUhGJiJMfWOyz73/HnZwQH3BOfFxoem4Pldfwo5d9m59OH9EHgKKyGtKT4n0mwg3MSiEpIY7Chy8Kyed3BnoyEJGwO1pZx5FK3yafEwZm+uwnB3ky+HTboZB8/p2vreOjLb7vNbhXKker6pj7yXYqaht8XnM3WXUnCgYiEnaHKwInbY0b5BsMEoI8BYQqcV2wSWP7S6sZ/8u3gx6fnhT4lNLVKRiISNj9a+VuAK6bMrTZY4LN/P3umSNC8vnBGpsOlgYGiOP6ZwCQEN/9vhq737OQiETcUx9sA+CSiblM+0oOdQ2BX/x5Q7O55tQhvLhsJ8N6p1F4uJKGIAGiPQZmpbJq5xGfsgqvWcduL886jX2lXX+2cTAKBiISdhnJCZTV1DNxcBZxzXQKG2P47tThvLhsJyfkZrL3aDU19aEZ1jnfSUntzbsPw91ElZmWSGZa109KF0z3exYS6QSstcxfu5fquoaWD45x1lpqGhqZddaIZgOB24icHjx93ck8+u3xJCfE8e+VuzzpIdqroqbpCeCRb41j+0MXMqx3mk8weO47kzv0GV2BgoFIDPqs4DC3v7iaX7+1KdpVaTd3IDtSWUdtfSP9eqa06rzzTuhPSmI8KYnxHCqv5YLff9ShehQUVQDw1H9N4spThmCMISUxnpLKWs8xo/t1/fUKWqJmIpEYtKfE1W4dbBROZ7D1YBnnPLaEJ6+ZxMEy10SzpPi2zRnwfoiw1mLamS1u/jpXFtLR/TI8ZcmJ8VR6DSdNjNN9sYKBSAzaerAccHV8dkbr9hwFYNGG/cxzUkJPHJLdpvc44DXap+BQBSPbsdrYf1bt5ukPC+idnsQor8yoyQm+X/4JbQxUXZHCoUgMenWVayhmdis6M99ct49N+4MnW4sGay3/ynfVf9/RppE5J+ZmNndKi/xnD7fWj19ZA8DZY3J8yv1TUyR2w6Gk/nQFRGKAtZZfv/Uly7cXU13XwKFyV3t2dV3TaJo1u44w+VfvBHzx3/qPVZz3uyURre+xrNtzlE+3HQZgRWFJSN7Tf/Zycz7ddoiXlu8MKPef3Zy/w7dewSa8dTcKBiIx4It9Zfzpg21c8fRnrPL6onps8WaGzV5AXUMjr63ew8GyGj7eGpoUDeHiXj7S2ynD2tZE5G/KiF6tOu6avyxj9n/WBZRvPlDe7Dm/vvykbjnJzJ+ugEiUvZK/iwufaBoxc81flwUcs/VgOZudvPv1XgnerA3NpKy22ne0KmBCWEOj5cv9paz2m9wFMPuC49r8Gf+65TRmnjaUgZkptHXumbWWMq/017+4uPnFaa7IG9zmunVFCgYiUfbKil0tHpMYH+dZgetwRS3WWl7J3+UzmaqqNvxzEuoaGtmw9yinPfQeTy/Z5vPa/fM3cv7vmoLayJx0z/bJQ1t3Z+/tlGG9+OWME0mIj/MJgM3x7geoqW+k0El//edrT2b84Kw2f353o9FEIlHmv8hLMOc89qFne86SAuYsKQg4pqK2ntQwJ1j7xRsb+KfTJr+soJjvT2t67dlPC32O/fO1J3Pu4x3vy0iIN9S14tHAOxldXUMje5xF7IOtUuZOdyFNFAxEoqwyRHf0FTX19PFaSrKuoZGGRktKYtsDxMa9pQzMSiErzTdQ/dOrc7Zfz2R2l1Ty8opdAf0Yv/7WSYzul8GYfj3YWdyxL93EuJafDMqq61i9s6mvZXdJFY++7ZqwNzArcLLbq7eezo9fWcNZfqOMujMFA5Eoq6kL/kV39eQhPl++LTn7Nx/4LMZy9ZylbCsqZ/UvprepPvfP38gzH28H8Hm/g6XVPsftLK5k6iPv+5QNyk4lNyuVGRMHAvDmHWfR2MF+jYR4Q32QxHbeZr+6jgXrmprMvGctu9cy9ta7R7JSUPhRn4FIlFXWBWbPBOiZ2vZ7tVedVNHgGj5ZUlnX5k5mdyAAmPHHj1nl3HFf+4xvx/bSguKAcy+bmMvLN5/mWbUsPs50eAx/QnzcMZuJrLU+gcBfe2cudzcKBiJRVl5dz/jBWSz4wVSfRVUagtwNu/PtN+cn/1oTUDb98SWU1wQPOMFkeU10W7P7KJf96VM+23a4Vat/9W1l/qG2SIwzx2wmOtaw0T6t6I8RlxaDgTFmrjHmoDFmvVdZL2PMYmPMFuffbKfcGGOeMMZsNcasNcZM8jpnpnP8FmPMTK/yk40x65xznjAK49LNlNfUc+LAnpwwMJMTvGbpFhyq8DluwQ+metIoXD15CH+78ZSg71dZW88ZD7/n2d9ysJzXV+9pVV1Kq13LUyb5pWu4+i9L+XzXEbLSElnwg6n8+vKTfF53B5DEMKR1aKmZ6LVj/G7t6S/prlrzZPAscL5f2WzgXWvtaOBdZx/gAmC08zMLeApcwQO4BzgVmAzc4w4gzjHf8zrP/7NEurSy6np6pLjuuh/99ngAMlMTSfN6Slhx5zmcMDCTb4x3tcXf/rVRJHs1v/zW67wv9pV5RtK4tTYV9r4jrn6Bi8YNCPr6kco6ThiYSY/kpqeE1Xefy5zr8gA4zVlkPpTijMHSfDA44pV91P/JqXeQ/gIJrsVgYK1dAvg3Ds4AnnO2nwMu8Sp/3rosBbKMMQOA84DF1tpia20JsBg433mtp7V2qXU1bD7v9V4iXV5tfSM19Y1kOF+u7jv/xPg4ny/cnAzXKKEbzxhO/l3nkJuV6nP3fvnJgzhtRG++0i+D7z63IuBzWrtIzF4nl9C1U4bwk3PHNHvc4Ow0AM4ak0N2ehKTh/ei8OGLGNI7rVWf0xZxxjQ76cxay0te8zTS/IbW/v6qiSGvT1fV3j6DftZad4/NfqCfs50LeM+g2e2UHat8d5DyoIwxs4wx+caY/KKionZWXSR2rNvjmq2b7nzx9+mRzGUTc/nrzLygcwbi44xn+Kh/U05qUjwVtfWeyWneWhsM3E8GAzJTPU8hwYwblMmaX0zn+QiMyDGGZpe/3O7VlHbm6D7c7TXT+LKJuQzrkx7sNAmiwx3Izh19RObEW2vnWGvzrLV5OTkaHyyd361/XwU0fdnFxRkeu3ICEwZnMclJ+Xx3M6kUAoJBYjw7/SZSDXXu1Fszg7emvoGfv+bK69M3I5lhfdJ558dnM66ZbKORWh4yPs40OyLqoTe/9Gy/cNOpTBySzaUTXfeTDVFK1dFZtTcYHHCaeHD+PeiU7wG8E30McsqOVT4oSLlIl3ekstazwtaVpwTmx/nG+IF8+D/TuGnq8KDnJ/kN2UxOjKPMb9TQ76+aSJ8eSRypajnr53+/uNqz7U7cNqpvDx69Yjy3nD0SoNnAEE7HaiZavPFAQNm0r7huFJt7mpDg2jvpbB4wE3jY+fcNr/LbjTEv4eosPmqt3WeMWQQ86NVpPB34mbW22BhTaoyZAiwDrgf+0M46iXQqE+5bDLi+YDNSgt9lD+3dfDOHe+DdMOfu33vkzNwb8shMTWLC4CwyUxN9OlmDKa6o5e0gX6wAY/plMPuC47jl7BGe+QORFGdoceLaQ5eN82yfPSaH4X3Sue2ro8JdtS6lxWBgjPknMA3oY4zZjWtU0MPAK8aYm4AdwBXO4QuBC4GtQCVwI4DzpX8/4O7Zus9a6+6U/j6uEUupwJvOj0i34d1R3BbxTjBwry2c6JWTPystydPMlJWW1OJ6AG9v2O/Znnf7GUGP8U9NESmmmSeDj7Y09Rt6p5XISkvi/Z9Oi0DNupYW/wqttVc389LXgxxrgduaeZ+5wNwg5fnAiS3VQ6SzK66oZe+RKk7MzWR3SVPbfnvbtof0TuPBS8cx/QTX+A3vNX69m5AaGi2fbjtMeU19s4Fnze6jnu2TBsVWhs84AwVF5QHrIL/sNYpoQBgmu3U3moEsEiHf/OPHXPyHjwF8cvos3x6Y1qG1rjl1iGd0UbzXk4F3wrrPd7lGLC1cGzxlQ+GhCk8OpMG9Ym/N5S/3l1FT38hfP9ruU+5O373hl+cRp5XKOkzBQCTMVhQWM2z2AnaXuMbw+4+Mef224M0ybRXvddfcP7PpTtk9uianZ3LAOfUNjUz77Qee/f+7fWpI6hJK+466hrsu237Yp/y0Eb3plZ7kGZYrHaNgIBJm3/7zZz77tX7DPCeEaOEVdyyYNMT3/a6dMgRwjcrxt+lA03rKr992RtT6BY7FPRHvnS8OsnZ30ypqu0oqOWNU6Gc8d1cKBiIRtnFvqWf71VtPD9n7uodSjurbw6fcnTW01pl49uX+Us/Tyd4jTWmpQxWUQi3Zaz7FN//4iWe7vKaeXhGa69AdKBiIhFGwbKHvfNE0hDOUWTXrnCcO/5TR7v3vPZ/Pnz7Yyvm/+4jfOgu/uIecvnrraSGrR6gdKg8cFrv/aDVHKuuUiC6EFAxEwqi8OjAYuNNFJCXEMSg7dLl8ap3Mns0FA4AXl7k6ip98fxvrdh+l8LArncOovsdOjR1rznjElZU1OUFfYaGiKykSRmXVri/++y850TPcc7/TITr/v6f6jADqKPeTgX+aCu9hpt79BgWHynnyfdei9hmdqBO2odF6msSS9WQQMgoGImH0WYFrBMzEwVmsuPMcAN770pW9pb2TzZpT5/QJ+KepSExoCgDe6xHf/bpniZJONTTz9+9uiXYVuqTOczsg0gltPlBGZmoiJ+Zm0ug1jTYhznjSUodKS30G/kqdJqy7Ljo+pPUItzW7mkYU1bRynQZpmZ4MRMLoQGkNA5wx/95338P7pHd4bWB/Ne5gkOB7l9/S57SUqiLa/np9ns/+ofIaz3aVgkHIKBiIhNDjizezYO0+rLV8uvUQh8pr6O01YuiMUb0Bgq5V0FGjclxDSsf4dQb7Nxv5Zx796nGxnQ7+nLH9fPY3eA3NVTAIHTUTiYSQuz37yrzBvJzvyp0zY0LTIjEpTtbPUHYcu11+8iCOH9CTE/2+7P3XJZ4xYSDr9jTlInIntOuMzhwd24GsM1EwEAmRqtqmu1R3IADond7UN3CowjVmfvXOpnbvUDHGBAQCCAw8vbzWBb52yhCf5G+xauyAnmzcV+pT9sV954flCau7UjORSIj8+cNtQcv7ZDR9+R4srQ56TDgZY3jnx2cz0Om78B7FVFoVOA8iFi2840y2/uoCz/5tXx2pQBBiCgYiIdLckEfvhWuCTUKLhFF9e9Az1VWPHskJnvz/lbWdIxiAa/W1BOcpJy1JjRqhpmAgEmberTTuZSkX/+isiNcjwek7SEmK54mrJjCiTzo/PGdMxOvREe7BuamabBZyCq8iIZQYb6hr8E1RfUVe0/rGz31nMq+v3uOzEE2kJMS57v0aGy1ZaUm81wlXA3Mvf5mmJqKQ05OBSAi4J3z94Guj2fbghZ7yN247w2ec/9ljcnj8ygkRrx/AL795AicNyuSEgZFf1D7U1F8QenoyEAmBT7YeAiArPYn4OMNdFx3PlBG9g47uiZbxg7OYF4OL17SFe10g9RmEnq6oSAjsOOzK+TN+kOvL/7tnjohmdbq8zFStYxBqaiYSCYENe4+SkZzQJZpgOoOhvUOX+ltc9GQg0gEHSqs59cF3SYgzHDcgIywziyWQf4oN6ThdUZEO+Om/1gBQ32jJjsH1g7sq/zUbpON0RUXayVrLR1sOefZjcTH5rkrBIPR0RUXayT/1c98Qr08gzUtQc1zIKRiItNOLy3f67LvXLZDwOddJZ90Zkut1NupAFmmH0uo6frNoEwAXjuvPwnX7Ka2K7UViuoInr5lERU3nyafUmejJQKQdCg9VeLYvPsm1XkGol7GUQEkJcWSnq28mHPRkINIO+482paK+4MT+PP+dyUwd1SeKNRLpGAUDkXb4dNthAN7/6TSMMZ6U0CKdlZqJRNrIWsuznxYCMLSXZsJK16BgINJGnxUc9mzHaYijdBEKBiKttLukkoqaeuav3QfAvNvPiHKNREJHfQYirfD66j388OXPfcpOGpQVpdqIhJ6CgUgLhs1eEO0qiISdmolEjmHPkaqg5Woikq5GwUDkGAqKyj3bQ7xGDqmJSLqaDjUTGWMKgTKgAai31uYZY3oBLwPDgELgCmttiXElE/k9cCFQCdxgrV3lvM9M4C7nbR+w1j7XkXqJhMrOYtcKZp/O/hoDs1LZc6QKDSCSrigUTwZftdZOsNbmOfuzgXettaOBd519gAuA0c7PLOApACd43AOcCkwG7jHGZIegXiIdsq2onDtfWw9Av56uJHS5WakMyEyNZrVEwiIczUQzAPed/XPAJV7lz1uXpUCWMWYAcB6w2FpbbK0tARYD54ehXiJtcudr6zzbWsFMurqOBgMLvG2MWbNTncIAAA1sSURBVGmMmeWU9bPW7nO29wP9nO1cYJfXubudsubKRaLqYGkNAPdfcmKUayISfh0dWjrVWrvHGNMXWGyM+dL7RWutNcbYDn6GhxNwZgEMGTIkVG8r4sNay18/2k7BoQp+cu4YrpsyNNpVEgm7DgUDa+0e59+DxpjXcLX5HzDGDLDW7nOagQ46h+8BBnudPsgp2wNM8yv/oJnPmwPMAcjLywtZkBFxW72zhEv/9Klnf0z/jCjWRiRy2t1MZIxJN8ZkuLeB6cB6YB4w0zlsJvCGsz0PuN64TAGOOs1Ji4Dpxphsp+N4ulMmEnHegWBQdipnKxupdBMdeTLoB7zmLD+XALxorX3LGLMCeMUYcxOwA7jCOX4hrmGlW3ENLb0RwFpbbIy5H1jhHHeftba4A/USaZea+gbP9nkn9OPp6/KOcbRI12Ks7ZytLXl5eTY/Pz/a1ZAuxJ124qfTx3D710ZHuTYi4WGMWek1FcBDM5BFgJKKWs/2zNOHRa8iIlGiYCACLFjnGg39yLfGkZGSGOXaiESegoF0e9ZaXvhsB8f1z+DbJw9u+QSRLkjBQLq8gqJy8gt9xyTsPFzJ+5sOcrSqjscXb2bTgTL+69QhWrlMui2tZyBd3tce/RCAr/TLYNGPzmLvkSrO+s37AcddrqcC6cYUDKRLW7K5yLO96UAZX3/0A7YVVQQc9+yNp5CaFB/JqonEFDUTSZe0ZHMRZ/76Pa6fu5w4A5dNdKW78g4Eg7Jd2UenjOjFtK/0jUo9RWKFngyky6hraGT+2r088uYm9pdWe8rn3T6V5IQ4/rN6DwBnjOrN3BtOITEujn+v3M0F4/pHq8oiMUPBQDqVo1V1fLbtEP0zUzmufwYpifHUNTRy3u+WUODX/HPq8F789tvjGeysUFb48EUB73fFKeonEAEFA+kkSipqeXXVbh5Y8IVP+bM3nsIf39vqEwju+cZYrsgbTHqy/rxFWkv/WyTmrdl1hBlPfhL0tRv+tsKzffyAnrxw02T69EiOVNVEugwFA4lZVbUNfLSliCVbmkYEfXP8QB68bBwb95ZyxdOfAXDZpFyO65/BrLNGRquqIp2egoFExcodJZTX1PukiD5YVs3GvaU+d/tuvdKTWHX3uZ79ycN78faPzmLT/jK+MX5gROos0pUpGEjEPTB/I3/9eDsAmx+4gKSEOPYeqeL0h99r9pys1MB8QWP6ZTCmnxafEQkFBQMJm/qGRh5bvJmkhDgOl9cyaWgWmamJnkAAsPlAGSfmZrJ+z1Gfc6eP7cdjV05g35Eq7np9PTcok6hIWCkYyDHNnLucqtoGnvyvSeRktK1j9r75G3n+sx2e/ReWNm2fMLAnG/aWsrTgMMcP6Mnfl+0EYNXd59IrPclz3Oh+Gbx882kd/C1EpCWagSzNKiqr4cPNRSwvLOacxz5s9XnWWt5av88nEPj7zeXjAXhgwReM/PlCT9oI70AgIpGjYCDN+uHLqz3bR6vqWn3effM3csvfVwHw0GXjAPjHd08FXLN/t/7qAsYO7Blw3oDMlI5UV0Q6QM1EEuBbT33Kyh0lnv0ROelkp7V8x/7ZtsO8sLSQhev2e8quOmUwV08eAgTOAF5773ROuvdtwDV5TJ3BItGjYCA+nnx/q08gyL/rHO6dt4ENe0ubPae6roH4OMPVf1nqKbv74rHcNHX4MT+rZ0oi7/3kbJIS4hiUndbxyotIuykYiEdDo+U3izZ59i+dmEufHslkpSV6mokaGy3LC4sxwJVzljKsdxqFhyt93ufikwa0GAjcRuT0CFn9RaT9FAzEwz3T92cXHMfNZzfN5k1JiKe4opa31u/nthdX0dBoPa95B4Jzju/LnOvytFqYSCekYNCNvbV+H3uPVJOYEEfPlATueOlzAGb6jenfVeL6wr/l7yuDvs/tXx3FkF5pXDx+gAKBSCelYNANPfXBNh5568ugr9189ghSEn1X/Lpvxoks2nDAs//CTZPZVVzF6SN7M6xPeljrKiKRoWDQzdQ3NDYbCObekMfXjusXUN6vZwpnj8nhw81FbH/oQozR3b9IV6Ng0I3UNTTy4ELXegDxcYY3bjuD7PQkSqvqyE5Lov8xxvk/fd3JVNTUKxCIdFEKBt2EtZZZz+fz/qYijHEliIt32vdzs1JbPD8lMT6g+UhEug4Fgy6svqGRN9fvZ1dJJat2lPD+JtdooZdnneYJBCIioGAQ00qr63jj873U1DVwsKyGOUsKyM1KZUROOo9fOcGzotfWg2W8vnov4wdnkZoYzwMLNvLl/rKA98tMTWTV3ecqEIhIAAWDGLVow35ufiFwKOeeI1XsOVJF3gPvADCqbw+2HiwP+h6J8YbvnTmC9OQEausbuXXaSAUCEQlKwSAMymvqSU+Kp6a+kZU7ShiYlUr/nimkJh27zX1ZwWGunLPUpyw9KZ7UpAQmDcli5unDGNYnnQVr9/LgQteIoGCB4K/X5/H14/sCqMNXRFql2wWDw+U1ZKclBZ0cVVPfwLKCYkb368GAzMBO1fqGRgoPVzIwK4XUxHh2FVcxuFcqxhgWrN3H/fM3sr+0Oujn9s1I5q6Lx/KNkwZwsKyGfj19R+5sKyr3CQSnj+zN/55/HOMHZQZ8oc86ayTfO3MEpVX1/PL/NnDK8F5ckTdYd/0i0m7GWtvyUTEoLy/P5ufnt+mcuoZGLv3TJ6zf40q6du2UIfzPecfx96U7fHLyAEwZ0YvSqnp2HK4gOz2Job3T2HygnKKyGuKMa+z9vqPVjMvNxGI97+nvnOP7Ul5Tz87Dlew96hso3E08WWmJHKl05f4Zl5vJH6+ZyNDemswlIqFnjFlprc0LKO9OwcBay79W7uZ//7222WN6JCdQXlPv2U9JjOOUYb3YU1JFQrxhd0kVlbUN9EpPIj7OUFRWA7hm7v7onDGkJMZT39BIfJzxuaM/WlXHhPvexlrXXf+n2w4HfPZVpwzmocvGqWlHRMJGwcBLXUMjjdbyxuq9LFi3j/GDMrnjnDGAazLW0ao6iitqGZydGvClbq2ltKqenqkJriyfb29i+th+nDy0V5vqYK1lz5EqcrNS+WBzEXHGcNqI3iQlaL0hEQkfBQMREWk2GOg2VEREFAxERCSGgoEx5nxjzCZjzFZjzOxo10dEpDuJiWBgjIkHngQuAMYCVxtjxka3ViIi3UdMBANgMrDVWltgra0FXgJmRLlOIiLdRqwEg1xgl9f+bqfMhzFmljEm3xiTX1RUFLHKiYh0dbESDFrFWjvHWptnrc3LycmJdnVERLqMWAkGe4DBXvuDnDIREYmAmJh0ZoxJADYDX8cVBFYA11hrNxzjnCJgRzs/sg9wqJ3ndhe6Ri3TNWqZrlHLIn2NhlprA5pWYiJrqbW23hhzO7AIiAfmHisQOOe0u53IGJMfbAaeNNE1apmuUct0jVoWK9coJoIBgLV2IbAw2vUQEemOYqXPQEREoqi7BoM50a5AJ6Br1DJdo5bpGrUsJq5RTHQgi4hIdHXXJwMREfGiYCAiIt0rGCgzahNjTKExZp0x5nNjTL5T1ssYs9gYs8X5N9spN8aYJ5zrttYYMym6tQ8fY8xcY8xBY8x6r7I2XxdjzEzn+C3GmJnR+F3CpZlrdK8xZo/z9/S5MeZCr9d+5lyjTcaY87zKu+z/R2PMYGPM+8aYjcaYDcaYO5zy2P1bstZ2ix9c8xe2ASOAJGANMDba9Yri9SgE+viV/RqY7WzPBh5xti8E3gQMMAVYFu36h/G6nAVMAta397oAvYAC599sZzs72r9bmK/RvcBPgxw71vm/lgwMd/4Pxnf1/4/AAGCSs52Ba1Lt2Fj+W+pOTwbKjNqyGcBzzvZzwCVe5c9bl6VAljFmQDQqGG7W2iVAsV9xW6/LecBia22xtbYEWAycH/7aR0Yz16g5M4CXrLU11trtwFZc/xe79P9Ha+0+a+0qZ7sM+AJX8s2Y/VvqTsGgVZlRuxELvG2MWWmMmeWU9bPW7nO29wP9nO3ufu3ael266/W63WnimOtu/kDXCGPMMGAisIwY/lvqTsFAfE211k7CtaDQbcaYs7xftK5nVI079qPr0qyngJHABGAf8Gh0qxMbjDE9gFeBH1prS71fi7W/pe4UDJQZ1Yu1do/z70HgNVyP7QfczT/Ovwedw7v7tWvrdel218tae8Ba22CtbQT+guvvCbrxNTLGJOIKBP+w1v7HKY7Zv6XuFAxWAKONMcONMUnAVcC8KNcpKowx6caYDPc2MB1Yj+t6uEcrzATecLbnAdc7Ix6mAEe9HnW7g7Zel0XAdGNMttNcMt0p67L8+pAuxfX3BK5rdJUxJtkYMxwYDSyni/9/NMYY4BngC2vtY14vxe7fUrR73SP5g6vHfjOuUQx3Rrs+UbwOI3CN3lgDbHBfC6A38C6wBXgH6OWUG1xrVG8D1gF50f4dwnht/omrmaMOV/vsTe25LsB3cHWWbgVujPbvFYFr9IJzDdbi+mIb4HX8nc412gRc4FXeZf8/AlNxNQGtBT53fi6M5b8lpaMQEZFu1UwkIiLNUDAQEREFAxERUTAQEREUDEREBAUDERFBwUBERID/D/HBC6AUDTDdAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq_LANEXFpTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "\tn_vars = 1 \n",
        "\tdf = DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t\tnames += [('x') for j in range(n_vars)]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [('y') for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg\n"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BS6ZOMgNdnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#splitting the values of dow into X and y.\n",
        "values = dow_values\n",
        "timeseries = series_to_supervised(values)\n",
        "X=timeseries.x\n",
        "y=timeseries.y\n"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wX8r76oRL53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_sequences(data, seq_length):\n",
        "    xs = []\n",
        "    ys = []\n",
        "\n",
        "    for i in range(len(data)-seq_length-1):\n",
        "        x = data[i:(i+seq_length)]\n",
        "        y = data[i+seq_length]\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "\n",
        "    return np.array(xs), np.array(ys)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX-HkytjRzV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# seq_length = 5\n",
        "# X, y = create_sequences(dow_values, seq_length)\n"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHbr-GBCOgrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#splitting X and y into test and train.\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "X_train=np.array(X_train).astype(np.float32)\n",
        "X_test=np.array(X_test).astype(np.float32)\n",
        "y_train=np.array(y_train).astype(np.float32)\n",
        "y_test=np.array(y_test).astype(np.float32)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tlnq_B1As4HL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "463066f4-cd7b-4f6c-ec0d-24dd54e19057"
      },
      "source": [
        "X_train,y_train"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 872.31,  857.04,  856.81, ..., 9093.24, 9171.61, 9370.07],\n",
              "       dtype=float32),\n",
              " array([ 857.04,  856.81,  839.14, ..., 9171.61, 9370.07, 9321.4 ],\n",
              "       dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNPo6ToDPEB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR, MultiStepLR"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3Hr30delw_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = torch.utils.data.DataLoader((X_train,y_train), batch_size=10, shuffle=False)\n",
        "testset = torch.utils.data.DataLoader((X_test,y_test), batch_size=10, shuffle=False)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPYO71g7PMd4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def norm(dim):\n",
        "    return nn.GroupNorm(min(32, dim), dim)\n",
        "    \n",
        "def zip_map(zipped, update_op):\n",
        "    return [update_op(*elems) for elems in zipped]\n",
        "\n",
        "def euler_update(h_list, dh_list, dt):\n",
        "    return zip_map(zip(h_list, dh_list), lambda h, dh: h + dt * dh)\n",
        "\n",
        "def euler_step(func, dt, state):\n",
        "    return euler_update(state, func(state), dt)\n",
        "\n",
        "def rk2_step(func, dt, state, **kwargs):\n",
        "    k1 = func(state, **kwargs)\n",
        "    k2 = func(euler_update(state, k1, dt), **kwargs)\n",
        "    return zip_map(zip(state, k1, k2),\n",
        "                   lambda h, dk1, dk2: h + dt * (dk1 + dk2) / 2)\n",
        "\n",
        "def rk4_step(func, dt, state, **kwargs):\n",
        "    k1 = func(state, **kwargs)\n",
        "    k2 = func(euler_update(state, k1, dt / 2), **kwargs)\n",
        "    k3 = func(euler_update(state, k2, dt / 2), **kwargs)\n",
        "    k4 = func(euler_update(state, k3, dt), **kwargs)\n",
        "\n",
        "    return zip_map(\n",
        "        zip(state, k1, k2, k3, k4), lambda h, dk1, dk2, dk3, dk4: h + dt * ( dk1 + 2 * dk2 + 2 * dk3 + dk4) / 6,)\n",
        "    \n",
        "def forward_dynamics(state, nnet):\n",
        "    t, y = state\n",
        "    return [1.0, nnet(t, y)]\n",
        "\n",
        "def backward_dynamics(state, nnet):\n",
        "    with torch.set_grad_enabled(True):\n",
        "        t, ht, at = state[0], state[1], state[2]\n",
        "        ht = ht.detach()\n",
        "        ht.requires_grad_(True)\n",
        "        ht_new = nnet(t, ht)\n",
        "        gradients = torch.autograd.grad(ht_new, [ht] + [w for w in nnet.parameters()], at, allow_unused=True, retain_graph=True)\n",
        "    return [1.0, ht_new, *gradients]\n",
        "\n",
        "class NeuralODEFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, nnet, solver, t, *params):\n",
        "        delta_t = t[1:] - t[:-1]\n",
        "\n",
        "        ctx.nnet = nnet\n",
        "        ctx.solver = solver\n",
        "        ctx.delta_t = delta_t\n",
        "\n",
        "        state = [0, input]\n",
        "        for dt in delta_t:\n",
        "            state = solver(func=forward_dynamics, dt=float(dt), state=state, nnet=nnet)\n",
        "        output = state[1]\n",
        "        \n",
        "        ctx.save_for_backward(input, output)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, output_gradients):\n",
        "        input, output = ctx.saved_tensors\n",
        "        nnet = ctx.nnet\n",
        "        solver = ctx.solver\n",
        "        delta_t = ctx.delta_t\n",
        "        params = nnet.parameters()\n",
        "\n",
        "        grad_weights = []\n",
        "        for p in params:\n",
        "            grad_weights.append(torch.zeros_like(p))\n",
        "\n",
        "        state = [1, output, output_gradients, *grad_weights]\n",
        "\n",
        "        for i, dt in enumerate(delta_t):\n",
        "            state = solver(func=backward_dynamics, dt=float(dt), state=state, nnet=nnet)\n",
        "\n",
        "        grad_input = state[2]\n",
        "        grad_weights = state[3:]\n",
        "        return (grad_input, None, None, None, *grad_weights)\n",
        "\n",
        "class NeuralODE(nn.Module):\n",
        "    def __init__(self, model, solver=rk4_step, t=np.linspace(0,99,99)):\n",
        "      super().__init__()\n",
        "      self.t = t\n",
        "      self.model = model\n",
        "      self.solver = solver\n",
        "      self.params = [w for w in model.parameters()]\n",
        "\n",
        "    def changetime(self, x):\n",
        "      self.t = np.array([n+1 for n in range(x)])\n",
        "\n",
        "    def forward(self, input):\n",
        "      return NeuralODEFunction.apply(input, self.model, self.solver, self.t, *self.params)\n",
        "\n",
        "class arguments:\n",
        "  def __init__(self):\n",
        "    self.batch_size=64\n",
        "    self.test_batch_size=1000\n",
        "    self.epochs=15\n",
        "    self.lr=0.01\n",
        "    self.gamma=1\n",
        "    self.seed=1\n",
        "    self.log_interval=5\n",
        "    \n",
        "args=arguments()\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3hNgJAQPSX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "      self.fc1 = nn.Linear(1, 64)\n",
        "      self.fc2 = nn.Linear(64, 64)\n",
        "      self.fc3 = nn.Linear(64, 256)\n",
        "      # self.fc4 = nn.Linear(128, 256)\n",
        "      # self.fc5 = nn.Linear(256, 512)\n",
        "      # self.fc6 = nn.Linear(256, 256)\n",
        "      # self.fc7 = nn.Linear(512, 256)\n",
        "      # self.fc8 = nn.Linear(256, 128)\n",
        "      self.fc9 = nn.Linear(256, 64)\n",
        "      self.fc10 = nn.Linear(64, 64)\n",
        "      self.fc11 = nn.Linear(64, 1)\n",
        "      self.fc12 = nn.Linear(1,1)\n",
        "\n",
        "    def forward(self, t, x):\n",
        "      # x = torch.tanh(self.fc1(x))\n",
        "      # x = torch.tanh(self.fc2(x))\n",
        "      # x = torch.tanh(self.fc3(x))\n",
        "      # # x = self.fc4(x)\n",
        "      # # x = self.fc5(x)\n",
        "      # # x = self.fc6(x)\n",
        "      # # x = self.fc7(x)\n",
        "      # # x = self.fc8(x)\n",
        "      # x = torch.tanh(self.fc9(x))\n",
        "      # x = torch.tanh(self.fc10(x))\n",
        "      # x = torch.tanh(self.fc11(x))\n",
        "      x = self.fc12(x)\n",
        "      return x\n"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj_tksB7PWjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train function\n",
        "\n",
        "def train(args, model, device, train_loader, optimizer, epoch, loss_values):\n",
        "  #optimizer = optim.Rprop(model.parameters(), lr=0.01, etas=(0.5, 1.2), step_sizes=(1e-06, 50))\n",
        "  for (x,y) in enumerate(train_loader):\n",
        "    y=y.view(2,1664,1)\n",
        "    data = y[0]\n",
        "    target = y[1]\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = torch.sqrt(loss_function(output,target))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss_values.append(loss)\n",
        "    print(\"{0:45s}\".format('Train Loss'), loss.item())\n",
        "    "
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8l3BA7dPZAf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2df8afec-41ce-4f01-950a-b391d83093cc"
      },
      "source": [
        "#training loop\n",
        "%%time\n",
        "loss_values=[]\n",
        "\n",
        "model_cases = Net().to(device)\n",
        "model_cases = NeuralODE(model_cases)\n",
        "loss_function=nn.MSELoss(reduction='mean')\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model_cases.parameters(), lr = 0.001)\n",
        "\n",
        "NODE_loss_cases = {}\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
        "\n",
        "epochs = 15\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('\\nTrain Epoch: {}'.format(epoch))\n",
        "    train(args, model_cases, device, trainset, optimizer, epoch, loss_values)\n",
        "    #scheduler.step()\n",
        "\n",
        "plt.title('MSE LOSS')\n",
        "plt.plot(loss_values)\n",
        "plt.xlabel('Epoch#')\n",
        "plt.ylabel('MSE')\n"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Epoch: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-144-7ce4ca1b943a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loss_values=[]\\n\\nmodel_cases = Net().to(device)\\nmodel_cases = NeuralODE(model_cases)\\nloss_function=nn.MSELoss(reduction='mean')\\n\\n\\noptimizer = optim.Adam(model_cases.parameters(), lr = 0.001)\\n\\nNODE_loss_cases = {}\\nscheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\\n\\nepochs = 15\\n\\nfor epoch in range(epochs):\\n    print('\\\\nTrain Epoch: {}'.format(epoch))\\n    train(args, model_cases, device, trainset, optimizer, epoch, loss_values)\\n    #scheduler.step()\\n\\nplt.title('MSE LOSS')\\nplt.plot(loss_values)\\nplt.xlabel('Epoch#')\\nplt.ylabel('MSE')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-143-1a1e6071f6ce>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, train_loader, optimizer, epoch, loss_values)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mloss_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IF7kG3xOW_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test function\n",
        "\n",
        "def test(args, model, device, test_loader):\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for (x,y) in enumerate(test_loader):\n",
        "      y=y.view(2,417,1)\n",
        "      data = y[0]\n",
        "      target = y[1]\n",
        "      #print(data)\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)\n",
        "      for i,j,k in zip(data,output,target):\n",
        "        print(i[0],j[0],k[0])\n",
        "      loss = torch.sqrt(loss_function(output,target))\n",
        "      test_loss += loss\n",
        "      #plt.plot(target.cpu())\n",
        "\n",
        "    return test_loss\n",
        "\n",
        "\n",
        "test_loss=test(args, model_cases, device, testset)\n",
        "print(test_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDp9S7Jawc8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}